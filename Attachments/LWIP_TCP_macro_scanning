tcp.c:50:#if LWIP_TCP /* don't build if not configured for use in lwipopts.h */
tcp.c:51:
tcp.c:52:#include "lwip/def.h"
tcp.c:53:#include "lwip/mem.h"
tcp.c:54:#include "lwip/memp.h"
tcp.c:55:#include "lwip/tcp.h"
tcp.c:56:#include "lwip/priv/tcp_priv.h"
tcp.c:57:#include "lwip/debug.h"
tcp.c:58:#include "lwip/stats.h"
tcp.c:59:#include "lwip/ip6.h"
tcp.c:60:#include "lwip/ip6_addr.h"
tcp.c:61:#include "lwip/nd6.h"
tcp.c:62:
tcp.c:63:#include <string.h>
tcp.c:64:
tcp.c:65:#ifndef TCP_LOCAL_PORT_RANGE_START
tcp.c:66:/* From http://www.iana.org/assignments/port-numbers:
tcp.c:67:   "The Dynamic and/or Private Ports are those from 49152 through 65535" */
tcp.c:68:#define TCP_LOCAL_PORT_RANGE_START        0xc000
tcp.c:69:#define TCP_LOCAL_PORT_RANGE_END          0xffff
tcp.c:70:#define TCP_ENSURE_LOCAL_PORT_RANGE(port) ((u16_t)(((port) & ~TCP_LOCAL_PORT_RANGE_START) + TCP_LOCAL_PORT_RANGE_START))
tcp.c:71:#endif
tcp.c:72:
tcp.c:73:#if LWIP_TCP_KEEPALIVE
tcp.c:74:#define TCP_KEEP_DUR(pcb)   ((pcb)->keep_cnt * (pcb)->keep_intvl)
tcp.c:75:#define TCP_KEEP_INTVL(pcb) ((pcb)->keep_intvl)
tcp.c:76:#else /* LWIP_TCP_KEEPALIVE */
tcp.c:77:#define TCP_KEEP_DUR(pcb)   TCP_MAXIDLE
tcp.c:78:#define TCP_KEEP_INTVL(pcb) TCP_KEEPINTVL_DEFAULT
tcp.c:79:#endif /* LWIP_TCP_KEEPALIVE */
tcp.c:80:
tcp.c:81:/* As initial send MSS, we use TCP_MSS but limit it to 536. */
tcp.c:82:#if TCP_MSS > 536
tcp.c:83:#define INITIAL_MSS 536
tcp.c:84:#else
tcp.c:85:#define INITIAL_MSS TCP_MSS
tcp.c:86:#endif
tcp.c:87:
tcp.c:88:static const char * const tcp_state_str[] = {
tcp.c:89:  "CLOSED",
tcp.c:90:  "LISTEN",
tcp.c:91:  "SYN_SENT",
tcp.c:92:  "SYN_RCVD",
tcp.c:93:  "ESTABLISHED",
tcp.c:94:  "FIN_WAIT_1",
tcp.c:95:  "FIN_WAIT_2",
tcp.c:96:  "CLOSE_WAIT",
tcp.c:97:  "CLOSING",
tcp.c:98:  "LAST_ACK",
tcp.c:99:  "TIME_WAIT"
tcp.c:100:};
tcp.c:101:
tcp.c:102:/* last local TCP port */
tcp.c:103:static u16_t tcp_port = TCP_LOCAL_PORT_RANGE_START;
tcp.c:104:
tcp.c:105:/* Incremented every coarse grained timer shot (typically every 500 ms). */
tcp.c:106:u32_t tcp_ticks;
tcp.c:107:static const u8_t tcp_backoff[13] =
tcp.c:108:    { 1, 2, 3, 4, 5, 6, 7, 7, 7, 7, 7, 7, 7};
tcp.c:109: /* Times per slowtmr hits */
tcp.c:110:static const u8_t tcp_persist_backoff[7] = { 3, 6, 12, 24, 48, 96, 120 };
tcp.c:111:
tcp.c:112:/* The TCP PCB lists. */
tcp.c:113:
tcp.c:114:/** List of all TCP PCBs bound but not yet (connected || listening) */
tcp.c:115:struct tcp_pcb *tcp_bound_pcbs;
tcp.c:116:/** List of all TCP PCBs in LISTEN state */
tcp.c:117:union tcp_listen_pcbs_t tcp_listen_pcbs;
tcp.c:118:/** List of all TCP PCBs that are in a state in which
tcp.c:119: * they accept or send data. */
tcp.c:120:struct tcp_pcb *tcp_active_pcbs;
tcp.c:121:/** List of all TCP PCBs in TIME-WAIT state */
tcp.c:122:struct tcp_pcb *tcp_tw_pcbs;
tcp.c:123:
tcp.c:124:/** An array with all (non-temporary) PCB lists, mainly used for smaller code size */
tcp.c:125:struct tcp_pcb ** const tcp_pcb_lists[] = {&tcp_listen_pcbs.pcbs, &tcp_bound_pcbs,
tcp.c:126:  &tcp_active_pcbs, &tcp_tw_pcbs};
tcp.c:127:
tcp.c:128:u8_t tcp_active_pcbs_changed;
tcp.c:129:
tcp.c:130:/** Timer counter to handle calling slow-timer from tcp_tmr() */
tcp.c:131:static u8_t tcp_timer;
tcp.c:132:static u8_t tcp_timer_ctr;
tcp.c:133:static u16_t tcp_new_port(void);
tcp.c:134:
tcp.c:135:/**
tcp.c:136: * Initialize this module.
tcp.c:137: */
tcp.c:138:void
tcp.c:139:tcp_init(void)
tcp.c:140:{
tcp.c:141:#if LWIP_RANDOMIZE_INITIAL_LOCAL_PORTS && defined(LWIP_RAND)
tcp.c:142:  tcp_port = TCP_ENSURE_LOCAL_PORT_RANGE(LWIP_RAND());
tcp.c:143:#endif /* LWIP_RANDOMIZE_INITIAL_LOCAL_PORTS && defined(LWIP_RAND) */
tcp.c:144:}
tcp.c:145:
tcp.c:146:/**
tcp.c:147: * Called periodically to dispatch TCP timers.
tcp.c:148: */
tcp.c:149:void
tcp.c:150:tcp_tmr(void)
tcp.c:151:{
tcp.c:152:  /* Call tcp_fasttmr() every 250 ms */
tcp.c:153:  tcp_fasttmr();
tcp.c:154:
tcp.c:155:  if (++tcp_timer & 1) {
tcp.c:156:    /* Call tcp_slowtmr() every 500 ms, i.e., every other timer
tcp.c:157:       tcp_tmr() is called. */
tcp.c:158:    tcp_slowtmr();
tcp.c:159:  }
tcp.c:160:}
tcp.c:161:
tcp.c:162:#if LWIP_CALLBACK_API || TCP_LISTEN_BACKLOG
tcp.c:163:/** Called when a listen pcb is closed. Iterates one pcb list and removes the
tcp.c:164: * closed listener pcb from pcb->listener if matching.
tcp.c:165: */
tcp.c:166:static void
tcp.c:167:tcp_remove_listener(struct tcp_pcb *list, struct tcp_pcb_listen *lpcb)
tcp.c:168:{
tcp.c:169:   struct tcp_pcb *pcb;
tcp.c:170:   for (pcb = list; pcb != NULL; pcb = pcb->next) {
tcp.c:171:      if (pcb->listener == lpcb) {
tcp.c:172:         pcb->listener = NULL;
tcp.c:173:      }
tcp.c:174:   }
tcp.c:175:}
tcp.c:176:#endif
tcp.c:177:
tcp.c:178:/** Called when a listen pcb is closed. Iterates all pcb lists and removes the
tcp.c:179: * closed listener pcb from pcb->listener if matching.
tcp.c:180: */
tcp.c:181:static void
tcp.c:182:tcp_listen_closed(struct tcp_pcb *pcb)
tcp.c:183:{
tcp.c:184:#if LWIP_CALLBACK_API || TCP_LISTEN_BACKLOG
tcp.c:185:  size_t i;
tcp.c:186:  LWIP_ASSERT("pcb != NULL", pcb != NULL);
tcp.c:187:  LWIP_ASSERT("pcb->state == LISTEN", pcb->state == LISTEN);
tcp.c:188:  for (i = 1; i < LWIP_ARRAYSIZE(tcp_pcb_lists); i++) {
tcp.c:189:    tcp_remove_listener(*tcp_pcb_lists[i], (struct tcp_pcb_listen*)pcb);
tcp.c:190:  }
tcp.c:191:#endif
tcp.c:192:  LWIP_UNUSED_ARG(pcb);
tcp.c:193:}
tcp.c:194:
tcp.c:195:#if TCP_LISTEN_BACKLOG
tcp.c:196:/** @ingroup tcp_raw
tcp.c:197: * Delay accepting a connection in respect to the listen backlog:
tcp.c:198: * the number of outstanding connections is increased until
tcp.c:199: * tcp_backlog_accepted() is called.
tcp.c:200: *
tcp.c:201: * ATTENTION: the caller is responsible for calling tcp_backlog_accepted()
tcp.c:202: * or else the backlog feature will get out of sync!
tcp.c:203: *
tcp.c:204: * @param pcb the connection pcb which is not fully accepted yet
tcp.c:205: */
tcp.c:206:void
tcp.c:207:tcp_backlog_delayed(struct tcp_pcb* pcb)
tcp.c:208:{
tcp.c:209:  LWIP_ASSERT("pcb != NULL", pcb != NULL);
tcp.c:210:  if ((pcb->flags & TF_BACKLOGPEND) == 0) {
tcp.c:211:    if (pcb->listener != NULL) {
tcp.c:212:      pcb->listener->accepts_pending++;
tcp.c:213:      LWIP_ASSERT("accepts_pending != 0", pcb->listener->accepts_pending != 0);
tcp.c:214:      pcb->flags |= TF_BACKLOGPEND;
tcp.c:215:    }
tcp.c:216:  }
tcp.c:217:}
tcp.c:218:
tcp.c:219:/** @ingroup tcp_raw
tcp.c:220: * A delayed-accept a connection is accepted (or closed/aborted): decreases
tcp.c:221: * the number of outstanding connections after calling tcp_backlog_delayed().
tcp.c:222: *
tcp.c:223: * ATTENTION: the caller is responsible for calling tcp_backlog_accepted()
tcp.c:224: * or else the backlog feature will get out of sync!
tcp.c:225: *
tcp.c:226: * @param pcb the connection pcb which is now fully accepted (or closed/aborted)
tcp.c:227: */
tcp.c:228:void
tcp.c:229:tcp_backlog_accepted(struct tcp_pcb* pcb)
tcp.c:230:{
tcp.c:231:  LWIP_ASSERT("pcb != NULL", pcb != NULL);
tcp.c:232:  if ((pcb->flags & TF_BACKLOGPEND) != 0) {
tcp.c:233:    if (pcb->listener != NULL) {
tcp.c:234:      LWIP_ASSERT("accepts_pending != 0", pcb->listener->accepts_pending != 0);
tcp.c:235:      pcb->listener->accepts_pending--;
tcp.c:236:      pcb->flags &= ~TF_BACKLOGPEND;
tcp.c:237:    }
tcp.c:238:  }
tcp.c:239:}
tcp.c:240:#endif /* TCP_LISTEN_BACKLOG */
tcp.c:241:
tcp.c:242:/**
tcp.c:243: * Closes the TX side of a connection held by the PCB.
tcp.c:244: * For tcp_close(), a RST is sent if the application didn't receive all data
tcp.c:245: * (tcp_recved() not called for all data passed to recv callback).
tcp.c:246: *
tcp.c:247: * Listening pcbs are freed and may not be referenced any more.
tcp.c:248: * Connection pcbs are freed if not yet connected and may not be referenced
tcp.c:249: * any more. If a connection is established (at least SYN received or in
tcp.c:250: * a closing state), the connection is closed, and put in a closing state.
tcp.c:251: * The pcb is then automatically freed in tcp_slowtmr(). It is therefore
tcp.c:252: * unsafe to reference it.
tcp.c:253: *
tcp.c:254: * @param pcb the tcp_pcb to close
tcp.c:255: * @return ERR_OK if connection has been closed
tcp.c:256: *         another err_t if closing failed and pcb is not freed
tcp.c:257: */
tcp.c:258:static err_t
tcp.c:259:tcp_close_shutdown(struct tcp_pcb *pcb, u8_t rst_on_unacked_data)
tcp.c:260:{
tcp.c:261:  err_t err;
tcp.c:262:
tcp.c:263:  if (rst_on_unacked_data && ((pcb->state == ESTABLISHED) || (pcb->state == CLOSE_WAIT))) {
tcp.c:264:    if ((pcb->refused_data != NULL) || (pcb->rcv_wnd != TCP_WND_MAX(pcb))) {
tcp.c:265:      /* Not all data received by application, send RST to tell the remote
tcp.c:266:         side about this. */
tcp.c:267:      LWIP_ASSERT("pcb->flags & TF_RXCLOSED", pcb->flags & TF_RXCLOSED);
tcp.c:268:
tcp.c:269:      /* don't call tcp_abort here: we must not deallocate the pcb since
tcp.c:270:         that might not be expected when calling tcp_close */
tcp.c:271:      tcp_rst(pcb->snd_nxt, pcb->rcv_nxt, &pcb->local_ip, &pcb->remote_ip,
tcp.c:272:               pcb->local_port, pcb->remote_port);
tcp.c:273:
tcp.c:274:      tcp_pcb_purge(pcb);
tcp.c:275:      TCP_RMV_ACTIVE(pcb);
tcp.c:276:      if (pcb->state == ESTABLISHED) {
tcp.c:277:        /* move to TIME_WAIT since we close actively */
tcp.c:278:        pcb->state = TIME_WAIT;
tcp.c:279:        TCP_REG(&tcp_tw_pcbs, pcb);
tcp.c:280:      } else {
tcp.c:281:        /* CLOSE_WAIT: deallocate the pcb since we already sent a RST for it */
tcp.c:282:        if (tcp_input_pcb == pcb) {
tcp.c:283:          /* prevent using a deallocated pcb: free it from tcp_input later */
tcp.c:284:          tcp_trigger_input_pcb_close();
tcp.c:285:        } else {
tcp.c:286:          memp_free(MEMP_TCP_PCB, pcb);
tcp.c:287:        }
tcp.c:288:      }
tcp.c:289:      return ERR_OK;
tcp.c:290:    }
tcp.c:291:  }
tcp.c:292:
tcp.c:293:  switch (pcb->state) {
tcp.c:294:  case CLOSED:
tcp.c:295:    /* Closing a pcb in the CLOSED state might seem erroneous,
tcp.c:296:     * however, it is in this state once allocated and as yet unused
tcp.c:297:     * and the user needs some way to free it should the need arise.
tcp.c:298:     * Calling tcp_close() with a pcb that has already been closed, (i.e. twice)
tcp.c:299:     * or for a pcb that has been used and then entered the CLOSED state
tcp.c:300:     * is erroneous, but this should never happen as the pcb has in those cases
tcp.c:301:     * been freed, and so any remaining handles are bogus. */
tcp.c:302:    err = ERR_OK;
tcp.c:303:    if (pcb->local_port != 0) {
tcp.c:304:      TCP_RMV(&tcp_bound_pcbs, pcb);
tcp.c:305:    }
tcp.c:306:    memp_free(MEMP_TCP_PCB, pcb);
tcp.c:307:    pcb = NULL;
tcp.c:308:    break;
tcp.c:309:  case LISTEN:
tcp.c:310:    err = ERR_OK;
tcp.c:311:    tcp_listen_closed(pcb);
tcp.c:312:    tcp_pcb_remove(&tcp_listen_pcbs.pcbs, pcb);
tcp.c:313:    memp_free(MEMP_TCP_PCB_LISTEN, pcb);
tcp.c:314:    pcb = NULL;
tcp.c:315:    break;
tcp.c:316:  case SYN_SENT:
tcp.c:317:    err = ERR_OK;
tcp.c:318:    TCP_PCB_REMOVE_ACTIVE(pcb);
tcp.c:319:    memp_free(MEMP_TCP_PCB, pcb);
tcp.c:320:    pcb = NULL;
tcp.c:321:    MIB2_STATS_INC(mib2.tcpattemptfails);
tcp.c:322:    break;
tcp.c:323:  case SYN_RCVD:
tcp.c:324:    err = tcp_send_fin(pcb);
tcp.c:325:    if (err == ERR_OK) {
tcp.c:326:      tcp_backlog_accepted(pcb);
tcp.c:327:      MIB2_STATS_INC(mib2.tcpattemptfails);
tcp.c:328:      pcb->state = FIN_WAIT_1;
tcp.c:329:    }
tcp.c:330:    break;
tcp.c:331:  case ESTABLISHED:
tcp.c:332:    err = tcp_send_fin(pcb);
tcp.c:333:    if (err == ERR_OK) {
tcp.c:334:      MIB2_STATS_INC(mib2.tcpestabresets);
tcp.c:335:      pcb->state = FIN_WAIT_1;
tcp.c:336:    }
tcp.c:337:    break;
tcp.c:338:  case CLOSE_WAIT:
tcp.c:339:    err = tcp_send_fin(pcb);
tcp.c:340:    if (err == ERR_OK) {
tcp.c:341:      MIB2_STATS_INC(mib2.tcpestabresets);
tcp.c:342:      pcb->state = LAST_ACK;
tcp.c:343:    }
tcp.c:344:    break;
tcp.c:345:  default:
tcp.c:346:    /* Has already been closed, do nothing. */
tcp.c:347:    err = ERR_OK;
tcp.c:348:    pcb = NULL;
tcp.c:349:    break;
tcp.c:350:  }
tcp.c:351:
tcp.c:352:  if (pcb != NULL && err == ERR_OK) {
tcp.c:353:    /* To ensure all data has been sent when tcp_close returns, we have
tcp.c:354:       to make sure tcp_output doesn't fail.
tcp.c:355:       Since we don't really have to ensure all data has been sent when tcp_close
tcp.c:356:       returns (unsent data is sent from tcp timer functions, also), we don't care
tcp.c:357:       for the return value of tcp_output for now. */
tcp.c:358:    tcp_output(pcb);
tcp.c:359:  }
tcp.c:360:  return err;
tcp.c:361:}
tcp.c:362:
tcp.c:363:/**
tcp.c:364: * @ingroup tcp_raw
tcp.c:365: * Closes the connection held by the PCB.
tcp.c:366: *
tcp.c:367: * Listening pcbs are freed and may not be referenced any more.
tcp.c:368: * Connection pcbs are freed if not yet connected and may not be referenced
tcp.c:369: * any more. If a connection is established (at least SYN received or in
tcp.c:370: * a closing state), the connection is closed, and put in a closing state.
tcp.c:371: * The pcb is then automatically freed in tcp_slowtmr(). It is therefore
tcp.c:372: * unsafe to reference it (unless an error is returned).
tcp.c:373: *
tcp.c:374: * @param pcb the tcp_pcb to close
tcp.c:375: * @return ERR_OK if connection has been closed
tcp.c:376: *         another err_t if closing failed and pcb is not freed
tcp.c:377: */
tcp.c:378:err_t
tcp.c:379:tcp_close(struct tcp_pcb *pcb)
tcp.c:380:{
tcp.c:381:  LWIP_DEBUGF(TCP_DEBUG, ("tcp_close: closing in "));
tcp.c:382:  tcp_debug_print_state(pcb->state);
tcp.c:383:
tcp.c:384:  if (pcb->state != LISTEN) {
tcp.c:385:    /* Set a flag not to receive any more data... */
tcp.c:386:    pcb->flags |= TF_RXCLOSED;
tcp.c:387:  }
tcp.c:388:  /* ... and close */
tcp.c:389:  return tcp_close_shutdown(pcb, 1);
tcp.c:390:}
tcp.c:391:
tcp.c:392:/**
tcp.c:393: * @ingroup tcp_raw
tcp.c:394: * Causes all or part of a full-duplex connection of this PCB to be shut down.
tcp.c:395: * This doesn't deallocate the PCB unless shutting down both sides!
tcp.c:396: * Shutting down both sides is the same as calling tcp_close, so if it succeds,
tcp.c:397: * the PCB should not be referenced any more.
tcp.c:398: *
tcp.c:399: * @param pcb PCB to shutdown
tcp.c:400: * @param shut_rx shut down receive side if this is != 0
tcp.c:401: * @param shut_tx shut down send side if this is != 0
tcp.c:402: * @return ERR_OK if shutdown succeeded (or the PCB has already been shut down)
tcp.c:403: *         another err_t on error.
tcp.c:404: */
tcp.c:405:err_t
tcp.c:406:tcp_shutdown(struct tcp_pcb *pcb, int shut_rx, int shut_tx)
tcp.c:407:{
tcp.c:408:  if (pcb->state == LISTEN) {
tcp.c:409:    return ERR_CONN;
tcp.c:410:  }
tcp.c:411:  if (shut_rx) {
tcp.c:412:    /* shut down the receive side: set a flag not to receive any more data... */
tcp.c:413:    pcb->flags |= TF_RXCLOSED;
tcp.c:414:    if (shut_tx) {
tcp.c:415:      /* shutting down the tx AND rx side is the same as closing for the raw API */
tcp.c:416:      return tcp_close_shutdown(pcb, 1);
tcp.c:417:    }
tcp.c:418:    /* ... and free buffered data */
tcp.c:419:    if (pcb->refused_data != NULL) {
tcp.c:420:      pbuf_free(pcb->refused_data);
tcp.c:421:      pcb->refused_data = NULL;
tcp.c:422:    }
tcp.c:423:  }
tcp.c:424:  if (shut_tx) {
tcp.c:425:    /* This can't happen twice since if it succeeds, the pcb's state is changed.
tcp.c:426:       Only close in these states as the others directly deallocate the PCB */
tcp.c:427:    switch (pcb->state) {
tcp.c:428:    case SYN_RCVD:
tcp.c:429:    case ESTABLISHED:
tcp.c:430:    case CLOSE_WAIT:
tcp.c:431:      return tcp_close_shutdown(pcb, (u8_t)shut_rx);
tcp.c:432:    default:
tcp.c:433:      /* Not (yet?) connected, cannot shutdown the TX side as that would bring us
tcp.c:434:        into CLOSED state, where the PCB is deallocated. */
tcp.c:435:      return ERR_CONN;
tcp.c:436:    }
tcp.c:437:  }
tcp.c:438:  return ERR_OK;
tcp.c:439:}
tcp.c:440:
tcp.c:441:/**
tcp.c:442: * Abandons a connection and optionally sends a RST to the remote
tcp.c:443: * host.  Deletes the local protocol control block. This is done when
tcp.c:444: * a connection is killed because of shortage of memory.
tcp.c:445: *
tcp.c:446: * @param pcb the tcp_pcb to abort
tcp.c:447: * @param reset boolean to indicate whether a reset should be sent
tcp.c:448: */
tcp.c:449:void
tcp.c:450:tcp_abandon(struct tcp_pcb *pcb, int reset)
tcp.c:451:{
tcp.c:452:  u32_t seqno, ackno;
tcp.c:453:#if LWIP_CALLBACK_API
tcp.c:454:  tcp_err_fn errf;
tcp.c:455:#endif /* LWIP_CALLBACK_API */
tcp.c:456:  void *errf_arg;
tcp.c:457:
tcp.c:458:  /* pcb->state LISTEN not allowed here */
tcp.c:459:  LWIP_ASSERT("don't call tcp_abort/tcp_abandon for listen-pcbs",
tcp.c:460:    pcb->state != LISTEN);
tcp.c:461:  /* Figure out on which TCP PCB list we are, and remove us. If we
tcp.c:462:     are in an active state, call the receive function associated with
tcp.c:463:     the PCB with a NULL argument, and send an RST to the remote end. */
tcp.c:464:  if (pcb->state == TIME_WAIT) {
tcp.c:465:    tcp_pcb_remove(&tcp_tw_pcbs, pcb);
tcp.c:466:    memp_free(MEMP_TCP_PCB, pcb);
tcp.c:467:  } else {
tcp.c:468:    int send_rst = 0;
tcp.c:469:    u16_t local_port = 0;
tcp.c:470:    seqno = pcb->snd_nxt;
tcp.c:471:    ackno = pcb->rcv_nxt;
tcp.c:472:#if LWIP_CALLBACK_API
tcp.c:473:    errf = pcb->errf;
tcp.c:474:#endif /* LWIP_CALLBACK_API */
tcp.c:475:    errf_arg = pcb->callback_arg;
tcp.c:476:    if (pcb->state == CLOSED) {
tcp.c:477:      if (pcb->local_port != 0) {
tcp.c:478:        /* bound, not yet opened */
tcp.c:479:        TCP_RMV(&tcp_bound_pcbs, pcb);
tcp.c:480:      }
tcp.c:481:    } else {
tcp.c:482:      send_rst = reset;
tcp.c:483:      local_port = pcb->local_port;
tcp.c:484:      TCP_PCB_REMOVE_ACTIVE(pcb);
tcp.c:485:    }
tcp.c:486:    if (pcb->unacked != NULL) {
tcp.c:487:      tcp_segs_free(pcb->unacked);
tcp.c:488:    }
tcp.c:489:    if (pcb->unsent != NULL) {
tcp.c:490:      tcp_segs_free(pcb->unsent);
tcp.c:491:    }
tcp.c:492:#if TCP_QUEUE_OOSEQ
tcp.c:493:    if (pcb->ooseq != NULL) {
tcp.c:494:      tcp_segs_free(pcb->ooseq);
tcp.c:495:    }
tcp.c:496:#endif /* TCP_QUEUE_OOSEQ */
tcp.c:497:    tcp_backlog_accepted(pcb);
tcp.c:498:    if (send_rst) {
tcp.c:499:      LWIP_DEBUGF(TCP_RST_DEBUG, ("tcp_abandon: sending RST\n"));
tcp.c:500:      tcp_rst(seqno, ackno, &pcb->local_ip, &pcb->remote_ip, local_port, pcb->remote_port);
tcp.c:501:    }
tcp.c:502:    memp_free(MEMP_TCP_PCB, pcb);
tcp.c:503:    TCP_EVENT_ERR(errf, errf_arg, ERR_ABRT);
tcp.c:504:  }
tcp.c:505:}
tcp.c:506:
tcp.c:507:/**
tcp.c:508: * @ingroup tcp_raw
tcp.c:509: * Aborts the connection by sending a RST (reset) segment to the remote
tcp.c:510: * host. The pcb is deallocated. This function never fails.
tcp.c:511: *
tcp.c:512: * ATTENTION: When calling this from one of the TCP callbacks, make
tcp.c:513: * sure you always return ERR_ABRT (and never return ERR_ABRT otherwise
tcp.c:514: * or you will risk accessing deallocated memory or memory leaks!
tcp.c:515: *
tcp.c:516: * @param pcb the tcp pcb to abort
tcp.c:517: */
tcp.c:518:void
tcp.c:519:tcp_abort(struct tcp_pcb *pcb)
tcp.c:520:{
tcp.c:521:  tcp_abandon(pcb, 1);
tcp.c:522:}
tcp.c:523:
tcp.c:524:/**
tcp.c:525: * @ingroup tcp_raw
tcp.c:526: * Binds the connection to a local port number and IP address. If the
tcp.c:527: * IP address is not given (i.e., ipaddr == NULL), the IP address of
tcp.c:528: * the outgoing network interface is used instead.
tcp.c:529: *
tcp.c:530: * @param pcb the tcp_pcb to bind (no check is done whether this pcb is
tcp.c:531: *        already bound!)
tcp.c:532: * @param ipaddr the local ip address to bind to (use IP4_ADDR_ANY to bind
tcp.c:533: *        to any local address
tcp.c:534: * @param port the local port to bind to
tcp.c:535: * @return ERR_USE if the port is already in use
tcp.c:536: *         ERR_VAL if bind failed because the PCB is not in a valid state
tcp.c:537: *         ERR_OK if bound
tcp.c:538: */
tcp.c:539:err_t
tcp.c:540:tcp_bind(struct tcp_pcb *pcb, const ip_addr_t *ipaddr, u16_t port)
tcp.c:541:{
tcp.c:542:  int i;
tcp.c:543:  int max_pcb_list = NUM_TCP_PCB_LISTS;
tcp.c:544:  struct tcp_pcb *cpcb;
tcp.c:545:
tcp.c:546:#if LWIP_IPV4
tcp.c:547:  /* Don't propagate NULL pointer (IPv4 ANY) to subsequent functions */
tcp.c:548:  if (ipaddr == NULL) {
tcp.c:549:    ipaddr = IP4_ADDR_ANY;
tcp.c:550:  }
tcp.c:551:#endif /* LWIP_IPV4 */
tcp.c:552:
tcp.c:553:  /* still need to check for ipaddr == NULL in IPv6 only case */
tcp.c:554:  if ((pcb == NULL) || (ipaddr == NULL) || !IP_ADDR_PCB_VERSION_MATCH_EXACT(pcb, ipaddr)) {
tcp.c:555:    return ERR_VAL;
tcp.c:556:  }
tcp.c:557:
tcp.c:558:  LWIP_ERROR("tcp_bind: can only bind in state CLOSED", pcb->state == CLOSED, return ERR_VAL);
tcp.c:559:
tcp.c:560:#if SO_REUSE
tcp.c:561:  /* Unless the REUSEADDR flag is set,
tcp.c:562:     we have to check the pcbs in TIME-WAIT state, also.
tcp.c:563:     We do not dump TIME_WAIT pcb's; they can still be matched by incoming
tcp.c:564:     packets using both local and remote IP addresses and ports to distinguish.
tcp.c:565:   */
tcp.c:566:  if (ip_get_option(pcb, SOF_REUSEADDR)) {
tcp.c:567:    max_pcb_list = NUM_TCP_PCB_LISTS_NO_TIME_WAIT;
tcp.c:568:  }
tcp.c:569:#endif /* SO_REUSE */
tcp.c:570:
tcp.c:571:  if (port == 0) {
tcp.c:572:    port = tcp_new_port();
tcp.c:573:    if (port == 0) {
tcp.c:574:      return ERR_BUF;
tcp.c:575:    }
tcp.c:576:  } else {
tcp.c:577:    /* Check if the address already is in use (on all lists) */
tcp.c:578:    for (i = 0; i < max_pcb_list; i++) {
tcp.c:579:      for (cpcb = *tcp_pcb_lists[i]; cpcb != NULL; cpcb = cpcb->next) {
tcp.c:580:        if (cpcb->local_port == port) {
tcp.c:581:#if SO_REUSE
tcp.c:582:          /* Omit checking for the same port if both pcbs have REUSEADDR set.
tcp.c:583:             For SO_REUSEADDR, the duplicate-check for a 5-tuple is done in
tcp.c:584:             tcp_connect. */
tcp.c:585:          if (!ip_get_option(pcb, SOF_REUSEADDR) ||
tcp.c:586:              !ip_get_option(cpcb, SOF_REUSEADDR))
tcp.c:587:#endif /* SO_REUSE */
tcp.c:588:          {
tcp.c:589:            /* @todo: check accept_any_ip_version */
tcp.c:590:            if ((IP_IS_V6(ipaddr) == IP_IS_V6_VAL(cpcb->local_ip)) &&
tcp.c:591:                (ip_addr_isany(&cpcb->local_ip) ||
tcp.c:592:                ip_addr_isany(ipaddr) ||
tcp.c:593:                ip_addr_cmp(&cpcb->local_ip, ipaddr))) {
tcp.c:594:              return ERR_USE;
tcp.c:595:            }
tcp.c:596:          }
tcp.c:597:        }
tcp.c:598:      }
tcp.c:599:    }
tcp.c:600:  }
tcp.c:601:
tcp.c:602:  if (!ip_addr_isany(ipaddr)) {
tcp.c:603:    ip_addr_set(&pcb->local_ip, ipaddr);
tcp.c:604:  }
tcp.c:605:  pcb->local_port = port;
tcp.c:606:  TCP_REG(&tcp_bound_pcbs, pcb);
tcp.c:607:  LWIP_DEBUGF(TCP_DEBUG, ("tcp_bind: bind to port %"U16_F"\n", port));
tcp.c:608:  return ERR_OK;
tcp.c:609:}
tcp.c:610:#if LWIP_CALLBACK_API
tcp.c:611:/**
tcp.c:612: * Default accept callback if no accept callback is specified by the user.
tcp.c:613: */
tcp.c:614:static err_t
tcp.c:615:tcp_accept_null(void *arg, struct tcp_pcb *pcb, err_t err)
tcp.c:616:{
tcp.c:617:  LWIP_UNUSED_ARG(arg);
tcp.c:618:  LWIP_UNUSED_ARG(err);
tcp.c:619:
tcp.c:620:  tcp_abort(pcb);
tcp.c:621:
tcp.c:622:  return ERR_ABRT;
tcp.c:623:}
tcp.c:624:#endif /* LWIP_CALLBACK_API */
tcp.c:625:
tcp.c:626:/**
tcp.c:627: * @ingroup tcp_raw
tcp.c:628: * Set the state of the connection to be LISTEN, which means that it
tcp.c:629: * is able to accept incoming connections. The protocol control block
tcp.c:630: * is reallocated in order to consume less memory. Setting the
tcp.c:631: * connection to LISTEN is an irreversible process.
tcp.c:632: *
tcp.c:633: * @param pcb the original tcp_pcb
tcp.c:634: * @param backlog the incoming connections queue limit
tcp.c:635: * @return tcp_pcb used for listening, consumes less memory.
tcp.c:636: *
tcp.c:637: * @note The original tcp_pcb is freed. This function therefore has to be
tcp.c:638: *       called like this:
tcp.c:639: *             tpcb = tcp_listen(tpcb);
tcp.c:640: */
tcp.c:641:struct tcp_pcb *
tcp.c:642:tcp_listen_with_backlog(struct tcp_pcb *pcb, u8_t backlog)
tcp.c:643:{
tcp.c:644:  struct tcp_pcb_listen *lpcb;
tcp.c:645:
tcp.c:646:  LWIP_UNUSED_ARG(backlog);
tcp.c:647:  LWIP_ERROR("tcp_listen: pcb already connected", pcb->state == CLOSED, return NULL);
tcp.c:648:
tcp.c:649:  /* already listening? */
tcp.c:650:  if (pcb->state == LISTEN) {
tcp.c:651:    return pcb;
tcp.c:652:  }
tcp.c:653:#if SO_REUSE
tcp.c:654:  if (ip_get_option(pcb, SOF_REUSEADDR)) {
tcp.c:655:    /* Since SOF_REUSEADDR allows reusing a local address before the pcb's usage
tcp.c:656:       is declared (listen-/connection-pcb), we have to make sure now that
tcp.c:657:       this port is only used once for every local IP. */
tcp.c:658:    for (lpcb = tcp_listen_pcbs.listen_pcbs; lpcb != NULL; lpcb = lpcb->next) {
tcp.c:659:      if ((lpcb->local_port == pcb->local_port) &&
tcp.c:660:          ip_addr_cmp(&lpcb->local_ip, &pcb->local_ip)) {
tcp.c:661:        /* this address/port is already used */
tcp.c:662:        return NULL;
tcp.c:663:      }
tcp.c:664:    }
tcp.c:665:  }
tcp.c:666:#endif /* SO_REUSE */
tcp.c:667:  lpcb = (struct tcp_pcb_listen *)memp_malloc(MEMP_TCP_PCB_LISTEN);
tcp.c:668:  if (lpcb == NULL) {
tcp.c:669:    return NULL;
tcp.c:670:  }
tcp.c:671:  lpcb->callback_arg = pcb->callback_arg;
tcp.c:672:  lpcb->local_port = pcb->local_port;
tcp.c:673:  lpcb->state = LISTEN;
tcp.c:674:  lpcb->prio = pcb->prio;
tcp.c:675:  lpcb->so_options = pcb->so_options;
tcp.c:676:  lpcb->ttl = pcb->ttl;
tcp.c:677:  lpcb->tos = pcb->tos;
tcp.c:678:#if LWIP_IPV4 && LWIP_IPV6
tcp.c:679:  IP_SET_TYPE_VAL(lpcb->remote_ip, pcb->local_ip.type);
tcp.c:680:#endif /* LWIP_IPV4 && LWIP_IPV6 */
tcp.c:681:  ip_addr_copy(lpcb->local_ip, pcb->local_ip);
tcp.c:682:  if (pcb->local_port != 0) {
tcp.c:683:    TCP_RMV(&tcp_bound_pcbs, pcb);
tcp.c:684:  }
tcp.c:685:  memp_free(MEMP_TCP_PCB, pcb);
tcp.c:686:#if LWIP_CALLBACK_API
tcp.c:687:  lpcb->accept = tcp_accept_null;
tcp.c:688:#endif /* LWIP_CALLBACK_API */
tcp.c:689:#if TCP_LISTEN_BACKLOG
tcp.c:690:  lpcb->accepts_pending = 0;
tcp.c:691:  tcp_backlog_set(lpcb, backlog);
tcp.c:692:#endif /* TCP_LISTEN_BACKLOG */
tcp.c:693:  TCP_REG(&tcp_listen_pcbs.pcbs, (struct tcp_pcb *)lpcb);
tcp.c:694:  return (struct tcp_pcb *)lpcb;
tcp.c:695:}
tcp.c:696:
tcp.c:697:/**
tcp.c:698: * Update the state that tracks the available window space to advertise.
tcp.c:699: *
tcp.c:700: * Returns how much extra window would be advertised if we sent an
tcp.c:701: * update now.
tcp.c:702: */
tcp.c:703:u32_t
tcp.c:704:tcp_update_rcv_ann_wnd(struct tcp_pcb *pcb)
tcp.c:705:{
tcp.c:706:  u32_t new_right_edge = pcb->rcv_nxt + pcb->rcv_wnd;
tcp.c:707:
tcp.c:708:  if (TCP_SEQ_GEQ(new_right_edge, pcb->rcv_ann_right_edge + LWIP_MIN((TCP_WND / 2), pcb->mss))) {
tcp.c:709:    /* we can advertise more window */
tcp.c:710:    pcb->rcv_ann_wnd = pcb->rcv_wnd;
tcp.c:711:    return new_right_edge - pcb->rcv_ann_right_edge;
tcp.c:712:  } else {
tcp.c:713:    if (TCP_SEQ_GT(pcb->rcv_nxt, pcb->rcv_ann_right_edge)) {
tcp.c:714:      /* Can happen due to other end sending out of advertised window,
tcp.c:715:       * but within actual available (but not yet advertised) window */
tcp.c:716:      pcb->rcv_ann_wnd = 0;
tcp.c:717:    } else {
tcp.c:718:      /* keep the right edge of window constant */
tcp.c:719:      u32_t new_rcv_ann_wnd = pcb->rcv_ann_right_edge - pcb->rcv_nxt;
tcp.c:720:#if !LWIP_WND_SCALE
tcp.c:721:      LWIP_ASSERT("new_rcv_ann_wnd <= 0xffff", new_rcv_ann_wnd <= 0xffff);
tcp.c:722:#endif
tcp.c:723:      pcb->rcv_ann_wnd = (tcpwnd_size_t)new_rcv_ann_wnd;
tcp.c:724:    }
tcp.c:725:    return 0;
tcp.c:726:  }
tcp.c:727:}
tcp.c:728:
tcp.c:729:/**
tcp.c:730: * @ingroup tcp_raw
tcp.c:731: * This function should be called by the application when it has
tcp.c:732: * processed the data. The purpose is to advertise a larger window
tcp.c:733: * when the data has been processed.
tcp.c:734: *
tcp.c:735: * @param pcb the tcp_pcb for which data is read
tcp.c:736: * @param len the amount of bytes that have been read by the application
tcp.c:737: */
tcp.c:738:void
tcp.c:739:tcp_recved(struct tcp_pcb *pcb, u16_t len)
tcp.c:740:{
tcp.c:741:  int wnd_inflation;
tcp.c:742:
tcp.c:743:  /* pcb->state LISTEN not allowed here */
tcp.c:744:  LWIP_ASSERT("don't call tcp_recved for listen-pcbs",
tcp.c:745:    pcb->state != LISTEN);
tcp.c:746:
tcp.c:747:  pcb->rcv_wnd += len;
tcp.c:748:  if (pcb->rcv_wnd > TCP_WND_MAX(pcb)) {
tcp.c:749:    pcb->rcv_wnd = TCP_WND_MAX(pcb);
tcp.c:750:  } else if (pcb->rcv_wnd == 0) {
tcp.c:751:    /* rcv_wnd overflowed */
tcp.c:752:    if ((pcb->state == CLOSE_WAIT) || (pcb->state == LAST_ACK)) {
tcp.c:753:      /* In passive close, we allow this, since the FIN bit is added to rcv_wnd
tcp.c:754:         by the stack itself, since it is not mandatory for an application
tcp.c:755:         to call tcp_recved() for the FIN bit, but e.g. the netconn API does so. */
tcp.c:756:      pcb->rcv_wnd = TCP_WND_MAX(pcb);
tcp.c:757:    } else {
tcp.c:758:      LWIP_ASSERT("tcp_recved: len wrapped rcv_wnd\n", 0);
tcp.c:759:    }
tcp.c:760:  }
tcp.c:761:
tcp.c:762:  wnd_inflation = tcp_update_rcv_ann_wnd(pcb);
tcp.c:763:
tcp.c:764:  /* If the change in the right edge of window is significant (default
tcp.c:765:   * watermark is TCP_WND/4), then send an explicit update now.
tcp.c:766:   * Otherwise wait for a packet to be sent in the normal course of
tcp.c:767:   * events (or more window to be available later) */
tcp.c:768:  if (wnd_inflation >= TCP_WND_UPDATE_THRESHOLD) {
tcp.c:769:    tcp_ack_now(pcb);
tcp.c:770:    tcp_output(pcb);
tcp.c:771:  }
tcp.c:772:
tcp.c:773:  LWIP_DEBUGF(TCP_DEBUG, ("tcp_recved: received %"U16_F" bytes, wnd %"TCPWNDSIZE_F" (%"TCPWNDSIZE_F").\n",
tcp.c:774:         len, pcb->rcv_wnd, (u16_t)(TCP_WND_MAX(pcb) - pcb->rcv_wnd)));
tcp.c:775:}
tcp.c:776:
tcp.c:777:/**
tcp.c:778: * Allocate a new local TCP port.
tcp.c:779: *
tcp.c:780: * @return a new (free) local TCP port number
tcp.c:781: */
tcp.c:782:static u16_t
tcp.c:783:tcp_new_port(void)
tcp.c:784:{
tcp.c:785:  u8_t i;
tcp.c:786:  u16_t n = 0;
tcp.c:787:  struct tcp_pcb *pcb;
tcp.c:788:
tcp.c:789:again:
tcp.c:790:  if (tcp_port++ == TCP_LOCAL_PORT_RANGE_END) {
tcp.c:791:    tcp_port = TCP_LOCAL_PORT_RANGE_START;
tcp.c:792:  }
tcp.c:793:  /* Check all PCB lists. */
tcp.c:794:  for (i = 0; i < NUM_TCP_PCB_LISTS; i++) {
tcp.c:795:    for (pcb = *tcp_pcb_lists[i]; pcb != NULL; pcb = pcb->next) {
tcp.c:796:      if (pcb->local_port == tcp_port) {
tcp.c:797:        if (++n > (TCP_LOCAL_PORT_RANGE_END - TCP_LOCAL_PORT_RANGE_START)) {
tcp.c:798:          return 0;
tcp.c:799:        }
tcp.c:800:        goto again;
tcp.c:801:      }
tcp.c:802:    }
tcp.c:803:  }
tcp.c:804:  return tcp_port;
tcp.c:805:}
tcp.c:806:
tcp.c:807:/**
tcp.c:808: * @ingroup tcp_raw
tcp.c:809: * Connects to another host. The function given as the "connected"
tcp.c:810: * argument will be called when the connection has been established.
tcp.c:811: *
tcp.c:812: * @param pcb the tcp_pcb used to establish the connection
tcp.c:813: * @param ipaddr the remote ip address to connect to
tcp.c:814: * @param port the remote tcp port to connect to
tcp.c:815: * @param connected callback function to call when connected (on error,
tcp.c:816:                    the err calback will be called)
tcp.c:817: * @return ERR_VAL if invalid arguments are given
tcp.c:818: *         ERR_OK if connect request has been sent
tcp.c:819: *         other err_t values if connect request couldn't be sent
tcp.c:820: */
tcp.c:821:err_t
tcp.c:822:tcp_connect(struct tcp_pcb *pcb, const ip_addr_t *ipaddr, u16_t port,
tcp.c:823:      tcp_connected_fn connected)
tcp.c:824:{
tcp.c:825:  err_t ret;
tcp.c:826:  u32_t iss;
tcp.c:827:  u16_t old_local_port;
tcp.c:828:
tcp.c:829:  if ((pcb == NULL) || (ipaddr == NULL) || !IP_ADDR_PCB_VERSION_MATCH_EXACT(pcb, ipaddr)) {
tcp.c:830:    return ERR_VAL;
tcp.c:831:  }
tcp.c:832:
tcp.c:833:  LWIP_ERROR("tcp_connect: can only connect from state CLOSED", pcb->state == CLOSED, return ERR_ISCONN);
tcp.c:834:
tcp.c:835:  LWIP_DEBUGF(TCP_DEBUG, ("tcp_connect to port %"U16_F"\n", port));
tcp.c:836:  ip_addr_set(&pcb->remote_ip, ipaddr);
tcp.c:837:  pcb->remote_port = port;
tcp.c:838:
tcp.c:839:  /* check if we have a route to the remote host */
tcp.c:840:  if (ip_addr_isany(&pcb->local_ip)) {
tcp.c:841:    /* no local IP address set, yet. */
tcp.c:842:    struct netif *netif;
tcp.c:843:    const ip_addr_t *local_ip;
tcp.c:844:    ip_route_get_local_ip(&pcb->local_ip, &pcb->remote_ip, netif, local_ip);
tcp.c:845:    if ((netif == NULL) || (local_ip == NULL)) {
tcp.c:846:      /* Don't even try to send a SYN packet if we have no route
tcp.c:847:         since that will fail. */
tcp.c:848:      return ERR_RTE;
tcp.c:849:    }
tcp.c:850:    /* Use the address as local address of the pcb. */
tcp.c:851:    ip_addr_copy(pcb->local_ip, *local_ip);
tcp.c:852:  }
tcp.c:853:
tcp.c:854:  old_local_port = pcb->local_port;
tcp.c:855:  if (pcb->local_port == 0) {
tcp.c:856:    pcb->local_port = tcp_new_port();
tcp.c:857:    if (pcb->local_port == 0) {
tcp.c:858:      return ERR_BUF;
tcp.c:859:    }
tcp.c:860:  } else {
tcp.c:861:#if SO_REUSE
tcp.c:862:    if (ip_get_option(pcb, SOF_REUSEADDR)) {
tcp.c:863:      /* Since SOF_REUSEADDR allows reusing a local address, we have to make sure
tcp.c:864:         now that the 5-tuple is unique. */
tcp.c:865:      struct tcp_pcb *cpcb;
tcp.c:866:      int i;
tcp.c:867:      /* Don't check listen- and bound-PCBs, check active- and TIME-WAIT PCBs. */
tcp.c:868:      for (i = 2; i < NUM_TCP_PCB_LISTS; i++) {
tcp.c:869:        for (cpcb = *tcp_pcb_lists[i]; cpcb != NULL; cpcb = cpcb->next) {
tcp.c:870:          if ((cpcb->local_port == pcb->local_port) &&
tcp.c:871:              (cpcb->remote_port == port) &&
tcp.c:872:              ip_addr_cmp(&cpcb->local_ip, &pcb->local_ip) &&
tcp.c:873:              ip_addr_cmp(&cpcb->remote_ip, ipaddr)) {
tcp.c:874:            /* linux returns EISCONN here, but ERR_USE should be OK for us */
tcp.c:875:            return ERR_USE;
tcp.c:876:          }
tcp.c:877:        }
tcp.c:878:      }
tcp.c:879:    }
tcp.c:880:#endif /* SO_REUSE */
tcp.c:881:  }
tcp.c:882:
tcp.c:883:  iss = tcp_next_iss();
tcp.c:884:  pcb->rcv_nxt = 0;
tcp.c:885:  pcb->snd_nxt = iss;
tcp.c:886:  pcb->lastack = iss - 1;
tcp.c:887:  pcb->snd_lbb = iss - 1;
tcp.c:888:  /* Start with a window that does not need scaling. When window scaling is
tcp.c:889:     enabled and used, the window is enlarged when both sides agree on scaling. */
tcp.c:890:  pcb->rcv_wnd = pcb->rcv_ann_wnd = TCPWND_MIN16(TCP_WND);
tcp.c:891:  pcb->rcv_ann_right_edge = pcb->rcv_nxt;
tcp.c:892:  pcb->snd_wnd = TCP_WND;
tcp.c:893:  /* As initial send MSS, we use TCP_MSS but limit it to 536.
tcp.c:894:     The send MSS is updated when an MSS option is received. */
tcp.c:895:  pcb->mss = INITIAL_MSS;
tcp.c:896:#if TCP_CALCULATE_EFF_SEND_MSS
tcp.c:897:  pcb->mss = tcp_eff_send_mss(pcb->mss, &pcb->local_ip, &pcb->remote_ip);
tcp.c:898:#endif /* TCP_CALCULATE_EFF_SEND_MSS */
tcp.c:899:  pcb->cwnd = 1;
tcp.c:900:  pcb->ssthresh = TCP_WND;
tcp.c:901:#if LWIP_CALLBACK_API
tcp.c:902:  pcb->connected = connected;
tcp.c:903:#else /* LWIP_CALLBACK_API */
tcp.c:904:  LWIP_UNUSED_ARG(connected);
tcp.c:905:#endif /* LWIP_CALLBACK_API */
tcp.c:906:
tcp.c:907:  /* Send a SYN together with the MSS option. */
tcp.c:908:  ret = tcp_enqueue_flags(pcb, TCP_SYN);
tcp.c:909:  if (ret == ERR_OK) {
tcp.c:910:    /* SYN segment was enqueued, changed the pcbs state now */
tcp.c:911:    pcb->state = SYN_SENT;
tcp.c:912:    if (old_local_port != 0) {
tcp.c:913:      TCP_RMV(&tcp_bound_pcbs, pcb);
tcp.c:914:    }
tcp.c:915:    TCP_REG_ACTIVE(pcb);
tcp.c:916:    MIB2_STATS_INC(mib2.tcpactiveopens);
tcp.c:917:
tcp.c:918:    tcp_output(pcb);
tcp.c:919:  }
tcp.c:920:  return ret;
tcp.c:921:}
tcp.c:922:
tcp.c:923:/**
tcp.c:924: * Called every 500 ms and implements the retransmission timer and the timer that
tcp.c:925: * removes PCBs that have been in TIME-WAIT for enough time. It also increments
tcp.c:926: * various timers such as the inactivity timer in each PCB.
tcp.c:927: *
tcp.c:928: * Automatically called from tcp_tmr().
tcp.c:929: */
tcp.c:930:void
tcp.c:931:tcp_slowtmr(void)
tcp.c:932:{
tcp.c:933:  struct tcp_pcb *pcb, *prev;
tcp.c:934:  tcpwnd_size_t eff_wnd;
tcp.c:935:  u8_t pcb_remove;      /* flag if a PCB should be removed */
tcp.c:936:  u8_t pcb_reset;       /* flag if a RST should be sent when removing */
tcp.c:937:  err_t err;
tcp.c:938:
tcp.c:939:  err = ERR_OK;
tcp.c:940:
tcp.c:941:  ++tcp_ticks;
tcp.c:942:  ++tcp_timer_ctr;
tcp.c:943:
tcp.c:944:tcp_slowtmr_start:
tcp.c:945:  /* Steps through all of the active PCBs. */
tcp.c:946:  prev = NULL;
tcp.c:947:  pcb = tcp_active_pcbs;
tcp.c:948:  if (pcb == NULL) {
tcp.c:949:    LWIP_DEBUGF(TCP_DEBUG, ("tcp_slowtmr: no active pcbs\n"));
tcp.c:950:  }
tcp.c:951:  while (pcb != NULL) {
tcp.c:952:    LWIP_DEBUGF(TCP_DEBUG, ("tcp_slowtmr: processing active pcb\n"));
tcp.c:953:    LWIP_ASSERT("tcp_slowtmr: active pcb->state != CLOSED\n", pcb->state != CLOSED);
tcp.c:954:    LWIP_ASSERT("tcp_slowtmr: active pcb->state != LISTEN\n", pcb->state != LISTEN);
tcp.c:955:    LWIP_ASSERT("tcp_slowtmr: active pcb->state != TIME-WAIT\n", pcb->state != TIME_WAIT);
tcp.c:956:    if (pcb->last_timer == tcp_timer_ctr) {
tcp.c:957:      /* skip this pcb, we have already processed it */
tcp.c:958:      pcb = pcb->next;
tcp.c:959:      continue;
tcp.c:960:    }
tcp.c:961:    pcb->last_timer = tcp_timer_ctr;
tcp.c:962:
tcp.c:963:    pcb_remove = 0;
tcp.c:964:    pcb_reset = 0;
tcp.c:965:
tcp.c:966:    if (pcb->state == SYN_SENT && pcb->nrtx == TCP_SYNMAXRTX) {
tcp.c:967:      ++pcb_remove;
tcp.c:968:      LWIP_DEBUGF(TCP_DEBUG, ("tcp_slowtmr: max SYN retries reached\n"));
tcp.c:969:    }
tcp.c:970:    else if (pcb->nrtx == TCP_MAXRTX) {
tcp.c:971:      ++pcb_remove;
tcp.c:972:      LWIP_DEBUGF(TCP_DEBUG, ("tcp_slowtmr: max DATA retries reached\n"));
tcp.c:973:    } else {
tcp.c:974:      if (pcb->persist_backoff > 0) {
tcp.c:975:        /* If snd_wnd is zero, use persist timer to send 1 byte probes
tcp.c:976:         * instead of using the standard retransmission mechanism. */
tcp.c:977:        u8_t backoff_cnt = tcp_persist_backoff[pcb->persist_backoff-1];
tcp.c:978:        if (pcb->persist_cnt < backoff_cnt) {
tcp.c:979:          pcb->persist_cnt++;
tcp.c:980:        }
tcp.c:981:        if (pcb->persist_cnt >= backoff_cnt) {
tcp.c:982:          if (tcp_zero_window_probe(pcb) == ERR_OK) {
tcp.c:983:            pcb->persist_cnt = 0;
tcp.c:984:            if (pcb->persist_backoff < sizeof(tcp_persist_backoff)) {
tcp.c:985:              pcb->persist_backoff++;
tcp.c:986:            }
tcp.c:987:          }
tcp.c:988:        }
tcp.c:989:      } else {
tcp.c:990:        /* Increase the retransmission timer if it is running */
tcp.c:991:        if (pcb->rtime >= 0) {
tcp.c:992:          ++pcb->rtime;
tcp.c:993:        }
tcp.c:994:
tcp.c:995:        if (pcb->unacked != NULL && pcb->rtime >= pcb->rto) {
tcp.c:996:          /* Time for a retransmission. */
tcp.c:997:          LWIP_DEBUGF(TCP_RTO_DEBUG, ("tcp_slowtmr: rtime %"S16_F
tcp.c:998:                                      " pcb->rto %"S16_F"\n",
tcp.c:999:                                      pcb->rtime, pcb->rto));
tcp.c:1000:
tcp.c:1001:          /* Double retransmission time-out unless we are trying to
tcp.c:1002:           * connect to somebody (i.e., we are in SYN_SENT). */
tcp.c:1003:          if (pcb->state != SYN_SENT) {
tcp.c:1004:            pcb->rto = ((pcb->sa >> 3) + pcb->sv) << tcp_backoff[pcb->nrtx];
tcp.c:1005:          }
tcp.c:1006:
tcp.c:1007:          /* Reset the retransmission timer. */
tcp.c:1008:          pcb->rtime = 0;
tcp.c:1009:
tcp.c:1010:          /* Reduce congestion window and ssthresh. */
tcp.c:1011:          eff_wnd = LWIP_MIN(pcb->cwnd, pcb->snd_wnd);
tcp.c:1012:          pcb->ssthresh = eff_wnd >> 1;
tcp.c:1013:          if (pcb->ssthresh < (tcpwnd_size_t)(pcb->mss << 1)) {
tcp.c:1014:            pcb->ssthresh = (pcb->mss << 1);
tcp.c:1015:          }
tcp.c:1016:          pcb->cwnd = pcb->mss;
tcp.c:1017:          LWIP_DEBUGF(TCP_CWND_DEBUG, ("tcp_slowtmr: cwnd %"TCPWNDSIZE_F
tcp.c:1018:                                       " ssthresh %"TCPWNDSIZE_F"\n",
tcp.c:1019:                                       pcb->cwnd, pcb->ssthresh));
tcp.c:1020:
tcp.c:1021:          /* The following needs to be called AFTER cwnd is set to one
tcp.c:1022:             mss - STJ */
tcp.c:1023:          tcp_rexmit_rto(pcb);
tcp.c:1024:        }
tcp.c:1025:      }
tcp.c:1026:    }
tcp.c:1027:    /* Check if this PCB has stayed too long in FIN-WAIT-2 */
tcp.c:1028:    if (pcb->state == FIN_WAIT_2) {
tcp.c:1029:      /* If this PCB is in FIN_WAIT_2 because of SHUT_WR don't let it time out. */
tcp.c:1030:      if (pcb->flags & TF_RXCLOSED) {
tcp.c:1031:        /* PCB was fully closed (either through close() or SHUT_RDWR):
tcp.c:1032:           normal FIN-WAIT timeout handling. */
tcp.c:1033:        if ((u32_t)(tcp_ticks - pcb->tmr) >
tcp.c:1034:            TCP_FIN_WAIT_TIMEOUT / TCP_SLOW_INTERVAL) {
tcp.c:1035:          ++pcb_remove;
tcp.c:1036:          LWIP_DEBUGF(TCP_DEBUG, ("tcp_slowtmr: removing pcb stuck in FIN-WAIT-2\n"));
tcp.c:1037:        }
tcp.c:1038:      }
tcp.c:1039:    }
tcp.c:1040:
tcp.c:1041:    /* Check if KEEPALIVE should be sent */
tcp.c:1042:    if (ip_get_option(pcb, SOF_KEEPALIVE) &&
tcp.c:1043:       ((pcb->state == ESTABLISHED) ||
tcp.c:1044:        (pcb->state == CLOSE_WAIT))) {
tcp.c:1045:      if ((u32_t)(tcp_ticks - pcb->tmr) >
tcp.c:1046:         (pcb->keep_idle + TCP_KEEP_DUR(pcb)) / TCP_SLOW_INTERVAL)
tcp.c:1047:      {
tcp.c:1048:        LWIP_DEBUGF(TCP_DEBUG, ("tcp_slowtmr: KEEPALIVE timeout. Aborting connection to "));
tcp.c:1049:        ip_addr_debug_print(TCP_DEBUG, &pcb->remote_ip);
tcp.c:1050:        LWIP_DEBUGF(TCP_DEBUG, ("\n"));
tcp.c:1051:
tcp.c:1052:        ++pcb_remove;
tcp.c:1053:        ++pcb_reset;
tcp.c:1054:      } else if ((u32_t)(tcp_ticks - pcb->tmr) >
tcp.c:1055:                (pcb->keep_idle + pcb->keep_cnt_sent * TCP_KEEP_INTVL(pcb))
tcp.c:1056:                / TCP_SLOW_INTERVAL)
tcp.c:1057:      {
tcp.c:1058:        err = tcp_keepalive(pcb);
tcp.c:1059:        if (err == ERR_OK) {
tcp.c:1060:          pcb->keep_cnt_sent++;
tcp.c:1061:        }
tcp.c:1062:      }
tcp.c:1063:    }
tcp.c:1064:
tcp.c:1065:    /* If this PCB has queued out of sequence data, but has been
tcp.c:1066:       inactive for too long, will drop the data (it will eventually
tcp.c:1067:       be retransmitted). */
tcp.c:1068:#if TCP_QUEUE_OOSEQ
tcp.c:1069:    if (pcb->ooseq != NULL &&
tcp.c:1070:        (u32_t)tcp_ticks - pcb->tmr >= pcb->rto * TCP_OOSEQ_TIMEOUT) {
tcp.c:1071:      tcp_segs_free(pcb->ooseq);
tcp.c:1072:      pcb->ooseq = NULL;
tcp.c:1073:      LWIP_DEBUGF(TCP_CWND_DEBUG, ("tcp_slowtmr: dropping OOSEQ queued data\n"));
tcp.c:1074:    }
tcp.c:1075:#endif /* TCP_QUEUE_OOSEQ */
tcp.c:1076:
tcp.c:1077:    /* Check if this PCB has stayed too long in SYN-RCVD */
tcp.c:1078:    if (pcb->state == SYN_RCVD) {
tcp.c:1079:      if ((u32_t)(tcp_ticks - pcb->tmr) >
tcp.c:1080:          TCP_SYN_RCVD_TIMEOUT / TCP_SLOW_INTERVAL) {
tcp.c:1081:        ++pcb_remove;
tcp.c:1082:        LWIP_DEBUGF(TCP_DEBUG, ("tcp_slowtmr: removing pcb stuck in SYN-RCVD\n"));
tcp.c:1083:      }
tcp.c:1084:    }
tcp.c:1085:
tcp.c:1086:    /* Check if this PCB has stayed too long in LAST-ACK */
tcp.c:1087:    if (pcb->state == LAST_ACK) {
tcp.c:1088:      if ((u32_t)(tcp_ticks - pcb->tmr) > 2 * TCP_MSL / TCP_SLOW_INTERVAL) {
tcp.c:1089:        ++pcb_remove;
tcp.c:1090:        LWIP_DEBUGF(TCP_DEBUG, ("tcp_slowtmr: removing pcb stuck in LAST-ACK\n"));
tcp.c:1091:      }
tcp.c:1092:    }
tcp.c:1093:
tcp.c:1094:    /* If the PCB should be removed, do it. */
tcp.c:1095:    if (pcb_remove) {
tcp.c:1096:      struct tcp_pcb *pcb2;
tcp.c:1097:#if LWIP_CALLBACK_API
tcp.c:1098:      tcp_err_fn err_fn = pcb->errf;
tcp.c:1099:#endif /* LWIP_CALLBACK_API */
tcp.c:1100:      void *err_arg;
tcp.c:1101:      tcp_pcb_purge(pcb);
tcp.c:1102:      /* Remove PCB from tcp_active_pcbs list. */
tcp.c:1103:      if (prev != NULL) {
tcp.c:1104:        LWIP_ASSERT("tcp_slowtmr: middle tcp != tcp_active_pcbs", pcb != tcp_active_pcbs);
tcp.c:1105:        prev->next = pcb->next;
tcp.c:1106:      } else {
tcp.c:1107:        /* This PCB was the first. */
tcp.c:1108:        LWIP_ASSERT("tcp_slowtmr: first pcb == tcp_active_pcbs", tcp_active_pcbs == pcb);
tcp.c:1109:        tcp_active_pcbs = pcb->next;
tcp.c:1110:      }
tcp.c:1111:
tcp.c:1112:      if (pcb_reset) {
tcp.c:1113:        tcp_rst(pcb->snd_nxt, pcb->rcv_nxt, &pcb->local_ip, &pcb->remote_ip,
tcp.c:1114:                 pcb->local_port, pcb->remote_port);
tcp.c:1115:      }
tcp.c:1116:
tcp.c:1117:      err_arg = pcb->callback_arg;
tcp.c:1118:      pcb2 = pcb;
tcp.c:1119:      pcb = pcb->next;
tcp.c:1120:      memp_free(MEMP_TCP_PCB, pcb2);
tcp.c:1121:
tcp.c:1122:      tcp_active_pcbs_changed = 0;
tcp.c:1123:      TCP_EVENT_ERR(err_fn, err_arg, ERR_ABRT);
tcp.c:1124:      if (tcp_active_pcbs_changed) {
tcp.c:1125:        goto tcp_slowtmr_start;
tcp.c:1126:      }
tcp.c:1127:    } else {
tcp.c:1128:      /* get the 'next' element now and work with 'prev' below (in case of abort) */
tcp.c:1129:      prev = pcb;
tcp.c:1130:      pcb = pcb->next;
tcp.c:1131:
tcp.c:1132:      /* We check if we should poll the connection. */
tcp.c:1133:      ++prev->polltmr;
tcp.c:1134:      if (prev->polltmr >= prev->pollinterval) {
tcp.c:1135:        prev->polltmr = 0;
tcp.c:1136:        LWIP_DEBUGF(TCP_DEBUG, ("tcp_slowtmr: polling application\n"));
tcp.c:1137:        tcp_active_pcbs_changed = 0;
tcp.c:1138:        TCP_EVENT_POLL(prev, err);
tcp.c:1139:        if (tcp_active_pcbs_changed) {
tcp.c:1140:          goto tcp_slowtmr_start;
tcp.c:1141:        }
tcp.c:1142:        /* if err == ERR_ABRT, 'prev' is already deallocated */
tcp.c:1143:        if (err == ERR_OK) {
tcp.c:1144:          tcp_output(prev);
tcp.c:1145:        }
tcp.c:1146:      }
tcp.c:1147:    }
tcp.c:1148:  }
tcp.c:1149:
tcp.c:1150:
tcp.c:1151:  /* Steps through all of the TIME-WAIT PCBs. */
tcp.c:1152:  prev = NULL;
tcp.c:1153:  pcb = tcp_tw_pcbs;
tcp.c:1154:  while (pcb != NULL) {
tcp.c:1155:    LWIP_ASSERT("tcp_slowtmr: TIME-WAIT pcb->state == TIME-WAIT", pcb->state == TIME_WAIT);
tcp.c:1156:    pcb_remove = 0;
tcp.c:1157:
tcp.c:1158:    /* Check if this PCB has stayed long enough in TIME-WAIT */
tcp.c:1159:    if ((u32_t)(tcp_ticks - pcb->tmr) > 2 * TCP_MSL / TCP_SLOW_INTERVAL) {
tcp.c:1160:      ++pcb_remove;
tcp.c:1161:    }
tcp.c:1162:
tcp.c:1163:    /* If the PCB should be removed, do it. */
tcp.c:1164:    if (pcb_remove) {
tcp.c:1165:      struct tcp_pcb *pcb2;
tcp.c:1166:      tcp_pcb_purge(pcb);
tcp.c:1167:      /* Remove PCB from tcp_tw_pcbs list. */
tcp.c:1168:      if (prev != NULL) {
tcp.c:1169:        LWIP_ASSERT("tcp_slowtmr: middle tcp != tcp_tw_pcbs", pcb != tcp_tw_pcbs);
tcp.c:1170:        prev->next = pcb->next;
tcp.c:1171:      } else {
tcp.c:1172:        /* This PCB was the first. */
tcp.c:1173:        LWIP_ASSERT("tcp_slowtmr: first pcb == tcp_tw_pcbs", tcp_tw_pcbs == pcb);
tcp.c:1174:        tcp_tw_pcbs = pcb->next;
tcp.c:1175:      }
tcp.c:1176:      pcb2 = pcb;
tcp.c:1177:      pcb = pcb->next;
tcp.c:1178:      memp_free(MEMP_TCP_PCB, pcb2);
tcp.c:1179:    } else {
tcp.c:1180:      prev = pcb;
tcp.c:1181:      pcb = pcb->next;
tcp.c:1182:    }
tcp.c:1183:  }
tcp.c:1184:}
tcp.c:1185:
tcp.c:1186:/**
tcp.c:1187: * Is called every TCP_FAST_INTERVAL (250 ms) and process data previously
tcp.c:1188: * "refused" by upper layer (application) and sends delayed ACKs.
tcp.c:1189: *
tcp.c:1190: * Automatically called from tcp_tmr().
tcp.c:1191: */
tcp.c:1192:void
tcp.c:1193:tcp_fasttmr(void)
tcp.c:1194:{
tcp.c:1195:  struct tcp_pcb *pcb;
tcp.c:1196:
tcp.c:1197:  ++tcp_timer_ctr;
tcp.c:1198:
tcp.c:1199:tcp_fasttmr_start:
tcp.c:1200:  pcb = tcp_active_pcbs;
tcp.c:1201:
tcp.c:1202:  while (pcb != NULL) {
tcp.c:1203:    if (pcb->last_timer != tcp_timer_ctr) {
tcp.c:1204:      struct tcp_pcb *next;
tcp.c:1205:      pcb->last_timer = tcp_timer_ctr;
tcp.c:1206:      /* send delayed ACKs */
tcp.c:1207:      if (pcb->flags & TF_ACK_DELAY) {
tcp.c:1208:        LWIP_DEBUGF(TCP_DEBUG, ("tcp_fasttmr: delayed ACK\n"));
tcp.c:1209:        tcp_ack_now(pcb);
tcp.c:1210:        tcp_output(pcb);
tcp.c:1211:        pcb->flags &= ~(TF_ACK_DELAY | TF_ACK_NOW);
tcp.c:1212:      }
tcp.c:1213:
tcp.c:1214:      next = pcb->next;
tcp.c:1215:
tcp.c:1216:      /* If there is data which was previously "refused" by upper layer */
tcp.c:1217:      if (pcb->refused_data != NULL) {
tcp.c:1218:        tcp_active_pcbs_changed = 0;
tcp.c:1219:        tcp_process_refused_data(pcb);
tcp.c:1220:        if (tcp_active_pcbs_changed) {
tcp.c:1221:          /* application callback has changed the pcb list: restart the loop */
tcp.c:1222:          goto tcp_fasttmr_start;
tcp.c:1223:        }
tcp.c:1224:      }
tcp.c:1225:      pcb = next;
tcp.c:1226:    } else {
tcp.c:1227:      pcb = pcb->next;
tcp.c:1228:    }
tcp.c:1229:  }
tcp.c:1230:}
tcp.c:1231:
tcp.c:1232:/** Call tcp_output for all active pcbs that have TF_NAGLEMEMERR set */
tcp.c:1233:void
tcp.c:1234:tcp_txnow(void)
tcp.c:1235:{
tcp.c:1236:  struct tcp_pcb *pcb;
tcp.c:1237:
tcp.c:1238:  for (pcb = tcp_active_pcbs; pcb != NULL; pcb = pcb->next) {
tcp.c:1239:    if (pcb->flags & TF_NAGLEMEMERR) {
tcp.c:1240:      tcp_output(pcb);
tcp.c:1241:    }
tcp.c:1242:  }
tcp.c:1243:}
tcp.c:1244:
tcp.c:1245:/** Pass pcb->refused_data to the recv callback */
tcp.c:1246:err_t
tcp.c:1247:tcp_process_refused_data(struct tcp_pcb *pcb)
tcp.c:1248:{
tcp.c:1249:#if TCP_QUEUE_OOSEQ && LWIP_WND_SCALE
tcp.c:1250:  struct pbuf *rest;
tcp.c:1251:  while (pcb->refused_data != NULL)
tcp.c:1252:#endif /* TCP_QUEUE_OOSEQ && LWIP_WND_SCALE */
tcp.c:1253:  {
tcp.c:1254:    err_t err;
tcp.c:1255:    u8_t refused_flags = pcb->refused_data->flags;
tcp.c:1256:    /* set pcb->refused_data to NULL in case the callback frees it and then
tcp.c:1257:       closes the pcb */
tcp.c:1258:    struct pbuf *refused_data = pcb->refused_data;
tcp.c:1259:#if TCP_QUEUE_OOSEQ && LWIP_WND_SCALE
tcp.c:1260:    pbuf_split_64k(refused_data, &rest);
tcp.c:1261:    pcb->refused_data = rest;
tcp.c:1262:#else /* TCP_QUEUE_OOSEQ && LWIP_WND_SCALE */
tcp.c:1263:    pcb->refused_data = NULL;
tcp.c:1264:#endif /* TCP_QUEUE_OOSEQ && LWIP_WND_SCALE */
tcp.c:1265:    /* Notify again application with data previously received. */
tcp.c:1266:    LWIP_DEBUGF(TCP_INPUT_DEBUG, ("tcp_input: notify kept packet\n"));
tcp.c:1267:    TCP_EVENT_RECV(pcb, refused_data, ERR_OK, err);
tcp.c:1268:    if (err == ERR_OK) {
tcp.c:1269:      /* did refused_data include a FIN? */
tcp.c:1270:      if (refused_flags & PBUF_FLAG_TCP_FIN
tcp.c:1271:#if TCP_QUEUE_OOSEQ && LWIP_WND_SCALE
tcp.c:1272:          && (rest == NULL)
tcp.c:1273:#endif /* TCP_QUEUE_OOSEQ && LWIP_WND_SCALE */
tcp.c:1274:         ) {
tcp.c:1275:        /* correct rcv_wnd as the application won't call tcp_recved()
tcp.c:1276:           for the FIN's seqno */
tcp.c:1277:        if (pcb->rcv_wnd != TCP_WND_MAX(pcb)) {
tcp.c:1278:          pcb->rcv_wnd++;
tcp.c:1279:        }
tcp.c:1280:        TCP_EVENT_CLOSED(pcb, err);
tcp.c:1281:        if (err == ERR_ABRT) {
tcp.c:1282:          return ERR_ABRT;
tcp.c:1283:        }
tcp.c:1284:      }
tcp.c:1285:    } else if (err == ERR_ABRT) {
tcp.c:1286:      /* if err == ERR_ABRT, 'pcb' is already deallocated */
tcp.c:1287:      /* Drop incoming packets because pcb is "full" (only if the incoming
tcp.c:1288:         segment contains data). */
tcp.c:1289:      LWIP_DEBUGF(TCP_INPUT_DEBUG, ("tcp_input: drop incoming packets, because pcb is \"full\"\n"));
tcp.c:1290:      return ERR_ABRT;
tcp.c:1291:    } else {
tcp.c:1292:      /* data is still refused, pbuf is still valid (go on for ACK-only packets) */
tcp.c:1293:#if TCP_QUEUE_OOSEQ && LWIP_WND_SCALE
tcp.c:1294:      if (rest != NULL) {
tcp.c:1295:        pbuf_cat(refused_data, rest);
tcp.c:1296:      }
tcp.c:1297:#endif /* TCP_QUEUE_OOSEQ && LWIP_WND_SCALE */
tcp.c:1298:      pcb->refused_data = refused_data;
tcp.c:1299:      return ERR_INPROGRESS;
tcp.c:1300:    }
tcp.c:1301:  }
tcp.c:1302:  return ERR_OK;
tcp.c:1303:}
tcp.c:1304:
tcp.c:1305:/**
tcp.c:1306: * Deallocates a list of TCP segments (tcp_seg structures).
tcp.c:1307: *
tcp.c:1308: * @param seg tcp_seg list of TCP segments to free
tcp.c:1309: */
tcp.c:1310:void
tcp.c:1311:tcp_segs_free(struct tcp_seg *seg)
tcp.c:1312:{
tcp.c:1313:  while (seg != NULL) {
tcp.c:1314:    struct tcp_seg *next = seg->next;
tcp.c:1315:    tcp_seg_free(seg);
tcp.c:1316:    seg = next;
tcp.c:1317:  }
tcp.c:1318:}
tcp.c:1319:
tcp.c:1320:/**
tcp.c:1321: * Frees a TCP segment (tcp_seg structure).
tcp.c:1322: *
tcp.c:1323: * @param seg single tcp_seg to free
tcp.c:1324: */
tcp.c:1325:void
tcp.c:1326:tcp_seg_free(struct tcp_seg *seg)
tcp.c:1327:{
tcp.c:1328:  if (seg != NULL) {
tcp.c:1329:    if (seg->p != NULL) {
tcp.c:1330:      pbuf_free(seg->p);
tcp.c:1331:#if TCP_DEBUG
tcp.c:1332:      seg->p = NULL;
tcp.c:1333:#endif /* TCP_DEBUG */
tcp.c:1334:    }
tcp.c:1335:    memp_free(MEMP_TCP_SEG, seg);
tcp.c:1336:  }
tcp.c:1337:}
tcp.c:1338:
tcp.c:1339:/**
tcp.c:1340: * Sets the priority of a connection.
tcp.c:1341: *
tcp.c:1342: * @param pcb the tcp_pcb to manipulate
tcp.c:1343: * @param prio new priority
tcp.c:1344: */
tcp.c:1345:void
tcp.c:1346:tcp_setprio(struct tcp_pcb *pcb, u8_t prio)
tcp.c:1347:{
tcp.c:1348:  pcb->prio = prio;
tcp.c:1349:}
tcp.c:1350:
tcp.c:1351:#if TCP_QUEUE_OOSEQ
tcp.c:1352:/**
tcp.c:1353: * Returns a copy of the given TCP segment.
tcp.c:1354: * The pbuf and data are not copied, only the pointers
tcp.c:1355: *
tcp.c:1356: * @param seg the old tcp_seg
tcp.c:1357: * @return a copy of seg
tcp.c:1358: */
tcp.c:1359:struct tcp_seg *
tcp.c:1360:tcp_seg_copy(struct tcp_seg *seg)
tcp.c:1361:{
tcp.c:1362:  struct tcp_seg *cseg;
tcp.c:1363:
tcp.c:1364:  cseg = (struct tcp_seg *)memp_malloc(MEMP_TCP_SEG);
tcp.c:1365:  if (cseg == NULL) {
tcp.c:1366:    return NULL;
tcp.c:1367:  }
tcp.c:1368:  SMEMCPY((u8_t *)cseg, (const u8_t *)seg, sizeof(struct tcp_seg));
tcp.c:1369:  pbuf_ref(cseg->p);
tcp.c:1370:  return cseg;
tcp.c:1371:}
tcp.c:1372:#endif /* TCP_QUEUE_OOSEQ */
tcp.c:1373:
tcp.c:1374:#if LWIP_CALLBACK_API
tcp.c:1375:/**
tcp.c:1376: * Default receive callback that is called if the user didn't register
tcp.c:1377: * a recv callback for the pcb.
tcp.c:1378: */
tcp.c:1379:err_t
tcp.c:1380:tcp_recv_null(void *arg, struct tcp_pcb *pcb, struct pbuf *p, err_t err)
tcp.c:1381:{
tcp.c:1382:  LWIP_UNUSED_ARG(arg);
tcp.c:1383:  if (p != NULL) {
tcp.c:1384:    tcp_recved(pcb, p->tot_len);
tcp.c:1385:    pbuf_free(p);
tcp.c:1386:  } else if (err == ERR_OK) {
tcp.c:1387:    return tcp_close(pcb);
tcp.c:1388:  }
tcp.c:1389:  return ERR_OK;
tcp.c:1390:}
tcp.c:1391:#endif /* LWIP_CALLBACK_API */
tcp.c:1392:
tcp.c:1393:/**
tcp.c:1394: * Kills the oldest active connection that has the same or lower priority than
tcp.c:1395: * 'prio'.
tcp.c:1396: *
tcp.c:1397: * @param prio minimum priority
tcp.c:1398: */
tcp.c:1399:static void
tcp.c:1400:tcp_kill_prio(u8_t prio)
tcp.c:1401:{
tcp.c:1402:  struct tcp_pcb *pcb, *inactive;
tcp.c:1403:  u32_t inactivity;
tcp.c:1404:  u8_t mprio;
tcp.c:1405:
tcp.c:1406:  mprio = LWIP_MIN(TCP_PRIO_MAX, prio);
tcp.c:1407:
tcp.c:1408:  /* We kill the oldest active connection that has lower priority than prio. */
tcp.c:1409:  inactivity = 0;
tcp.c:1410:  inactive = NULL;
tcp.c:1411:  for (pcb = tcp_active_pcbs; pcb != NULL; pcb = pcb->next) {
tcp.c:1412:    if (pcb->prio <= mprio &&
tcp.c:1413:       (u32_t)(tcp_ticks - pcb->tmr) >= inactivity) {
tcp.c:1414:      inactivity = tcp_ticks - pcb->tmr;
tcp.c:1415:      inactive = pcb;
tcp.c:1416:      mprio = pcb->prio;
tcp.c:1417:    }
tcp.c:1418:  }
tcp.c:1419:  if (inactive != NULL) {
tcp.c:1420:    LWIP_DEBUGF(TCP_DEBUG, ("tcp_kill_prio: killing oldest PCB %p (%"S32_F")\n",
tcp.c:1421:           (void *)inactive, inactivity));
tcp.c:1422:    tcp_abort(inactive);
tcp.c:1423:  }
tcp.c:1424:}
tcp.c:1425:
tcp.c:1426:/**
tcp.c:1427: * Kills the oldest connection that is in specific state.
tcp.c:1428: * Called from tcp_alloc() for LAST_ACK and CLOSING if no more connections are available.
tcp.c:1429: */
tcp.c:1430:static void
tcp.c:1431:tcp_kill_state(enum tcp_state state)
tcp.c:1432:{
tcp.c:1433:  struct tcp_pcb *pcb, *inactive;
tcp.c:1434:  u32_t inactivity;
tcp.c:1435:
tcp.c:1436:  LWIP_ASSERT("invalid state", (state == CLOSING) || (state == LAST_ACK));
tcp.c:1437:
tcp.c:1438:  inactivity = 0;
tcp.c:1439:  inactive = NULL;
tcp.c:1440:  /* Go through the list of active pcbs and get the oldest pcb that is in state
tcp.c:1441:     CLOSING/LAST_ACK. */
tcp.c:1442:  for (pcb = tcp_active_pcbs; pcb != NULL; pcb = pcb->next) {
tcp.c:1443:    if (pcb->state == state) {
tcp.c:1444:      if ((u32_t)(tcp_ticks - pcb->tmr) >= inactivity) {
tcp.c:1445:        inactivity = tcp_ticks - pcb->tmr;
tcp.c:1446:        inactive = pcb;
tcp.c:1447:      }
tcp.c:1448:    }
tcp.c:1449:  }
tcp.c:1450:  if (inactive != NULL) {
tcp.c:1451:    LWIP_DEBUGF(TCP_DEBUG, ("tcp_kill_closing: killing oldest %s PCB %p (%"S32_F")\n",
tcp.c:1452:           tcp_state_str[state], (void *)inactive, inactivity));
tcp.c:1453:    /* Don't send a RST, since no data is lost. */
tcp.c:1454:    tcp_abandon(inactive, 0);
tcp.c:1455:  }
tcp.c:1456:}
tcp.c:1457:
tcp.c:1458:/**
tcp.c:1459: * Kills the oldest connection that is in TIME_WAIT state.
tcp.c:1460: * Called from tcp_alloc() if no more connections are available.
tcp.c:1461: */
tcp.c:1462:static void
tcp.c:1463:tcp_kill_timewait(void)
tcp.c:1464:{
tcp.c:1465:  struct tcp_pcb *pcb, *inactive;
tcp.c:1466:  u32_t inactivity;
tcp.c:1467:
tcp.c:1468:  inactivity = 0;
tcp.c:1469:  inactive = NULL;
tcp.c:1470:  /* Go through the list of TIME_WAIT pcbs and get the oldest pcb. */
tcp.c:1471:  for (pcb = tcp_tw_pcbs; pcb != NULL; pcb = pcb->next) {
tcp.c:1472:    if ((u32_t)(tcp_ticks - pcb->tmr) >= inactivity) {
tcp.c:1473:      inactivity = tcp_ticks - pcb->tmr;
tcp.c:1474:      inactive = pcb;
tcp.c:1475:    }
tcp.c:1476:  }
tcp.c:1477:  if (inactive != NULL) {
tcp.c:1478:    LWIP_DEBUGF(TCP_DEBUG, ("tcp_kill_timewait: killing oldest TIME-WAIT PCB %p (%"S32_F")\n",
tcp.c:1479:           (void *)inactive, inactivity));
tcp.c:1480:    tcp_abort(inactive);
tcp.c:1481:  }
tcp.c:1482:}
tcp.c:1483:
tcp.c:1484:/**
tcp.c:1485: * Allocate a new tcp_pcb structure.
tcp.c:1486: *
tcp.c:1487: * @param prio priority for the new pcb
tcp.c:1488: * @return a new tcp_pcb that initially is in state CLOSED
tcp.c:1489: */
tcp.c:1490:struct tcp_pcb *
tcp.c:1491:tcp_alloc(u8_t prio)
tcp.c:1492:{
tcp.c:1493:  struct tcp_pcb *pcb;
tcp.c:1494:  u32_t iss;
tcp.c:1495:
tcp.c:1496:  pcb = (struct tcp_pcb *)memp_malloc(MEMP_TCP_PCB);
tcp.c:1497:  if (pcb == NULL) {
tcp.c:1498:    /* Try killing oldest connection in TIME-WAIT. */
tcp.c:1499:    LWIP_DEBUGF(TCP_DEBUG, ("tcp_alloc: killing off oldest TIME-WAIT connection\n"));
tcp.c:1500:    tcp_kill_timewait();
tcp.c:1501:    /* Try to allocate a tcp_pcb again. */
tcp.c:1502:    pcb = (struct tcp_pcb *)memp_malloc(MEMP_TCP_PCB);
tcp.c:1503:    if (pcb == NULL) {
tcp.c:1504:      /* Try killing oldest connection in LAST-ACK (these wouldn't go to TIME-WAIT). */
tcp.c:1505:      LWIP_DEBUGF(TCP_DEBUG, ("tcp_alloc: killing off oldest LAST-ACK connection\n"));
tcp.c:1506:      tcp_kill_state(LAST_ACK);
tcp.c:1507:      /* Try to allocate a tcp_pcb again. */
tcp.c:1508:      pcb = (struct tcp_pcb *)memp_malloc(MEMP_TCP_PCB);
tcp.c:1509:      if (pcb == NULL) {
tcp.c:1510:        /* Try killing oldest connection in CLOSING. */
tcp.c:1511:        LWIP_DEBUGF(TCP_DEBUG, ("tcp_alloc: killing off oldest CLOSING connection\n"));
tcp.c:1512:        tcp_kill_state(CLOSING);
tcp.c:1513:        /* Try to allocate a tcp_pcb again. */
tcp.c:1514:        pcb = (struct tcp_pcb *)memp_malloc(MEMP_TCP_PCB);
tcp.c:1515:        if (pcb == NULL) {
tcp.c:1516:          /* Try killing active connections with lower priority than the new one. */
tcp.c:1517:          LWIP_DEBUGF(TCP_DEBUG, ("tcp_alloc: killing connection with prio lower than %d\n", prio));
tcp.c:1518:          tcp_kill_prio(prio);
tcp.c:1519:          /* Try to allocate a tcp_pcb again. */
tcp.c:1520:          pcb = (struct tcp_pcb *)memp_malloc(MEMP_TCP_PCB);
tcp.c:1521:          if (pcb != NULL) {
tcp.c:1522:            /* adjust err stats: memp_malloc failed multiple times before */
tcp.c:1523:            MEMP_STATS_DEC(err, MEMP_TCP_PCB);
tcp.c:1524:          }
tcp.c:1525:        }
tcp.c:1526:        if (pcb != NULL) {
tcp.c:1527:          /* adjust err stats: memp_malloc failed multiple times before */
tcp.c:1528:          MEMP_STATS_DEC(err, MEMP_TCP_PCB);
tcp.c:1529:        }
tcp.c:1530:      }
tcp.c:1531:      if (pcb != NULL) {
tcp.c:1532:        /* adjust err stats: memp_malloc failed multiple times before */
tcp.c:1533:        MEMP_STATS_DEC(err, MEMP_TCP_PCB);
tcp.c:1534:      }
tcp.c:1535:    }
tcp.c:1536:    if (pcb != NULL) {
tcp.c:1537:      /* adjust err stats: memp_malloc failed above */
tcp.c:1538:      MEMP_STATS_DEC(err, MEMP_TCP_PCB);
tcp.c:1539:    }
tcp.c:1540:  }
tcp.c:1541:  if (pcb != NULL) {
tcp.c:1542:    /* zero out the whole pcb, so there is no need to initialize members to zero */
tcp.c:1543:    memset(pcb, 0, sizeof(struct tcp_pcb));
tcp.c:1544:    pcb->prio = prio;
tcp.c:1545:    pcb->snd_buf = TCP_SND_BUF;
tcp.c:1546:    /* Start with a window that does not need scaling. When window scaling is
tcp.c:1547:       enabled and used, the window is enlarged when both sides agree on scaling. */
tcp.c:1548:    pcb->rcv_wnd = pcb->rcv_ann_wnd = TCPWND_MIN16(TCP_WND);
tcp.c:1549:    pcb->ttl = TCP_TTL;
tcp.c:1550:    /* As initial send MSS, we use TCP_MSS but limit it to 536.
tcp.c:1551:       The send MSS is updated when an MSS option is received. */
tcp.c:1552:    pcb->mss = INITIAL_MSS;
tcp.c:1553:    pcb->rto = 3000 / TCP_SLOW_INTERVAL;
tcp.c:1554:    pcb->sv = 3000 / TCP_SLOW_INTERVAL;
tcp.c:1555:    pcb->rtime = -1;
tcp.c:1556:    pcb->cwnd = 1;
tcp.c:1557:    iss = tcp_next_iss();
tcp.c:1558:    pcb->snd_wl2 = iss;
tcp.c:1559:    pcb->snd_nxt = iss;
tcp.c:1560:    pcb->lastack = iss;
tcp.c:1561:    pcb->snd_lbb = iss;
tcp.c:1562:    pcb->tmr = tcp_ticks;
tcp.c:1563:    pcb->last_timer = tcp_timer_ctr;
tcp.c:1564:
tcp.c:1565:#if LWIP_CALLBACK_API
tcp.c:1566:    pcb->recv = tcp_recv_null;
tcp.c:1567:#endif /* LWIP_CALLBACK_API */
tcp.c:1568:
tcp.c:1569:    /* Init KEEPALIVE timer */
tcp.c:1570:    pcb->keep_idle  = TCP_KEEPIDLE_DEFAULT;
tcp.c:1571:
tcp.c:1572:#if LWIP_TCP_KEEPALIVE
tcp.c:1573:    pcb->keep_intvl = TCP_KEEPINTVL_DEFAULT;
tcp.c:1574:    pcb->keep_cnt   = TCP_KEEPCNT_DEFAULT;
tcp.c:1575:#endif /* LWIP_TCP_KEEPALIVE */
tcp.c:1576:  }
tcp.c:1577:  return pcb;
tcp.c:1578:}
tcp.c:1579:
tcp.c:1580:/**
tcp.c:1581: * @ingroup tcp_raw
tcp.c:1582: * Creates a new TCP protocol control block but doesn't place it on
tcp.c:1583: * any of the TCP PCB lists.
tcp.c:1584: * The pcb is not put on any list until binding using tcp_bind().
tcp.c:1585: *
tcp.c:1586: * @internal: Maybe there should be a idle TCP PCB list where these
tcp.c:1587: * PCBs are put on. Port reservation using tcp_bind() is implemented but
tcp.c:1588: * allocated pcbs that are not bound can't be killed automatically if wanting
tcp.c:1589: * to allocate a pcb with higher prio (@see tcp_kill_prio())
tcp.c:1590: *
tcp.c:1591: * @return a new tcp_pcb that initially is in state CLOSED
tcp.c:1592: */
tcp.c:1593:struct tcp_pcb *
tcp.c:1594:tcp_new(void)
tcp.c:1595:{
tcp.c:1596:  return tcp_alloc(TCP_PRIO_NORMAL);
tcp.c:1597:}
tcp.c:1598:
tcp.c:1599:/**
tcp.c:1600: * @ingroup tcp_raw
tcp.c:1601: * Creates a new TCP protocol control block but doesn't
tcp.c:1602: * place it on any of the TCP PCB lists.
tcp.c:1603: * The pcb is not put on any list until binding using tcp_bind().
tcp.c:1604: *
tcp.c:1605: * @param type IP address type, see @ref lwip_ip_addr_type definitions.
tcp.c:1606: * If you want to listen to IPv4 and IPv6 (dual-stack) connections,
tcp.c:1607: * supply @ref IPADDR_TYPE_ANY as argument and bind to @ref IP_ANY_TYPE.
tcp.c:1608: * @return a new tcp_pcb that initially is in state CLOSED
tcp.c:1609: */
tcp.c:1610:struct tcp_pcb *
tcp.c:1611:tcp_new_ip_type(u8_t type)
tcp.c:1612:{
tcp.c:1613:  struct tcp_pcb * pcb;
tcp.c:1614:  pcb = tcp_alloc(TCP_PRIO_NORMAL);
tcp.c:1615:#if LWIP_IPV4 && LWIP_IPV6
tcp.c:1616:  if (pcb != NULL) {
tcp.c:1617:    IP_SET_TYPE_VAL(pcb->local_ip, type);
tcp.c:1618:    IP_SET_TYPE_VAL(pcb->remote_ip, type);
tcp.c:1619:  }
tcp.c:1620:#else
tcp.c:1621:  LWIP_UNUSED_ARG(type);
tcp.c:1622:#endif /* LWIP_IPV4 && LWIP_IPV6 */
tcp.c:1623:  return pcb;
tcp.c:1624:}
tcp.c:1625:
tcp.c:1626:/**
tcp.c:1627: * @ingroup tcp_raw
tcp.c:1628: * Used to specify the argument that should be passed callback
tcp.c:1629: * functions.
tcp.c:1630: *
tcp.c:1631: * @param pcb tcp_pcb to set the callback argument
tcp.c:1632: * @param arg void pointer argument to pass to callback functions
tcp.c:1633: */
tcp.c:1634:void
tcp.c:1635:tcp_arg(struct tcp_pcb *pcb, void *arg)
tcp.c:1636:{
tcp.c:1637:  /* This function is allowed to be called for both listen pcbs and
tcp.c:1638:     connection pcbs. */
tcp.c:1639:  if (pcb != NULL) {
tcp.c:1640:    pcb->callback_arg = arg;
tcp.c:1641:  }
tcp.c:1642:}
tcp.c:1643:#if LWIP_CALLBACK_API
tcp.c:1644:
tcp.c:1645:/**
tcp.c:1646: * @ingroup tcp_raw
tcp.c:1647: * Used to specify the function that should be called when a TCP
tcp.c:1648: * connection receives data.
tcp.c:1649: *
tcp.c:1650: * @param pcb tcp_pcb to set the recv callback
tcp.c:1651: * @param recv callback function to call for this pcb when data is received
tcp.c:1652: */
tcp.c:1653:void
tcp.c:1654:tcp_recv(struct tcp_pcb *pcb, tcp_recv_fn recv)
tcp.c:1655:{
tcp.c:1656:  if (pcb != NULL) {
tcp.c:1657:    LWIP_ASSERT("invalid socket state for recv callback", pcb->state != LISTEN);
tcp.c:1658:    pcb->recv = recv;
tcp.c:1659:  }
tcp.c:1660:}
tcp.c:1661:
tcp.c:1662:/**
tcp.c:1663: * @ingroup tcp_raw
tcp.c:1664: * Used to specify the function that should be called when TCP data
tcp.c:1665: * has been successfully delivered to the remote host.
tcp.c:1666: *
tcp.c:1667: * @param pcb tcp_pcb to set the sent callback
tcp.c:1668: * @param sent callback function to call for this pcb when data is successfully sent
tcp.c:1669: */
tcp.c:1670:void
tcp.c:1671:tcp_sent(struct tcp_pcb *pcb, tcp_sent_fn sent)
tcp.c:1672:{
tcp.c:1673:  if (pcb != NULL) {
tcp.c:1674:    LWIP_ASSERT("invalid socket state for sent callback", pcb->state != LISTEN);
tcp.c:1675:    pcb->sent = sent;
tcp.c:1676:  }
tcp.c:1677:}
tcp.c:1678:
tcp.c:1679:/**
tcp.c:1680: * @ingroup tcp_raw
tcp.c:1681: * Used to specify the function that should be called when a fatal error
tcp.c:1682: * has occurred on the connection.
tcp.c:1683: *
tcp.c:1684: * @note The corresponding pcb is already freed when this callback is called!
tcp.c:1685: * 
tcp.c:1686: * @param pcb tcp_pcb to set the err callback
tcp.c:1687: * @param err callback function to call for this pcb when a fatal error
tcp.c:1688: *        has occurred on the connection
tcp.c:1689: */
tcp.c:1690:void
tcp.c:1691:tcp_err(struct tcp_pcb *pcb, tcp_err_fn err)
tcp.c:1692:{
tcp.c:1693:  if (pcb != NULL) {
tcp.c:1694:    LWIP_ASSERT("invalid socket state for err callback", pcb->state != LISTEN);
tcp.c:1695:    pcb->errf = err;
tcp.c:1696:  }
tcp.c:1697:}
tcp.c:1698:
tcp.c:1699:/**
tcp.c:1700: * @ingroup tcp_raw
tcp.c:1701: * Used for specifying the function that should be called when a
tcp.c:1702: * LISTENing connection has been connected to another host.
tcp.c:1703: *
tcp.c:1704: * @param pcb tcp_pcb to set the accept callback
tcp.c:1705: * @param accept callback function to call for this pcb when LISTENing
tcp.c:1706: *        connection has been connected to another host
tcp.c:1707: */
tcp.c:1708:void
tcp.c:1709:tcp_accept(struct tcp_pcb *pcb, tcp_accept_fn accept)
tcp.c:1710:{
tcp.c:1711:  if ((pcb != NULL) && (pcb->state == LISTEN)) {
tcp.c:1712:    struct tcp_pcb_listen *lpcb = (struct tcp_pcb_listen*)pcb;
tcp.c:1713:    lpcb->accept = accept;
tcp.c:1714:  }
tcp.c:1715:}
tcp.c:1716:#endif /* LWIP_CALLBACK_API */
tcp.c:1717:
tcp.c:1718:
tcp.c:1719:/**
tcp.c:1720: * @ingroup tcp_raw
tcp.c:1721: * Used to specify the function that should be called periodically
tcp.c:1722: * from TCP. The interval is specified in terms of the TCP coarse
tcp.c:1723: * timer interval, which is called twice a second.
tcp.c:1724: *
tcp.c:1725: */
tcp.c:1726:void
tcp.c:1727:tcp_poll(struct tcp_pcb *pcb, tcp_poll_fn poll, u8_t interval)
tcp.c:1728:{
tcp.c:1729:  LWIP_ASSERT("invalid socket state for poll", pcb->state != LISTEN);
tcp.c:1730:#if LWIP_CALLBACK_API
tcp.c:1731:  pcb->poll = poll;
tcp.c:1732:#else /* LWIP_CALLBACK_API */
tcp.c:1733:  LWIP_UNUSED_ARG(poll);
tcp.c:1734:#endif /* LWIP_CALLBACK_API */
tcp.c:1735:  pcb->pollinterval = interval;
tcp.c:1736:}
tcp.c:1737:
tcp.c:1738:/**
tcp.c:1739: * Purges a TCP PCB. Removes any buffered data and frees the buffer memory
tcp.c:1740: * (pcb->ooseq, pcb->unsent and pcb->unacked are freed).
tcp.c:1741: *
tcp.c:1742: * @param pcb tcp_pcb to purge. The pcb itself is not deallocated!
tcp.c:1743: */
tcp.c:1744:void
tcp.c:1745:tcp_pcb_purge(struct tcp_pcb *pcb)
tcp.c:1746:{
tcp.c:1747:  if (pcb->state != CLOSED &&
tcp.c:1748:     pcb->state != TIME_WAIT &&
tcp.c:1749:     pcb->state != LISTEN) {
tcp.c:1750:
tcp.c:1751:    LWIP_DEBUGF(TCP_DEBUG, ("tcp_pcb_purge\n"));
tcp.c:1752:
tcp.c:1753:    tcp_backlog_accepted(pcb);
tcp.c:1754:
tcp.c:1755:    if (pcb->refused_data != NULL) {
tcp.c:1756:      LWIP_DEBUGF(TCP_DEBUG, ("tcp_pcb_purge: data left on ->refused_data\n"));
tcp.c:1757:      pbuf_free(pcb->refused_data);
tcp.c:1758:      pcb->refused_data = NULL;
tcp.c:1759:    }
tcp.c:1760:    if (pcb->unsent != NULL) {
tcp.c:1761:      LWIP_DEBUGF(TCP_DEBUG, ("tcp_pcb_purge: not all data sent\n"));
tcp.c:1762:    }
tcp.c:1763:    if (pcb->unacked != NULL) {
tcp.c:1764:      LWIP_DEBUGF(TCP_DEBUG, ("tcp_pcb_purge: data left on ->unacked\n"));
tcp.c:1765:    }
tcp.c:1766:#if TCP_QUEUE_OOSEQ
tcp.c:1767:    if (pcb->ooseq != NULL) {
tcp.c:1768:      LWIP_DEBUGF(TCP_DEBUG, ("tcp_pcb_purge: data left on ->ooseq\n"));
tcp.c:1769:    }
tcp.c:1770:    tcp_segs_free(pcb->ooseq);
tcp.c:1771:    pcb->ooseq = NULL;
tcp.c:1772:#endif /* TCP_QUEUE_OOSEQ */
tcp.c:1773:
tcp.c:1774:    /* Stop the retransmission timer as it will expect data on unacked
tcp.c:1775:       queue if it fires */
tcp.c:1776:    pcb->rtime = -1;
tcp.c:1777:
tcp.c:1778:    tcp_segs_free(pcb->unsent);
tcp.c:1779:    tcp_segs_free(pcb->unacked);
tcp.c:1780:    pcb->unacked = pcb->unsent = NULL;
tcp.c:1781:#if TCP_OVERSIZE
tcp.c:1782:    pcb->unsent_oversize = 0;
tcp.c:1783:#endif /* TCP_OVERSIZE */
tcp.c:1784:  }
tcp.c:1785:}
tcp.c:1786:
tcp.c:1787:/**
tcp.c:1788: * Purges the PCB and removes it from a PCB list. Any delayed ACKs are sent first.
tcp.c:1789: *
tcp.c:1790: * @param pcblist PCB list to purge.
tcp.c:1791: * @param pcb tcp_pcb to purge. The pcb itself is NOT deallocated!
tcp.c:1792: */
tcp.c:1793:void
tcp.c:1794:tcp_pcb_remove(struct tcp_pcb **pcblist, struct tcp_pcb *pcb)
tcp.c:1795:{
tcp.c:1796:  TCP_RMV(pcblist, pcb);
tcp.c:1797:
tcp.c:1798:  tcp_pcb_purge(pcb);
tcp.c:1799:
tcp.c:1800:  /* if there is an outstanding delayed ACKs, send it */
tcp.c:1801:  if (pcb->state != TIME_WAIT &&
tcp.c:1802:     pcb->state != LISTEN &&
tcp.c:1803:     pcb->flags & TF_ACK_DELAY) {
tcp.c:1804:    pcb->flags |= TF_ACK_NOW;
tcp.c:1805:    tcp_output(pcb);
tcp.c:1806:  }
tcp.c:1807:
tcp.c:1808:  if (pcb->state != LISTEN) {
tcp.c:1809:    LWIP_ASSERT("unsent segments leaking", pcb->unsent == NULL);
tcp.c:1810:    LWIP_ASSERT("unacked segments leaking", pcb->unacked == NULL);
tcp.c:1811:#if TCP_QUEUE_OOSEQ
tcp.c:1812:    LWIP_ASSERT("ooseq segments leaking", pcb->ooseq == NULL);
tcp.c:1813:#endif /* TCP_QUEUE_OOSEQ */
tcp.c:1814:  }
tcp.c:1815:
tcp.c:1816:  pcb->state = CLOSED;
tcp.c:1817:  /* reset the local port to prevent the pcb from being 'bound' */
tcp.c:1818:  pcb->local_port = 0;
tcp.c:1819:
tcp.c:1820:  LWIP_ASSERT("tcp_pcb_remove: tcp_pcbs_sane()", tcp_pcbs_sane());
tcp.c:1821:}
tcp.c:1822:
tcp.c:1823:/**
tcp.c:1824: * Calculates a new initial sequence number for new connections.
tcp.c:1825: *
tcp.c:1826: * @return u32_t pseudo random sequence number
tcp.c:1827: */
tcp.c:1828:u32_t
tcp.c:1829:tcp_next_iss(void)
tcp.c:1830:{
tcp.c:1831:  static u32_t iss = 6510;
tcp.c:1832:
tcp.c:1833:  iss += tcp_ticks;       /* XXX */
tcp.c:1834:  return iss;
tcp.c:1835:}
tcp.c:1836:
tcp.c:1837:#if TCP_CALCULATE_EFF_SEND_MSS
tcp.c:1838:/**
tcp.c:1839: * Calculates the effective send mss that can be used for a specific IP address
tcp.c:1840: * by using ip_route to determine the netif used to send to the address and
tcp.c:1841: * calculating the minimum of TCP_MSS and that netif's mtu (if set).
tcp.c:1842: */
tcp.c:1843:u16_t
tcp.c:1844:tcp_eff_send_mss_impl(u16_t sendmss, const ip_addr_t *dest
tcp.c:1845:#if LWIP_IPV6 || LWIP_IPV4_SRC_ROUTING
tcp.c:1846:                     , const ip_addr_t *src
tcp.c:1847:#endif /* LWIP_IPV6 || LWIP_IPV4_SRC_ROUTING */
tcp.c:1848:                     )
tcp.c:1849:{
tcp.c:1850:  u16_t mss_s;
tcp.c:1851:  struct netif *outif;
tcp.c:1852:  s16_t mtu;
tcp.c:1853:
tcp.c:1854:  outif = ip_route(src, dest);
tcp.c:1855:#if LWIP_IPV6
tcp.c:1856:#if LWIP_IPV4
tcp.c:1857:  if (IP_IS_V6(dest))
tcp.c:1858:#endif /* LWIP_IPV4 */
tcp.c:1859:  {
tcp.c:1860:    /* First look in destination cache, to see if there is a Path MTU. */
tcp.c:1861:    mtu = nd6_get_destination_mtu(ip_2_ip6(dest), outif);
tcp.c:1862:  }
tcp.c:1863:#if LWIP_IPV4
tcp.c:1864:  else
tcp.c:1865:#endif /* LWIP_IPV4 */
tcp.c:1866:#endif /* LWIP_IPV6 */
tcp.c:1867:#if LWIP_IPV4
tcp.c:1868:  {
tcp.c:1869:    if (outif == NULL) {
tcp.c:1870:      return sendmss;
tcp.c:1871:    }
tcp.c:1872:    mtu = outif->mtu;
tcp.c:1873:  }
tcp.c:1874:#endif /* LWIP_IPV4 */
tcp.c:1875:
tcp.c:1876:  if (mtu != 0) {
tcp.c:1877:#if LWIP_IPV6
tcp.c:1878:#if LWIP_IPV4
tcp.c:1879:    if (IP_IS_V6(dest))
tcp.c:1880:#endif /* LWIP_IPV4 */
tcp.c:1881:    {
tcp.c:1882:      mss_s = mtu - IP6_HLEN - TCP_HLEN;
tcp.c:1883:    }
tcp.c:1884:#if LWIP_IPV4
tcp.c:1885:    else
tcp.c:1886:#endif /* LWIP_IPV4 */
tcp.c:1887:#endif /* LWIP_IPV6 */
tcp.c:1888:#if LWIP_IPV4
tcp.c:1889:    {
tcp.c:1890:      mss_s = mtu - IP_HLEN - TCP_HLEN;
tcp.c:1891:    }
tcp.c:1892:#endif /* LWIP_IPV4 */
tcp.c:1893:    /* RFC 1122, chap 4.2.2.6:
tcp.c:1894:     * Eff.snd.MSS = min(SendMSS+20, MMS_S) - TCPhdrsize - IPoptionsize
tcp.c:1895:     * We correct for TCP options in tcp_write(), and don't support IP options.
tcp.c:1896:     */
tcp.c:1897:    sendmss = LWIP_MIN(sendmss, mss_s);
tcp.c:1898:  }
tcp.c:1899:  return sendmss;
tcp.c:1900:}
tcp.c:1901:#endif /* TCP_CALCULATE_EFF_SEND_MSS */
tcp.c:1902:
tcp.c:1903:/** Helper function for tcp_netif_ip_addr_changed() that iterates a pcb list */
tcp.c:1904:static void
tcp.c:1905:tcp_netif_ip_addr_changed_pcblist(const ip_addr_t* old_addr, struct tcp_pcb* pcb_list)
tcp.c:1906:{
tcp.c:1907:  struct tcp_pcb *pcb;
tcp.c:1908:  pcb = pcb_list;
tcp.c:1909:  while (pcb != NULL) {
tcp.c:1910:    /* PCB bound to current local interface address? */
tcp.c:1911:    if (ip_addr_cmp(&pcb->local_ip, old_addr)
tcp.c:1912:#if LWIP_AUTOIP
tcp.c:1913:      /* connections to link-local addresses must persist (RFC3927 ch. 1.9) */
tcp.c:1914:      && (!IP_IS_V4_VAL(pcb->local_ip) || !ip4_addr_islinklocal(ip_2_ip4(&pcb->local_ip)))
tcp.c:1915:#endif /* LWIP_AUTOIP */
tcp.c:1916:      ) {
tcp.c:1917:      /* this connection must be aborted */
tcp.c:1918:      struct tcp_pcb *next = pcb->next;
tcp.c:1919:      LWIP_DEBUGF(NETIF_DEBUG | LWIP_DBG_STATE, ("netif_set_ipaddr: aborting TCP pcb %p\n", (void *)pcb));
tcp.c:1920:      tcp_abort(pcb);
tcp.c:1921:      pcb = next;
tcp.c:1922:    } else {
tcp.c:1923:      pcb = pcb->next;
tcp.c:1924:    }
tcp.c:1925:  }
tcp.c:1926:}
tcp.c:1927:
tcp.c:1928:/** This function is called from netif.c when address is changed or netif is removed
tcp.c:1929: *
tcp.c:1930: * @param old_addr IP address of the netif before change
tcp.c:1931: * @param new_addr IP address of the netif after change or NULL if netif has been removed
tcp.c:1932: */
tcp.c:1933:void
tcp.c:1934:tcp_netif_ip_addr_changed(const ip_addr_t* old_addr, const ip_addr_t* new_addr)
tcp.c:1935:{
tcp.c:1936:  struct tcp_pcb_listen *lpcb, *next;
tcp.c:1937:
tcp.c:1938:  if (!ip_addr_isany(old_addr)) {
tcp.c:1939:    tcp_netif_ip_addr_changed_pcblist(old_addr, tcp_active_pcbs);
tcp.c:1940:    tcp_netif_ip_addr_changed_pcblist(old_addr, tcp_bound_pcbs);
tcp.c:1941:
tcp.c:1942:    if (!ip_addr_isany(new_addr)) {
tcp.c:1943:      /* PCB bound to current local interface address? */
tcp.c:1944:      for (lpcb = tcp_listen_pcbs.listen_pcbs; lpcb != NULL; lpcb = next) {
tcp.c:1945:        next = lpcb->next;
tcp.c:1946:        /* PCB bound to current local interface address? */
tcp.c:1947:        if (ip_addr_cmp(&lpcb->local_ip, old_addr)) {
tcp.c:1948:          /* The PCB is listening to the old ipaddr and
tcp.c:1949:            * is set to listen to the new one instead */
tcp.c:1950:          ip_addr_copy(lpcb->local_ip, *new_addr);
tcp.c:1951:        }
tcp.c:1952:      }
tcp.c:1953:    }
tcp.c:1954:  }
tcp.c:1955:}
tcp.c:1956:
tcp.c:1957:const char*
tcp.c:1958:tcp_debug_state_str(enum tcp_state s)
tcp.c:1959:{
tcp.c:1960:  return tcp_state_str[s];
tcp.c:1961:}
tcp.c:1962:
tcp.c:1963:#if TCP_DEBUG || TCP_INPUT_DEBUG || TCP_OUTPUT_DEBUG
tcp.c:1964:/**
tcp.c:1965: * Print a tcp header for debugging purposes.
tcp.c:1966: *
tcp.c:1967: * @param tcphdr pointer to a struct tcp_hdr
tcp.c:1968: */
tcp.c:1969:void
tcp.c:1970:tcp_debug_print(struct tcp_hdr *tcphdr)
tcp.c:1971:{
tcp.c:1972:  LWIP_DEBUGF(TCP_DEBUG, ("TCP header:\n"));
tcp.c:1973:  LWIP_DEBUGF(TCP_DEBUG, ("+-------------------------------+\n"));
tcp.c:1974:  LWIP_DEBUGF(TCP_DEBUG, ("|    %5"U16_F"      |    %5"U16_F"      | (src port, dest port)\n",
tcp.c:1975:         lwip_ntohs(tcphdr->src), lwip_ntohs(tcphdr->dest)));
tcp.c:1976:  LWIP_DEBUGF(TCP_DEBUG, ("+-------------------------------+\n"));
tcp.c:1977:  LWIP_DEBUGF(TCP_DEBUG, ("|           %010"U32_F"          | (seq no)\n",
tcp.c:1978:          lwip_ntohl(tcphdr->seqno)));
tcp.c:1979:  LWIP_DEBUGF(TCP_DEBUG, ("+-------------------------------+\n"));
tcp.c:1980:  LWIP_DEBUGF(TCP_DEBUG, ("|           %010"U32_F"          | (ack no)\n",
tcp.c:1981:         lwip_ntohl(tcphdr->ackno)));
tcp.c:1982:  LWIP_DEBUGF(TCP_DEBUG, ("+-------------------------------+\n"));
tcp.c:1983:  LWIP_DEBUGF(TCP_DEBUG, ("| %2"U16_F" |   |%"U16_F"%"U16_F"%"U16_F"%"U16_F"%"U16_F"%"U16_F"|     %5"U16_F"     | (hdrlen, flags (",
tcp.c:1984:       TCPH_HDRLEN(tcphdr),
tcp.c:1985:         (u16_t)(TCPH_FLAGS(tcphdr) >> 5 & 1),
tcp.c:1986:         (u16_t)(TCPH_FLAGS(tcphdr) >> 4 & 1),
tcp.c:1987:         (u16_t)(TCPH_FLAGS(tcphdr) >> 3 & 1),
tcp.c:1988:         (u16_t)(TCPH_FLAGS(tcphdr) >> 2 & 1),
tcp.c:1989:         (u16_t)(TCPH_FLAGS(tcphdr) >> 1 & 1),
tcp.c:1990:         (u16_t)(TCPH_FLAGS(tcphdr)      & 1),
tcp.c:1991:         lwip_ntohs(tcphdr->wnd)));
tcp.c:1992:  tcp_debug_print_flags(TCPH_FLAGS(tcphdr));
tcp.c:1993:  LWIP_DEBUGF(TCP_DEBUG, ("), win)\n"));
tcp.c:1994:  LWIP_DEBUGF(TCP_DEBUG, ("+-------------------------------+\n"));
tcp.c:1995:  LWIP_DEBUGF(TCP_DEBUG, ("|    0x%04"X16_F"     |     %5"U16_F"     | (chksum, urgp)\n",
tcp.c:1996:         lwip_ntohs(tcphdr->chksum), lwip_ntohs(tcphdr->urgp)));
tcp.c:1997:  LWIP_DEBUGF(TCP_DEBUG, ("+-------------------------------+\n"));
tcp.c:1998:}
tcp.c:1999:
tcp.c:2000:/**
tcp.c:2001: * Print a tcp state for debugging purposes.
tcp.c:2002: *
tcp.c:2003: * @param s enum tcp_state to print
tcp.c:2004: */
tcp.c:2005:void
tcp.c:2006:tcp_debug_print_state(enum tcp_state s)
tcp.c:2007:{
tcp.c:2008:  LWIP_DEBUGF(TCP_DEBUG, ("State: %s\n", tcp_state_str[s]));
tcp.c:2009:}
tcp.c:2010:
tcp.c:2011:/**
tcp.c:2012: * Print tcp flags for debugging purposes.
tcp.c:2013: *
tcp.c:2014: * @param flags tcp flags, all active flags are printed
tcp.c:2015: */
tcp.c:2016:void
tcp.c:2017:tcp_debug_print_flags(u8_t flags)
tcp.c:2018:{
tcp.c:2019:  if (flags & TCP_FIN) {
tcp.c:2020:    LWIP_DEBUGF(TCP_DEBUG, ("FIN "));
tcp.c:2021:  }
tcp.c:2022:  if (flags & TCP_SYN) {
tcp.c:2023:    LWIP_DEBUGF(TCP_DEBUG, ("SYN "));
tcp.c:2024:  }
tcp.c:2025:  if (flags & TCP_RST) {
tcp.c:2026:    LWIP_DEBUGF(TCP_DEBUG, ("RST "));
tcp.c:2027:  }
tcp.c:2028:  if (flags & TCP_PSH) {
tcp.c:2029:    LWIP_DEBUGF(TCP_DEBUG, ("PSH "));
tcp.c:2030:  }
tcp.c:2031:  if (flags & TCP_ACK) {
tcp.c:2032:    LWIP_DEBUGF(TCP_DEBUG, ("ACK "));
tcp.c:2033:  }
tcp.c:2034:  if (flags & TCP_URG) {
tcp.c:2035:    LWIP_DEBUGF(TCP_DEBUG, ("URG "));
tcp.c:2036:  }
tcp.c:2037:  if (flags & TCP_ECE) {
tcp.c:2038:    LWIP_DEBUGF(TCP_DEBUG, ("ECE "));
tcp.c:2039:  }
tcp.c:2040:  if (flags & TCP_CWR) {
tcp.c:2041:    LWIP_DEBUGF(TCP_DEBUG, ("CWR "));
tcp.c:2042:  }
tcp.c:2043:  LWIP_DEBUGF(TCP_DEBUG, ("\n"));
tcp.c:2044:}
tcp.c:2045:
tcp.c:2046:/**
tcp.c:2047: * Print all tcp_pcbs in every list for debugging purposes.
tcp.c:2048: */
tcp.c:2049:void
tcp.c:2050:tcp_debug_print_pcbs(void)
tcp.c:2051:{
tcp.c:2052:  struct tcp_pcb *pcb;
tcp.c:2053:  struct tcp_pcb_listen *pcbl;
tcp.c:2054:
tcp.c:2055:  LWIP_DEBUGF(TCP_DEBUG, ("Active PCB states:\n"));
tcp.c:2056:  for (pcb = tcp_active_pcbs; pcb != NULL; pcb = pcb->next) {
tcp.c:2057:    LWIP_DEBUGF(TCP_DEBUG, ("Local port %"U16_F", foreign port %"U16_F" snd_nxt %"U32_F" rcv_nxt %"U32_F" ",
tcp.c:2058:                       pcb->local_port, pcb->remote_port,
tcp.c:2059:                       pcb->snd_nxt, pcb->rcv_nxt));
tcp.c:2060:    tcp_debug_print_state(pcb->state);
tcp.c:2061:  }
tcp.c:2062:
tcp.c:2063:  LWIP_DEBUGF(TCP_DEBUG, ("Listen PCB states:\n"));
tcp.c:2064:  for (pcbl = tcp_listen_pcbs.listen_pcbs; pcbl != NULL; pcbl = pcbl->next) {
tcp.c:2065:    LWIP_DEBUGF(TCP_DEBUG, ("Local port %"U16_F" ", pcbl->local_port));
tcp.c:2066:    tcp_debug_print_state(pcbl->state);
tcp.c:2067:  }
tcp.c:2068:
tcp.c:2069:  LWIP_DEBUGF(TCP_DEBUG, ("TIME-WAIT PCB states:\n"));
tcp.c:2070:  for (pcb = tcp_tw_pcbs; pcb != NULL; pcb = pcb->next) {
tcp.c:2071:    LWIP_DEBUGF(TCP_DEBUG, ("Local port %"U16_F", foreign port %"U16_F" snd_nxt %"U32_F" rcv_nxt %"U32_F" ",
tcp.c:2072:                       pcb->local_port, pcb->remote_port,
tcp.c:2073:                       pcb->snd_nxt, pcb->rcv_nxt));
tcp.c:2074:    tcp_debug_print_state(pcb->state);
tcp.c:2075:  }
tcp.c:2076:}
tcp.c:2077:
tcp.c:2078:/**
tcp.c:2079: * Check state consistency of the tcp_pcb lists.
tcp.c:2080: */
tcp.c:2081:s16_t
tcp.c:2082:tcp_pcbs_sane(void)
tcp.c:2083:{
tcp.c:2084:  struct tcp_pcb *pcb;
tcp.c:2085:  for (pcb = tcp_active_pcbs; pcb != NULL; pcb = pcb->next) {
tcp.c:2086:    LWIP_ASSERT("tcp_pcbs_sane: active pcb->state != CLOSED", pcb->state != CLOSED);
tcp.c:2087:    LWIP_ASSERT("tcp_pcbs_sane: active pcb->state != LISTEN", pcb->state != LISTEN);
tcp.c:2088:    LWIP_ASSERT("tcp_pcbs_sane: active pcb->state != TIME-WAIT", pcb->state != TIME_WAIT);
tcp.c:2089:  }
tcp.c:2090:  for (pcb = tcp_tw_pcbs; pcb != NULL; pcb = pcb->next) {
tcp.c:2091:    LWIP_ASSERT("tcp_pcbs_sane: tw pcb->state == TIME-WAIT", pcb->state == TIME_WAIT);
tcp.c:2092:  }
tcp.c:2093:  return 1;
tcp.c:2094:}
tcp.c:2095:#endif /* TCP_DEBUG */
tcp.c:2096:
tcp.c:2097:#endif /* LWIP_TCP */
ipv4/ip4.c:667:#if LWIP_TCP
ipv4/ip4.c:668:    case IP_PROTO_TCP:
ipv4/ip4.c:669:      MIB2_STATS_INC(mib2.ipindelivers);
ipv4/ip4.c:670:      tcp_input(p, inp);
ipv4/ip4.c:671:      break;
ipv4/ip4.c:672:#endif /* LWIP_TCP */
timeouts.c:72:#if LWIP_TCP
timeouts.c:73:  /* The TCP timer is a special case: it does not have to run always and
timeouts.c:74:     is triggered to start from TCP using tcp_timer_needed() */
timeouts.c:75:  {TCP_TMR_INTERVAL, HANDLER(tcp_tmr)},
timeouts.c:76:#endif /* LWIP_TCP */
timeouts.c:77:#if LWIP_IPV4
timeouts.c:78:#if IP_REASSEMBLY
timeouts.c:79:  {IP_TMR_INTERVAL, HANDLER(ip_reass_tmr)},
timeouts.c:80:#endif /* IP_REASSEMBLY */
timeouts.c:81:#if LWIP_ARP
timeouts.c:82:  {ARP_TMR_INTERVAL, HANDLER(etharp_tmr)},
timeouts.c:83:#endif /* LWIP_ARP */
timeouts.c:84:#if LWIP_DHCP
timeouts.c:85:  {DHCP_COARSE_TIMER_MSECS, HANDLER(dhcp_coarse_tmr)},
timeouts.c:86:  {DHCP_FINE_TIMER_MSECS, HANDLER(dhcp_fine_tmr)},
timeouts.c:87:#endif /* LWIP_DHCP */
timeouts.c:88:#if LWIP_AUTOIP
timeouts.c:89:  {AUTOIP_TMR_INTERVAL, HANDLER(autoip_tmr)},
timeouts.c:90:#endif /* LWIP_AUTOIP */
timeouts.c:91:#if LWIP_IGMP
timeouts.c:92:  {IGMP_TMR_INTERVAL, HANDLER(igmp_tmr)},
timeouts.c:93:#endif /* LWIP_IGMP */
timeouts.c:94:#endif /* LWIP_IPV4 */
timeouts.c:95:#if LWIP_DNS
timeouts.c:96:  {DNS_TMR_INTERVAL, HANDLER(dns_tmr)},
timeouts.c:97:#endif /* LWIP_DNS */
timeouts.c:98:#if LWIP_IPV6
timeouts.c:99:  {ND6_TMR_INTERVAL, HANDLER(nd6_tmr)},
timeouts.c:100:#if LWIP_IPV6_REASS
timeouts.c:101:  {IP6_REASS_TMR_INTERVAL, HANDLER(ip6_reass_tmr)},
timeouts.c:102:#endif /* LWIP_IPV6_REASS */
timeouts.c:103:#if LWIP_IPV6_MLD
timeouts.c:104:  {MLD6_TMR_INTERVAL, HANDLER(mld6_tmr)},
timeouts.c:105:#endif /* LWIP_IPV6_MLD */
timeouts.c:106:#endif /* LWIP_IPV6 */
timeouts.c:107:};
timeouts.c:108:
timeouts.c:109:#if LWIP_TIMERS && !LWIP_TIMERS_CUSTOM
timeouts.c:110:
timeouts.c:111:/** The one and only timeout list */
timeouts.c:112:static struct sys_timeo *next_timeout;
timeouts.c:113:static u32_t timeouts_last_time;
timeouts.c:114:
timeouts.c:115:#if LWIP_TCP
timeouts.c:116:/** global variable that shows if the tcp timer is currently scheduled or not */
timeouts.c:117:static int tcpip_tcp_timer_active;
timeouts.c:118:
timeouts.c:119:/**
timeouts.c:120: * Timer callback function that calls tcp_tmr() and reschedules itself.
timeouts.c:121: *
timeouts.c:122: * @param arg unused argument
timeouts.c:123: */
timeouts.c:124:static void
timeouts.c:125:tcpip_tcp_timer(void *arg)
timeouts.c:126:{
timeouts.c:127:  LWIP_UNUSED_ARG(arg);
timeouts.c:128:
timeouts.c:129:  /* call TCP timer handler */
timeouts.c:130:  tcp_tmr();
timeouts.c:131:  /* timer still needed? */
timeouts.c:132:  if (tcp_active_pcbs || tcp_tw_pcbs) {
timeouts.c:133:    /* restart timer */
timeouts.c:134:    sys_timeout(TCP_TMR_INTERVAL, tcpip_tcp_timer, NULL);
timeouts.c:135:  } else {
timeouts.c:136:    /* disable timer */
timeouts.c:137:    tcpip_tcp_timer_active = 0;
timeouts.c:138:  }
timeouts.c:139:}
timeouts.c:140:
timeouts.c:141:/**
timeouts.c:142: * Called from TCP_REG when registering a new PCB:
timeouts.c:143: * the reason is to have the TCP timer only running when
timeouts.c:144: * there are active (or time-wait) PCBs.
timeouts.c:145: */
timeouts.c:146:void
timeouts.c:147:tcp_timer_needed(void)
timeouts.c:148:{
timeouts.c:149:  /* timer is off but needed again? */
timeouts.c:150:  if (!tcpip_tcp_timer_active && (tcp_active_pcbs || tcp_tw_pcbs)) {
timeouts.c:151:    /* enable and start timer */
timeouts.c:152:    tcpip_tcp_timer_active = 1;
timeouts.c:153:    sys_timeout(TCP_TMR_INTERVAL, tcpip_tcp_timer, NULL);
timeouts.c:154:  }
timeouts.c:155:}
timeouts.c:156:#endif /* LWIP_TCP */
init.c:114:#if (LWIP_TCP && (MEMP_NUM_TCP_PCB<=0))
init.c:115:  #error "If you want to use TCP, you have to define MEMP_NUM_TCP_PCB>=1 in your lwipopts.h"
init.c:116:#endif
init.c:117:#if (LWIP_IGMP && (MEMP_NUM_IGMP_GROUP<=1))
init.c:118:  #error "If you want to use IGMP, you have to define MEMP_NUM_IGMP_GROUP>1 in your lwipopts.h"
init.c:119:#endif
init.c:120:#if (LWIP_IGMP && !LWIP_MULTICAST_TX_OPTIONS)
init.c:121:  #error "If you want to use IGMP, you have to define LWIP_MULTICAST_TX_OPTIONS==1 in your lwipopts.h"
init.c:122:#endif
init.c:123:#if (LWIP_IGMP && !LWIP_IPV4)
init.c:124:  #error "IGMP needs LWIP_IPV4 enabled in your lwipopts.h"
init.c:125:#endif
init.c:126:#if (LWIP_MULTICAST_TX_OPTIONS && !LWIP_IPV4)
init.c:127:  #error "LWIP_MULTICAST_TX_OPTIONS needs LWIP_IPV4 enabled in your lwipopts.h"
init.c:128:#endif
init.c:129:#if ((LWIP_NETCONN || LWIP_SOCKET) && (MEMP_NUM_TCPIP_MSG_API<=0))
init.c:130:  #error "If you want to use Sequential API, you have to define MEMP_NUM_TCPIP_MSG_API>=1 in your lwipopts.h"
init.c:131:#endif
init.c:132:/* There must be sufficient timeouts, taking into account requirements of the subsystems. */
init.c:133:#if LWIP_TIMERS && (MEMP_NUM_SYS_TIMEOUT < (LWIP_TCP + IP_REASSEMBLY + LWIP_ARP + (2*LWIP_DHCP) + LWIP_AUTOIP + LWIP_IGMP + LWIP_DNS + PPP_SUPPORT + (LWIP_IPV6 ? (1 + LWIP_IPV6_REASS + LWIP_IPV6_MLD) : 0)))
init.c:134:  #error "MEMP_NUM_SYS_TIMEOUT is too low to accomodate all required timeouts"
init.c:135:#endif
init.c:136:#if (IP_REASSEMBLY && (MEMP_NUM_REASSDATA > IP_REASS_MAX_PBUFS))
init.c:137:  #error "MEMP_NUM_REASSDATA > IP_REASS_MAX_PBUFS doesn't make sense since each struct ip_reassdata must hold 2 pbufs at least!"
init.c:138:#endif
init.c:139:#endif /* !MEMP_MEM_MALLOC */
init.c:140:#if LWIP_WND_SCALE
init.c:141:#if (LWIP_TCP && (TCP_WND > 0xffffffff))
init.c:142:  #error "If you want to use TCP, TCP_WND must fit in an u32_t, so, you have to reduce it in your lwipopts.h"
init.c:143:#endif
init.c:144:#if (LWIP_TCP && LWIP_WND_SCALE && (TCP_RCV_SCALE > 14))
init.c:145:  #error "The maximum valid window scale value is 14!"
init.c:146:#endif
init.c:147:#if (LWIP_TCP && (TCP_WND > (0xFFFFU << TCP_RCV_SCALE)))
init.c:148:  #error "TCP_WND is bigger than the configured LWIP_WND_SCALE allows!"
init.c:149:#endif
init.c:150:#if (LWIP_TCP && ((TCP_WND >> TCP_RCV_SCALE) == 0))
init.c:151:  #error "TCP_WND is too small for the configured LWIP_WND_SCALE (results in zero window)!"
init.c:152:#endif
init.c:153:#else /* LWIP_WND_SCALE */
init.c:154:#if (LWIP_TCP && (TCP_WND > 0xffff))
init.c:155:  #error "If you want to use TCP, TCP_WND must fit in an u16_t, so, you have to reduce it in your lwipopts.h (or enable window scaling)"
init.c:156:#endif
init.c:157:#endif /* LWIP_WND_SCALE */
init.c:158:#if (LWIP_TCP && (TCP_SND_QUEUELEN > 0xffff))
init.c:159:  #error "If you want to use TCP, TCP_SND_QUEUELEN must fit in an u16_t, so, you have to reduce it in your lwipopts.h"
init.c:160:#endif
init.c:161:#if (LWIP_TCP && (TCP_SND_QUEUELEN < 2))
init.c:162:  #error "TCP_SND_QUEUELEN must be at least 2 for no-copy TCP writes to work"
init.c:163:#endif
init.c:164:#if (LWIP_TCP && ((TCP_MAXRTX > 12) || (TCP_SYNMAXRTX > 12)))
init.c:165:  #error "If you want to use TCP, TCP_MAXRTX and TCP_SYNMAXRTX must less or equal to 12 (due to tcp_backoff table), so, you have to reduce them in your lwipopts.h"
init.c:166:#endif
init.c:167:#if (LWIP_TCP && TCP_LISTEN_BACKLOG && ((TCP_DEFAULT_LISTEN_BACKLOG < 0) || (TCP_DEFAULT_LISTEN_BACKLOG > 0xff)))
init.c:168:  #error "If you want to use TCP backlog, TCP_DEFAULT_LISTEN_BACKLOG must fit into an u8_t"
init.c:169:#endif
init.c:170:#if (LWIP_NETIF_API && (NO_SYS==1))
init.c:171:  #error "If you want to use NETIF API, you have to define NO_SYS=0 in your lwipopts.h"
init.c:172:#endif
init.c:173:#if ((LWIP_SOCKET || LWIP_NETCONN) && (NO_SYS==1))
init.c:174:  #error "If you want to use Sequential API, you have to define NO_SYS=0 in your lwipopts.h"
init.c:175:#endif
init.c:176:#if (LWIP_PPP_API && (NO_SYS==1))
init.c:177:  #error "If you want to use PPP API, you have to define NO_SYS=0 in your lwipopts.h"
init.c:178:#endif
init.c:179:#if (LWIP_PPP_API && (PPP_SUPPORT==0))
init.c:180:  #error "If you want to use PPP API, you have to enable PPP_SUPPORT in your lwipopts.h"
init.c:181:#endif
init.c:182:#if (((!LWIP_DHCP) || (!LWIP_AUTOIP)) && LWIP_DHCP_AUTOIP_COOP)
init.c:183:  #error "If you want to use DHCP/AUTOIP cooperation mode, you have to define LWIP_DHCP=1 and LWIP_AUTOIP=1 in your lwipopts.h"
init.c:184:#endif
init.c:185:#if (((!LWIP_DHCP) || (!LWIP_ARP)) && DHCP_DOES_ARP_CHECK)
init.c:186:  #error "If you want to use DHCP ARP checking, you have to define LWIP_DHCP=1 and LWIP_ARP=1 in your lwipopts.h"
init.c:187:#endif
init.c:188:#if (!LWIP_ARP && LWIP_AUTOIP)
init.c:189:  #error "If you want to use AUTOIP, you have to define LWIP_ARP=1 in your lwipopts.h"
init.c:190:#endif
init.c:191:#if (LWIP_TCP && ((LWIP_EVENT_API && LWIP_CALLBACK_API) || (!LWIP_EVENT_API && !LWIP_CALLBACK_API)))
init.c:192:  #error "One and exactly one of LWIP_EVENT_API and LWIP_CALLBACK_API has to be enabled in your lwipopts.h"
init.c:193:#endif
init.c:194:#if (MEM_LIBC_MALLOC && MEM_USE_POOLS)
init.c:195:  #error "MEM_LIBC_MALLOC and MEM_USE_POOLS may not both be simultaneously enabled in your lwipopts.h"
init.c:196:#endif
init.c:197:#if (MEM_USE_POOLS && !MEMP_USE_CUSTOM_POOLS)
init.c:198:  #error "MEM_USE_POOLS requires custom pools (MEMP_USE_CUSTOM_POOLS) to be enabled in your lwipopts.h"
init.c:199:#endif
init.c:200:#if (PBUF_POOL_BUFSIZE <= MEM_ALIGNMENT)
init.c:201:  #error "PBUF_POOL_BUFSIZE must be greater than MEM_ALIGNMENT or the offset may take the full first pbuf"
init.c:202:#endif
init.c:203:#if (DNS_LOCAL_HOSTLIST && !DNS_LOCAL_HOSTLIST_IS_DYNAMIC && !(defined(DNS_LOCAL_HOSTLIST_INIT)))
init.c:204:  #error "you have to define define DNS_LOCAL_HOSTLIST_INIT {{'host1', 0x123}, {'host2', 0x234}} to initialize DNS_LOCAL_HOSTLIST"
init.c:205:#endif
init.c:206:#if PPP_SUPPORT && !PPPOS_SUPPORT && !PPPOE_SUPPORT && !PPPOL2TP_SUPPORT
init.c:207:  #error "PPP_SUPPORT needs at least one of PPPOS_SUPPORT, PPPOE_SUPPORT or PPPOL2TP_SUPPORT turned on"
init.c:208:#endif
init.c:209:#if PPP_SUPPORT && !PPP_IPV4_SUPPORT && !PPP_IPV6_SUPPORT
init.c:210:  #error "PPP_SUPPORT needs PPP_IPV4_SUPPORT and/or PPP_IPV6_SUPPORT turned on"
init.c:211:#endif
init.c:212:#if PPP_SUPPORT && PPP_IPV4_SUPPORT && !LWIP_IPV4
init.c:213:  #error "PPP_IPV4_SUPPORT needs LWIP_IPV4 turned on"
init.c:214:#endif
init.c:215:#if PPP_SUPPORT && PPP_IPV6_SUPPORT && !LWIP_IPV6
init.c:216:  #error "PPP_IPV6_SUPPORT needs LWIP_IPV6 turned on"
init.c:217:#endif
init.c:218:#if !LWIP_ETHERNET && (LWIP_ARP || PPPOE_SUPPORT)
init.c:219:  #error "LWIP_ETHERNET needs to be turned on for LWIP_ARP or PPPOE_SUPPORT"
init.c:220:#endif
init.c:221:#if (LWIP_IGMP || LWIP_IPV6) && !defined(LWIP_RAND)
init.c:222:  #error "When using IGMP or IPv6, LWIP_RAND() needs to be defined to a random-function returning an u32_t random value (in arch/cc.h)"
init.c:223:#endif
init.c:224:#if LWIP_TCPIP_CORE_LOCKING_INPUT && !LWIP_TCPIP_CORE_LOCKING
init.c:225:  #error "When using LWIP_TCPIP_CORE_LOCKING_INPUT, LWIP_TCPIP_CORE_LOCKING must be enabled, too"
init.c:226:#endif
init.c:227:#if LWIP_TCP && LWIP_NETIF_TX_SINGLE_PBUF && !TCP_OVERSIZE
init.c:228:  #error "LWIP_NETIF_TX_SINGLE_PBUF needs TCP_OVERSIZE enabled to create single-pbuf TCP packets"
init.c:229:#endif
init.c:230:#if LWIP_NETCONN && LWIP_TCP
init.c:231:#if NETCONN_COPY != TCP_WRITE_FLAG_COPY
init.c:232:  #error "NETCONN_COPY != TCP_WRITE_FLAG_COPY"
init.c:233:#endif
init.c:234:#if NETCONN_MORE != TCP_WRITE_FLAG_MORE
init.c:235:  #error "NETCONN_MORE != TCP_WRITE_FLAG_MORE"
init.c:236:#endif
init.c:237:#endif /* LWIP_NETCONN && LWIP_TCP */
init.c:238:#if LWIP_SOCKET
init.c:239:/* Check that the SO_* socket options and SOF_* lwIP-internal flags match */
init.c:240:#if SO_REUSEADDR != SOF_REUSEADDR
init.c:241:  #error "WARNING: SO_REUSEADDR != SOF_REUSEADDR"
init.c:242:#endif
init.c:243:#if SO_KEEPALIVE != SOF_KEEPALIVE
init.c:244:  #error "WARNING: SO_KEEPALIVE != SOF_KEEPALIVE"
init.c:245:#endif
init.c:246:#if SO_BROADCAST != SOF_BROADCAST
init.c:247:  #error "WARNING: SO_BROADCAST != SOF_BROADCAST"
init.c:248:#endif
init.c:249:#endif /* LWIP_SOCKET */
init.c:250:
init.c:251:
init.c:252:/* Compile-time checks for deprecated options.
init.c:253: */
init.c:254:#ifdef MEMP_NUM_TCPIP_MSG
init.c:255:  #error "MEMP_NUM_TCPIP_MSG option is deprecated. Remove it from your lwipopts.h."
init.c:256:#endif
init.c:257:#ifdef TCP_REXMIT_DEBUG
init.c:258:  #error "TCP_REXMIT_DEBUG option is deprecated. Remove it from your lwipopts.h."
init.c:259:#endif
init.c:260:#ifdef RAW_STATS
init.c:261:  #error "RAW_STATS option is deprecated. Remove it from your lwipopts.h."
init.c:262:#endif
init.c:263:#ifdef ETHARP_QUEUE_FIRST
init.c:264:  #error "ETHARP_QUEUE_FIRST option is deprecated. Remove it from your lwipopts.h."
init.c:265:#endif
init.c:266:#ifdef ETHARP_ALWAYS_INSERT
init.c:267:  #error "ETHARP_ALWAYS_INSERT option is deprecated. Remove it from your lwipopts.h."
init.c:268:#endif
init.c:269:#if !NO_SYS && LWIP_TCPIP_CORE_LOCKING && LWIP_COMPAT_MUTEX && !defined(LWIP_COMPAT_MUTEX_ALLOWED)
init.c:270:  #error "LWIP_COMPAT_MUTEX cannot prevent priority inversion. It is recommended to implement priority-aware mutexes. (Define LWIP_COMPAT_MUTEX_ALLOWED to disable this error.)"
init.c:271:#endif
init.c:272:
init.c:273:#ifndef LWIP_DISABLE_TCP_SANITY_CHECKS
init.c:274:#define LWIP_DISABLE_TCP_SANITY_CHECKS  0
init.c:275:#endif
init.c:276:#ifndef LWIP_DISABLE_MEMP_SANITY_CHECKS
init.c:277:#define LWIP_DISABLE_MEMP_SANITY_CHECKS 0
init.c:278:#endif
init.c:279:
init.c:280:/* MEMP sanity checks */
init.c:281:#if MEMP_MEM_MALLOC
init.c:282:#if !LWIP_DISABLE_MEMP_SANITY_CHECKS
init.c:283:#if LWIP_NETCONN || LWIP_SOCKET
init.c:284:#if !MEMP_NUM_NETCONN && LWIP_SOCKET
init.c:285:#error "lwip_sanity_check: WARNING: MEMP_NUM_NETCONN cannot be 0 when using sockets!"
init.c:286:#endif
init.c:287:#else /* MEMP_MEM_MALLOC */
init.c:288:#if MEMP_NUM_NETCONN > (MEMP_NUM_TCP_PCB+MEMP_NUM_TCP_PCB_LISTEN+MEMP_NUM_UDP_PCB+MEMP_NUM_RAW_PCB)
init.c:289:#error "lwip_sanity_check: WARNING: MEMP_NUM_NETCONN should be less than the sum of MEMP_NUM_{TCP,RAW,UDP}_PCB+MEMP_NUM_TCP_PCB_LISTEN. If you know what you are doing, define LWIP_DISABLE_MEMP_SANITY_CHECKS to 1 to disable this error."
init.c:290:#endif
init.c:291:#endif /* LWIP_NETCONN || LWIP_SOCKET */
init.c:292:#endif /* !LWIP_DISABLE_MEMP_SANITY_CHECKS */
init.c:293:#if MEM_USE_POOLS
init.c:294:#error "MEMP_MEM_MALLOC and MEM_USE_POOLS cannot be enabled at the same time"
init.c:295:#endif
init.c:296:#ifdef LWIP_HOOK_MEMP_AVAILABLE
init.c:297:#error "LWIP_HOOK_MEMP_AVAILABLE doesn't make sense with MEMP_MEM_MALLOC"
init.c:298:#endif
init.c:299:#endif /* MEMP_MEM_MALLOC */
init.c:300:
init.c:301:/* TCP sanity checks */
init.c:302:#if !LWIP_DISABLE_TCP_SANITY_CHECKS
init.c:303:#if LWIP_TCP
init.c:304:#if !MEMP_MEM_MALLOC && (MEMP_NUM_TCP_SEG < TCP_SND_QUEUELEN)
init.c:305:  #error "lwip_sanity_check: WARNING: MEMP_NUM_TCP_SEG should be at least as big as TCP_SND_QUEUELEN. If you know what you are doing, define LWIP_DISABLE_TCP_SANITY_CHECKS to 1 to disable this error."
init.c:306:#endif
init.c:307:#if TCP_SND_BUF < (2 * TCP_MSS)
init.c:308:  #error "lwip_sanity_check: WARNING: TCP_SND_BUF must be at least as much as (2 * TCP_MSS) for things to work smoothly. If you know what you are doing, define LWIP_DISABLE_TCP_SANITY_CHECKS to 1 to disable this error."
init.c:309:#endif
init.c:310:#if TCP_SND_QUEUELEN < (2 * (TCP_SND_BUF / TCP_MSS))
init.c:311:  #error "lwip_sanity_check: WARNING: TCP_SND_QUEUELEN must be at least as much as (2 * TCP_SND_BUF/TCP_MSS) for things to work. If you know what you are doing, define LWIP_DISABLE_TCP_SANITY_CHECKS to 1 to disable this error."
init.c:312:#endif
init.c:313:#if TCP_SNDLOWAT >= TCP_SND_BUF
init.c:314:  #error "lwip_sanity_check: WARNING: TCP_SNDLOWAT must be less than TCP_SND_BUF. If you know what you are doing, define LWIP_DISABLE_TCP_SANITY_CHECKS to 1 to disable this error."
init.c:315:#endif
init.c:316:#if TCP_SNDLOWAT >= (0xFFFF - (4 * TCP_MSS))
init.c:317:  #error "lwip_sanity_check: WARNING: TCP_SNDLOWAT must at least be 4*MSS below u16_t overflow!"
init.c:318:#endif
init.c:319:#if TCP_SNDQUEUELOWAT >= TCP_SND_QUEUELEN
init.c:320:  #error "lwip_sanity_check: WARNING: TCP_SNDQUEUELOWAT must be less than TCP_SND_QUEUELEN. If you know what you are doing, define LWIP_DISABLE_TCP_SANITY_CHECKS to 1 to disable this error."
init.c:321:#endif
init.c:322:#if !MEMP_MEM_MALLOC && PBUF_POOL_SIZE && (PBUF_POOL_BUFSIZE <= (PBUF_LINK_ENCAPSULATION_HLEN + PBUF_LINK_HLEN + PBUF_IP_HLEN + PBUF_TRANSPORT_HLEN))
init.c:323:  #error "lwip_sanity_check: WARNING: PBUF_POOL_BUFSIZE does not provide enough space for protocol headers. If you know what you are doing, define LWIP_DISABLE_TCP_SANITY_CHECKS to 1 to disable this error."
init.c:324:#endif
init.c:325:#if !MEMP_MEM_MALLOC && PBUF_POOL_SIZE && (TCP_WND > (PBUF_POOL_SIZE * (PBUF_POOL_BUFSIZE - (PBUF_LINK_ENCAPSULATION_HLEN + PBUF_LINK_HLEN + PBUF_IP_HLEN + PBUF_TRANSPORT_HLEN))))
init.c:326:  #error "lwip_sanity_check: WARNING: TCP_WND is larger than space provided by PBUF_POOL_SIZE * (PBUF_POOL_BUFSIZE - protocol headers). If you know what you are doing, define LWIP_DISABLE_TCP_SANITY_CHECKS to 1 to disable this error."
init.c:327:#endif
init.c:328:#if TCP_WND < TCP_MSS
init.c:329:  #error "lwip_sanity_check: WARNING: TCP_WND is smaller than MSS. If you know what you are doing, define LWIP_DISABLE_TCP_SANITY_CHECKS to 1 to disable this error."
init.c:330:#endif
init.c:331:#endif /* LWIP_TCP */
init.c:332:#endif /* !LWIP_DISABLE_TCP_SANITY_CHECKS */
init.c:333:
init.c:334:/**
init.c:335: * @ingroup lwip_nosys
init.c:336: * Initialize all modules.
init.c:337: * Use this in NO_SYS mode. Use tcpip_init() otherwise.
init.c:338: */
init.c:339:void
init.c:340:lwip_init(void)
init.c:341:{
init.c:342:#ifndef LWIP_SKIP_PACKING_CHECK
init.c:343:  LWIP_ASSERT("Struct packing not implemented correctly. Check your lwIP port.", sizeof(struct packed_struct_test) == PACKED_STRUCT_TEST_EXPECTED_SIZE);
init.c:344:#endif
init.c:345:
init.c:346:  /* Modules initialization */
init.c:347:  stats_init();
init.c:348:#if !NO_SYS
init.c:349:  sys_init();
init.c:350:#endif /* !NO_SYS */
init.c:351:  mem_init();
init.c:352:  memp_init();
init.c:353:  pbuf_init();
init.c:354:  netif_init();
init.c:355:#if LWIP_IPV4
init.c:356:  ip_init();
init.c:357:#if LWIP_ARP
init.c:358:  etharp_init();
init.c:359:#endif /* LWIP_ARP */
init.c:360:#endif /* LWIP_IPV4 */
init.c:361:#if LWIP_RAW
init.c:362:  raw_init();
init.c:363:#endif /* LWIP_RAW */
init.c:364:#if LWIP_UDP
init.c:365:  udp_init();
init.c:366:#endif /* LWIP_UDP */
init.c:367:#if LWIP_TCP
init.c:368:  tcp_init();
init.c:369:#endif /* LWIP_TCP */
ipv6/ip6.c:738:#if LWIP_TCP
ipv6/ip6.c:739:    case IP6_NEXTH_TCP:
ipv6/ip6.c:740:      /* Point to payload. */
ipv6/ip6.c:741:      pbuf_header(p, -(s16_t)ip_data.current_ip_header_tot_len);
ipv6/ip6.c:742:      tcp_input(p, inp);
ipv6/ip6.c:743:      break;
ipv6/ip6.c:744:#endif /* LWIP_TCP */
netif.c:389:#if LWIP_TCP
netif.c:390:    tcp_netif_ip_addr_changed(netif_ip_addr4(netif), NULL);
netif.c:391:#endif /* LWIP_TCP */
netif.c:392:#if LWIP_UDP
netif.c:393:    udp_netif_ip_addr_changed(netif_ip_addr4(netif), NULL);
netif.c:394:#endif /* LWIP_UDP */
netif.c:395:#if LWIP_RAW
netif.c:396:    raw_netif_ip_addr_changed(netif_ip_addr4(netif), NULL);
netif.c:397:#endif /* LWIP_RAW */
netif.c:398:  }
netif.c:399:
netif.c:400:#if LWIP_IGMP
netif.c:401:  /* stop IGMP processing */
netif.c:402:  if (netif->flags & NETIF_FLAG_IGMP) {
netif.c:403:    igmp_stop(netif);
netif.c:404:  }
netif.c:405:#endif /* LWIP_IGMP */
netif.c:406:#endif /* LWIP_IPV4*/
netif.c:407:
netif.c:408:#if LWIP_IPV6
netif.c:409:  for (i = 0; i < LWIP_IPV6_NUM_ADDRESSES; i++) {
netif.c:410:    if (ip6_addr_isvalid(netif_ip6_addr_state(netif, i))) {
netif.c:411:#if LWIP_TCP
netif.c:412:      tcp_netif_ip_addr_changed(netif_ip_addr6(netif, i), NULL);
netif.c:413:#endif /* LWIP_TCP */
netif.c:414:#if LWIP_UDP
netif.c:415:      udp_netif_ip_addr_changed(netif_ip_addr6(netif, i), NULL);
netif.c:416:#endif /* LWIP_UDP */
netif.c:417:#if LWIP_RAW
netif.c:418:    raw_netif_ip_addr_changed(netif_ip_addr6(netif, i), NULL);
netif.c:419:#endif /* LWIP_RAW */
netif.c:420:    }
netif.c:421:  }
netif.c:422:#if LWIP_IPV6_MLD
netif.c:423:  /* stop MLD processing */
netif.c:424:  mld6_stop(netif);
netif.c:425:#endif /* LWIP_IPV6_MLD */
netif.c:426:#endif /* LWIP_IPV6 */
netif.c:427:  if (netif_is_up(netif)) {
netif.c:428:    /* set netif down before removing (call callback function) */
netif.c:429:    netif_set_down(netif);
netif.c:430:  }
netif.c:431:
netif.c:432:  mib2_remove_ip4(netif);
netif.c:433:
netif.c:434:  /* this netif is default? */
netif.c:435:  if (netif_default == netif) {
netif.c:436:    /* reset default netif */
netif.c:437:    netif_set_default(NULL);
netif.c:438:  }
netif.c:439:  /*  is it the first netif? */
netif.c:440:  if (netif_list == netif) {
netif.c:441:    netif_list = netif->next;
netif.c:442:  } else {
netif.c:443:    /*  look for netif further down the list */
netif.c:444:    struct netif * tmp_netif;
netif.c:445:    for (tmp_netif = netif_list; tmp_netif != NULL; tmp_netif = tmp_netif->next) {
netif.c:446:      if (tmp_netif->next == netif) {
netif.c:447:        tmp_netif->next = netif->next;
netif.c:448:        break;
netif.c:449:      }
netif.c:450:    }
netif.c:451:    if (tmp_netif == NULL) {
netif.c:452:      return; /* netif is not on the list */
netif.c:453:    }
netif.c:454:  }
netif.c:455:  mib2_netif_removed(netif);
netif.c:456:#if LWIP_NETIF_REMOVE_CALLBACK
netif.c:457:  if (netif->remove_callback) {
netif.c:458:    netif->remove_callback(netif);
netif.c:459:  }
netif.c:460:#endif /* LWIP_NETIF_REMOVE_CALLBACK */
netif.c:461:  LWIP_DEBUGF( NETIF_DEBUG, ("netif_remove: removed netif\n") );
netif.c:462:}
netif.c:463:
netif.c:464:/**
netif.c:465: * @ingroup netif
netif.c:466: * Find a network interface by searching for its name
netif.c:467: *
netif.c:468: * @param name the name of the netif (like netif->name) plus concatenated number
netif.c:469: * in ascii representation (e.g. 'en0')
netif.c:470: */
netif.c:471:struct netif *
netif.c:472:netif_find(const char *name)
netif.c:473:{
netif.c:474:  struct netif *netif;
netif.c:475:  u8_t num;
netif.c:476:
netif.c:477:  if (name == NULL) {
netif.c:478:    return NULL;
netif.c:479:  }
netif.c:480:
netif.c:481:  num = name[2] - '0';
netif.c:482:
netif.c:483:  for (netif = netif_list; netif != NULL; netif = netif->next) {
netif.c:484:    if (num == netif->num &&
netif.c:485:       name[0] == netif->name[0] &&
netif.c:486:       name[1] == netif->name[1]) {
netif.c:487:      LWIP_DEBUGF(NETIF_DEBUG, ("netif_find: found %c%c\n", name[0], name[1]));
netif.c:488:      return netif;
netif.c:489:    }
netif.c:490:  }
netif.c:491:  LWIP_DEBUGF(NETIF_DEBUG, ("netif_find: didn't find %c%c\n", name[0], name[1]));
netif.c:492:  return NULL;
netif.c:493:}
netif.c:494:
netif.c:495:#if LWIP_IPV4
netif.c:496:/**
netif.c:497: * @ingroup netif_ip4
netif.c:498: * Change the IP address of a network interface
netif.c:499: *
netif.c:500: * @param netif the network interface to change
netif.c:501: * @param ipaddr the new IP address
netif.c:502: *
netif.c:503: * @note call netif_set_addr() if you also want to change netmask and
netif.c:504: * default gateway
netif.c:505: */
netif.c:506:void
netif.c:507:netif_set_ipaddr(struct netif *netif, const ip4_addr_t *ipaddr)
netif.c:508:{
netif.c:509:  ip_addr_t new_addr;
netif.c:510:  *ip_2_ip4(&new_addr) = (ipaddr ? *ipaddr : *IP4_ADDR_ANY4);
netif.c:511:  IP_SET_TYPE_VAL(new_addr, IPADDR_TYPE_V4);
netif.c:512:
netif.c:513:  /* address is actually being changed? */
netif.c:514:  if (ip4_addr_cmp(ip_2_ip4(&new_addr), netif_ip4_addr(netif)) == 0) {
netif.c:515:    LWIP_DEBUGF(NETIF_DEBUG | LWIP_DBG_STATE, ("netif_set_ipaddr: netif address being changed\n"));
netif.c:516:#if LWIP_TCP
netif.c:517:    tcp_netif_ip_addr_changed(netif_ip_addr4(netif), &new_addr);
netif.c:518:#endif /* LWIP_TCP */
netif.c:519:#if LWIP_UDP
netif.c:520:    udp_netif_ip_addr_changed(netif_ip_addr4(netif), &new_addr);
netif.c:521:#endif /* LWIP_UDP */
netif.c:522:#if LWIP_RAW
netif.c:523:    raw_netif_ip_addr_changed(netif_ip_addr4(netif), &new_addr);
netif.c:524:#endif /* LWIP_RAW */
netif.c:525:
netif.c:526:    mib2_remove_ip4(netif);
netif.c:527:    mib2_remove_route_ip4(0, netif);
netif.c:528:    /* set new IP address to netif */
netif.c:529:    ip4_addr_set(ip_2_ip4(&netif->ip_addr), ipaddr);
netif.c:530:    IP_SET_TYPE_VAL(netif->ip_addr, IPADDR_TYPE_V4);
netif.c:531:    mib2_add_ip4(netif);
netif.c:532:    mib2_add_route_ip4(0, netif);
netif.c:533:
netif.c:534:    netif_issue_reports(netif, NETIF_REPORT_TYPE_IPV4);
netif.c:535:
netif.c:536:    NETIF_STATUS_CALLBACK(netif);
netif.c:537:  }
netif.c:538:
netif.c:539:  LWIP_DEBUGF(NETIF_DEBUG | LWIP_DBG_TRACE | LWIP_DBG_STATE, ("netif: IP address of interface %c%c set to %"U16_F".%"U16_F".%"U16_F".%"U16_F"\n",
netif.c:540:    netif->name[0], netif->name[1],
netif.c:541:    ip4_addr1_16(netif_ip4_addr(netif)),
netif.c:542:    ip4_addr2_16(netif_ip4_addr(netif)),
netif.c:543:    ip4_addr3_16(netif_ip4_addr(netif)),
netif.c:544:    ip4_addr4_16(netif_ip4_addr(netif))));
netif.c:545:}
netif.c:546:
netif.c:547:/**
netif.c:548: * @ingroup netif_ip4
netif.c:549: * Change the default gateway for a network interface
netif.c:550: *
netif.c:551: * @param netif the network interface to change
netif.c:552: * @param gw the new default gateway
netif.c:553: *
netif.c:554: * @note call netif_set_addr() if you also want to change ip address and netmask
netif.c:555: */
netif.c:556:void
netif.c:557:netif_set_gw(struct netif *netif, const ip4_addr_t *gw)
netif.c:558:{
netif.c:559:  ip4_addr_set(ip_2_ip4(&netif->gw), gw);
netif.c:560:  IP_SET_TYPE_VAL(netif->gw, IPADDR_TYPE_V4);
netif.c:561:  LWIP_DEBUGF(NETIF_DEBUG | LWIP_DBG_TRACE | LWIP_DBG_STATE, ("netif: GW address of interface %c%c set to %"U16_F".%"U16_F".%"U16_F".%"U16_F"\n",
netif.c:562:    netif->name[0], netif->name[1],
netif.c:563:    ip4_addr1_16(netif_ip4_gw(netif)),
netif.c:564:    ip4_addr2_16(netif_ip4_gw(netif)),
netif.c:565:    ip4_addr3_16(netif_ip4_gw(netif)),
netif.c:566:    ip4_addr4_16(netif_ip4_gw(netif))));
netif.c:567:}
netif.c:568:
netif.c:569:/**
netif.c:570: * @ingroup netif_ip4
netif.c:571: * Change the netmask of a network interface
netif.c:572: *
netif.c:573: * @param netif the network interface to change
netif.c:574: * @param netmask the new netmask
netif.c:575: *
netif.c:576: * @note call netif_set_addr() if you also want to change ip address and
netif.c:577: * default gateway
netif.c:578: */
netif.c:579:void
netif.c:580:netif_set_netmask(struct netif *netif, const ip4_addr_t *netmask)
netif.c:581:{
netif.c:582:  mib2_remove_route_ip4(0, netif);
netif.c:583:  /* set new netmask to netif */
netif.c:584:  ip4_addr_set(ip_2_ip4(&netif->netmask), netmask);
netif.c:585:  IP_SET_TYPE_VAL(netif->netmask, IPADDR_TYPE_V4);
netif.c:586:  mib2_add_route_ip4(0, netif);
netif.c:587:  LWIP_DEBUGF(NETIF_DEBUG | LWIP_DBG_TRACE | LWIP_DBG_STATE, ("netif: netmask of interface %c%c set to %"U16_F".%"U16_F".%"U16_F".%"U16_F"\n",
netif.c:588:    netif->name[0], netif->name[1],
netif.c:589:    ip4_addr1_16(netif_ip4_netmask(netif)),
netif.c:590:    ip4_addr2_16(netif_ip4_netmask(netif)),
netif.c:591:    ip4_addr3_16(netif_ip4_netmask(netif)),
netif.c:592:    ip4_addr4_16(netif_ip4_netmask(netif))));
netif.c:593:}
netif.c:594:#endif /* LWIP_IPV4 */
netif.c:595:
netif.c:596:/**
netif.c:597: * @ingroup netif
netif.c:598: * Set a network interface as the default network interface
netif.c:599: * (used to output all packets for which no specific route is found)
netif.c:600: *
netif.c:601: * @param netif the default network interface
netif.c:602: */
netif.c:603:void
netif.c:604:netif_set_default(struct netif *netif)
netif.c:605:{
netif.c:606:  if (netif == NULL) {
netif.c:607:    /* remove default route */
netif.c:608:    mib2_remove_route_ip4(1, netif);
netif.c:609:  } else {
netif.c:610:    /* install default route */
netif.c:611:    mib2_add_route_ip4(1, netif);
netif.c:612:  }
netif.c:613:  netif_default = netif;
netif.c:614:  LWIP_DEBUGF(NETIF_DEBUG, ("netif: setting default interface %c%c\n",
netif.c:615:           netif ? netif->name[0] : '\'', netif ? netif->name[1] : '\''));
netif.c:616:}
netif.c:617:
netif.c:618:/**
netif.c:619: * @ingroup netif
netif.c:620: * Bring an interface up, available for processing
netif.c:621: * traffic.
netif.c:622: */
netif.c:623:void
netif.c:624:netif_set_up(struct netif *netif)
netif.c:625:{
netif.c:626:  if (!(netif->flags & NETIF_FLAG_UP)) {
netif.c:627:    netif->flags |= NETIF_FLAG_UP;
netif.c:628:
netif.c:629:    MIB2_COPY_SYSUPTIME_TO(&netif->ts);
netif.c:630:
netif.c:631:    NETIF_STATUS_CALLBACK(netif);
netif.c:632:
netif.c:633:    if (netif->flags & NETIF_FLAG_LINK_UP) {
netif.c:634:      netif_issue_reports(netif, NETIF_REPORT_TYPE_IPV4|NETIF_REPORT_TYPE_IPV6);
netif.c:635:    }
netif.c:636:  }
netif.c:637:}
netif.c:638:
netif.c:639:/** Send ARP/IGMP/MLD/RS events, e.g. on link-up/netif-up or addr-change
netif.c:640: */
netif.c:641:static void
netif.c:642:netif_issue_reports(struct netif* netif, u8_t report_type)
netif.c:643:{
netif.c:644:#if LWIP_IPV4
netif.c:645:  if ((report_type & NETIF_REPORT_TYPE_IPV4) &&
netif.c:646:      !ip4_addr_isany_val(*netif_ip4_addr(netif))) {
netif.c:647:#if LWIP_ARP
netif.c:648:    /* For Ethernet network interfaces, we would like to send a "gratuitous ARP" */
netif.c:649:    if (netif->flags & (NETIF_FLAG_ETHARP)) {
netif.c:650:      etharp_gratuitous(netif);
netif.c:651:    }
netif.c:652:#endif /* LWIP_ARP */
netif.c:653:
netif.c:654:#if LWIP_IGMP
netif.c:655:    /* resend IGMP memberships */
netif.c:656:    if (netif->flags & NETIF_FLAG_IGMP) {
netif.c:657:      igmp_report_groups(netif);
netif.c:658:    }
netif.c:659:#endif /* LWIP_IGMP */
netif.c:660:  }
netif.c:661:#endif /* LWIP_IPV4 */
netif.c:662:
netif.c:663:#if LWIP_IPV6
netif.c:664:  if (report_type & NETIF_REPORT_TYPE_IPV6) {
netif.c:665:#if LWIP_IPV6_MLD
netif.c:666:    /* send mld memberships */
netif.c:667:    mld6_report_groups(netif);
netif.c:668:#endif /* LWIP_IPV6_MLD */
netif.c:669:#if LWIP_IPV6_SEND_ROUTER_SOLICIT
netif.c:670:    /* Send Router Solicitation messages. */
netif.c:671:    netif->rs_count = LWIP_ND6_MAX_MULTICAST_SOLICIT;
netif.c:672:#endif /* LWIP_IPV6_SEND_ROUTER_SOLICIT */
netif.c:673:  }
netif.c:674:#endif /* LWIP_IPV6 */
netif.c:675:}
netif.c:676:
netif.c:677:/**
netif.c:678: * @ingroup netif
netif.c:679: * Bring an interface down, disabling any traffic processing.
netif.c:680: */
netif.c:681:void
netif.c:682:netif_set_down(struct netif *netif)
netif.c:683:{
netif.c:684:  if (netif->flags & NETIF_FLAG_UP) {
netif.c:685:    netif->flags &= ~NETIF_FLAG_UP;
netif.c:686:    MIB2_COPY_SYSUPTIME_TO(&netif->ts);
netif.c:687:
netif.c:688:#if LWIP_IPV4 && LWIP_ARP
netif.c:689:    if (netif->flags & NETIF_FLAG_ETHARP) {
netif.c:690:      etharp_cleanup_netif(netif);
netif.c:691:    }
netif.c:692:#endif /* LWIP_IPV4 && LWIP_ARP */
netif.c:693:
netif.c:694:#if LWIP_IPV6
netif.c:695:    nd6_cleanup_netif(netif);
netif.c:696:#endif /* LWIP_IPV6 */
netif.c:697:
netif.c:698:    NETIF_STATUS_CALLBACK(netif);
netif.c:699:  }
netif.c:700:}
netif.c:701:
netif.c:702:#if LWIP_NETIF_STATUS_CALLBACK
netif.c:703:/**
netif.c:704: * @ingroup netif
netif.c:705: * Set callback to be called when interface is brought up/down or address is changed while up
netif.c:706: */
netif.c:707:void
netif.c:708:netif_set_status_callback(struct netif *netif, netif_status_callback_fn status_callback)
netif.c:709:{
netif.c:710:  if (netif) {
netif.c:711:    netif->status_callback = status_callback;
netif.c:712:  }
netif.c:713:}
netif.c:714:#endif /* LWIP_NETIF_STATUS_CALLBACK */
netif.c:715:
netif.c:716:#if LWIP_NETIF_REMOVE_CALLBACK
netif.c:717:/**
netif.c:718: * @ingroup netif
netif.c:719: * Set callback to be called when the interface has been removed
netif.c:720: */
netif.c:721:void
netif.c:722:netif_set_remove_callback(struct netif *netif, netif_status_callback_fn remove_callback)
netif.c:723:{
netif.c:724:  if (netif) {
netif.c:725:    netif->remove_callback = remove_callback;
netif.c:726:  }
netif.c:727:}
netif.c:728:#endif /* LWIP_NETIF_REMOVE_CALLBACK */
netif.c:729:
netif.c:730:/**
netif.c:731: * @ingroup netif
netif.c:732: * Called by a driver when its link goes up
netif.c:733: */
netif.c:734:void
netif.c:735:netif_set_link_up(struct netif *netif)
netif.c:736:{
netif.c:737:  if (!(netif->flags & NETIF_FLAG_LINK_UP)) {
netif.c:738:    netif->flags |= NETIF_FLAG_LINK_UP;
netif.c:739:
netif.c:740:#if LWIP_DHCP
netif.c:741:    dhcp_network_changed(netif);
netif.c:742:#endif /* LWIP_DHCP */
netif.c:743:
netif.c:744:#if LWIP_AUTOIP
netif.c:745:    autoip_network_changed(netif);
netif.c:746:#endif /* LWIP_AUTOIP */
netif.c:747:
netif.c:748:    if (netif->flags & NETIF_FLAG_UP) {
netif.c:749:      netif_issue_reports(netif, NETIF_REPORT_TYPE_IPV4|NETIF_REPORT_TYPE_IPV6);
netif.c:750:    }
netif.c:751:    NETIF_LINK_CALLBACK(netif);
netif.c:752:  }
netif.c:753:}
netif.c:754:
netif.c:755:/**
netif.c:756: * @ingroup netif
netif.c:757: * Called by a driver when its link goes down
netif.c:758: */
netif.c:759:void
netif.c:760:netif_set_link_down(struct netif *netif )
netif.c:761:{
netif.c:762:  if (netif->flags & NETIF_FLAG_LINK_UP) {
netif.c:763:    netif->flags &= ~NETIF_FLAG_LINK_UP;
netif.c:764:    NETIF_LINK_CALLBACK(netif);
netif.c:765:  }
netif.c:766:}
netif.c:767:
netif.c:768:#if LWIP_NETIF_LINK_CALLBACK
netif.c:769:/**
netif.c:770: * @ingroup netif
netif.c:771: * Set callback to be called when link is brought up/down
netif.c:772: */
netif.c:773:void
netif.c:774:netif_set_link_callback(struct netif *netif, netif_status_callback_fn link_callback)
netif.c:775:{
netif.c:776:  if (netif) {
netif.c:777:    netif->link_callback = link_callback;
netif.c:778:  }
netif.c:779:}
netif.c:780:#endif /* LWIP_NETIF_LINK_CALLBACK */
netif.c:781:
netif.c:782:#if ENABLE_LOOPBACK
netif.c:783:/**
netif.c:784: * @ingroup netif
netif.c:785: * Send an IP packet to be received on the same netif (loopif-like).
netif.c:786: * The pbuf is simply copied and handed back to netif->input.
netif.c:787: * In multithreaded mode, this is done directly since netif->input must put
netif.c:788: * the packet on a queue.
netif.c:789: * In callback mode, the packet is put on an internal queue and is fed to
netif.c:790: * netif->input by netif_poll().
netif.c:791: *
netif.c:792: * @param netif the lwip network interface structure
netif.c:793: * @param p the (IP) packet to 'send'
netif.c:794: * @return ERR_OK if the packet has been sent
netif.c:795: *         ERR_MEM if the pbuf used to copy the packet couldn't be allocated
netif.c:796: */
netif.c:797:err_t
netif.c:798:netif_loop_output(struct netif *netif, struct pbuf *p)
netif.c:799:{
netif.c:800:  struct pbuf *r;
netif.c:801:  err_t err;
netif.c:802:  struct pbuf *last;
netif.c:803:#if LWIP_LOOPBACK_MAX_PBUFS
netif.c:804:  u16_t clen = 0;
netif.c:805:#endif /* LWIP_LOOPBACK_MAX_PBUFS */
netif.c:806:  /* If we have a loopif, SNMP counters are adjusted for it,
netif.c:807:   * if not they are adjusted for 'netif'. */
netif.c:808:#if MIB2_STATS
netif.c:809:#if LWIP_HAVE_LOOPIF
netif.c:810:  struct netif *stats_if = &loop_netif;
netif.c:811:#else /* LWIP_HAVE_LOOPIF */
netif.c:812:  struct netif *stats_if = netif;
netif.c:813:#endif /* LWIP_HAVE_LOOPIF */
netif.c:814:#endif /* MIB2_STATS */
netif.c:815:  SYS_ARCH_DECL_PROTECT(lev);
netif.c:816:
netif.c:817:  /* Allocate a new pbuf */
netif.c:818:  r = pbuf_alloc(PBUF_LINK, p->tot_len, PBUF_RAM);
netif.c:819:  if (r == NULL) {
netif.c:820:    LINK_STATS_INC(link.memerr);
netif.c:821:    LINK_STATS_INC(link.drop);
netif.c:822:    MIB2_STATS_NETIF_INC(stats_if, ifoutdiscards);
netif.c:823:    return ERR_MEM;
netif.c:824:  }
netif.c:825:#if LWIP_LOOPBACK_MAX_PBUFS
netif.c:826:  clen = pbuf_clen(r);
netif.c:827:  /* check for overflow or too many pbuf on queue */
netif.c:828:  if (((netif->loop_cnt_current + clen) < netif->loop_cnt_current) ||
netif.c:829:     ((netif->loop_cnt_current + clen) > LWIP_LOOPBACK_MAX_PBUFS)) {
netif.c:830:    pbuf_free(r);
netif.c:831:    LINK_STATS_INC(link.memerr);
netif.c:832:    LINK_STATS_INC(link.drop);
netif.c:833:    MIB2_STATS_NETIF_INC(stats_if, ifoutdiscards);
netif.c:834:    return ERR_MEM;
netif.c:835:  }
netif.c:836:  netif->loop_cnt_current += clen;
netif.c:837:#endif /* LWIP_LOOPBACK_MAX_PBUFS */
netif.c:838:
netif.c:839:  /* Copy the whole pbuf queue p into the single pbuf r */
netif.c:840:  if ((err = pbuf_copy(r, p)) != ERR_OK) {
netif.c:841:    pbuf_free(r);
netif.c:842:    LINK_STATS_INC(link.memerr);
netif.c:843:    LINK_STATS_INC(link.drop);
netif.c:844:    MIB2_STATS_NETIF_INC(stats_if, ifoutdiscards);
netif.c:845:    return err;
netif.c:846:  }
netif.c:847:
netif.c:848:  /* Put the packet on a linked list which gets emptied through calling
netif.c:849:     netif_poll(). */
netif.c:850:
netif.c:851:  /* let last point to the last pbuf in chain r */
netif.c:852:  for (last = r; last->next != NULL; last = last->next);
netif.c:853:
netif.c:854:  SYS_ARCH_PROTECT(lev);
netif.c:855:  if (netif->loop_first != NULL) {
netif.c:856:    LWIP_ASSERT("if first != NULL, last must also be != NULL", netif->loop_last != NULL);
netif.c:857:    netif->loop_last->next = r;
netif.c:858:    netif->loop_last = last;
netif.c:859:  } else {
netif.c:860:    netif->loop_first = r;
netif.c:861:    netif->loop_last = last;
netif.c:862:  }
netif.c:863:  SYS_ARCH_UNPROTECT(lev);
netif.c:864:
netif.c:865:  LINK_STATS_INC(link.xmit);
netif.c:866:  MIB2_STATS_NETIF_ADD(stats_if, ifoutoctets, p->tot_len);
netif.c:867:  MIB2_STATS_NETIF_INC(stats_if, ifoutucastpkts);
netif.c:868:
netif.c:869:#if LWIP_NETIF_LOOPBACK_MULTITHREADING
netif.c:870:  /* For multithreading environment, schedule a call to netif_poll */
netif.c:871:  tcpip_callback_with_block((tcpip_callback_fn)netif_poll, netif, 0);
netif.c:872:#endif /* LWIP_NETIF_LOOPBACK_MULTITHREADING */
netif.c:873:
netif.c:874:  return ERR_OK;
netif.c:875:}
netif.c:876:
netif.c:877:#if LWIP_HAVE_LOOPIF
netif.c:878:#if LWIP_IPV4
netif.c:879:static err_t
netif.c:880:netif_loop_output_ipv4(struct netif *netif, struct pbuf *p, const ip4_addr_t* addr)
netif.c:881:{
netif.c:882:  LWIP_UNUSED_ARG(addr);
netif.c:883:  return netif_loop_output(netif, p);
netif.c:884:}
netif.c:885:#endif /* LWIP_IPV4 */
netif.c:886:
netif.c:887:#if LWIP_IPV6
netif.c:888:static err_t
netif.c:889:netif_loop_output_ipv6(struct netif *netif, struct pbuf *p, const ip6_addr_t* addr)
netif.c:890:{
netif.c:891:  LWIP_UNUSED_ARG(addr);
netif.c:892:  return netif_loop_output(netif, p);
netif.c:893:}
netif.c:894:#endif /* LWIP_IPV6 */
netif.c:895:#endif /* LWIP_HAVE_LOOPIF */
netif.c:896:
netif.c:897:
netif.c:898:/**
netif.c:899: * Call netif_poll() in the main loop of your application. This is to prevent
netif.c:900: * reentering non-reentrant functions like tcp_input(). Packets passed to
netif.c:901: * netif_loop_output() are put on a list that is passed to netif->input() by
netif.c:902: * netif_poll().
netif.c:903: */
netif.c:904:void
netif.c:905:netif_poll(struct netif *netif)
netif.c:906:{
netif.c:907:  struct pbuf *in;
netif.c:908:  /* If we have a loopif, SNMP counters are adjusted for it,
netif.c:909:   * if not they are adjusted for 'netif'. */
netif.c:910:#if MIB2_STATS
netif.c:911:#if LWIP_HAVE_LOOPIF
netif.c:912:  struct netif *stats_if = &loop_netif;
netif.c:913:#else /* LWIP_HAVE_LOOPIF */
netif.c:914:  struct netif *stats_if = netif;
netif.c:915:#endif /* LWIP_HAVE_LOOPIF */
netif.c:916:#endif /* MIB2_STATS */
netif.c:917:  SYS_ARCH_DECL_PROTECT(lev);
netif.c:918:
netif.c:919:  do {
netif.c:920:    /* Get a packet from the list. With SYS_LIGHTWEIGHT_PROT=1, this is protected */
netif.c:921:    SYS_ARCH_PROTECT(lev);
netif.c:922:    in = netif->loop_first;
netif.c:923:    if (in != NULL) {
netif.c:924:      struct pbuf *in_end = in;
netif.c:925:#if LWIP_LOOPBACK_MAX_PBUFS
netif.c:926:      u8_t clen = 1;
netif.c:927:#endif /* LWIP_LOOPBACK_MAX_PBUFS */
netif.c:928:      while (in_end->len != in_end->tot_len) {
netif.c:929:        LWIP_ASSERT("bogus pbuf: len != tot_len but next == NULL!", in_end->next != NULL);
netif.c:930:        in_end = in_end->next;
netif.c:931:#if LWIP_LOOPBACK_MAX_PBUFS
netif.c:932:        clen++;
netif.c:933:#endif /* LWIP_LOOPBACK_MAX_PBUFS */
netif.c:934:      }
netif.c:935:#if LWIP_LOOPBACK_MAX_PBUFS
netif.c:936:      /* adjust the number of pbufs on queue */
netif.c:937:      LWIP_ASSERT("netif->loop_cnt_current underflow",
netif.c:938:        ((netif->loop_cnt_current - clen) < netif->loop_cnt_current));
netif.c:939:      netif->loop_cnt_current -= clen;
netif.c:940:#endif /* LWIP_LOOPBACK_MAX_PBUFS */
netif.c:941:
netif.c:942:      /* 'in_end' now points to the last pbuf from 'in' */
netif.c:943:      if (in_end == netif->loop_last) {
netif.c:944:        /* this was the last pbuf in the list */
netif.c:945:        netif->loop_first = netif->loop_last = NULL;
netif.c:946:      } else {
netif.c:947:        /* pop the pbuf off the list */
netif.c:948:        netif->loop_first = in_end->next;
netif.c:949:        LWIP_ASSERT("should not be null since first != last!", netif->loop_first != NULL);
netif.c:950:      }
netif.c:951:      /* De-queue the pbuf from its successors on the 'loop_' list. */
netif.c:952:      in_end->next = NULL;
netif.c:953:    }
netif.c:954:    SYS_ARCH_UNPROTECT(lev);
netif.c:955:
netif.c:956:    if (in != NULL) {
netif.c:957:      LINK_STATS_INC(link.recv);
netif.c:958:      MIB2_STATS_NETIF_ADD(stats_if, ifinoctets, in->tot_len);
netif.c:959:      MIB2_STATS_NETIF_INC(stats_if, ifinucastpkts);
netif.c:960:      /* loopback packets are always IP packets! */
netif.c:961:      if (ip_input(in, netif) != ERR_OK) {
netif.c:962:        pbuf_free(in);
netif.c:963:      }
netif.c:964:      /* Don't reference the packet any more! */
netif.c:965:      in = NULL;
netif.c:966:    }
netif.c:967:  /* go on while there is a packet on the list */
netif.c:968:  } while (netif->loop_first != NULL);
netif.c:969:}
netif.c:970:
netif.c:971:#if !LWIP_NETIF_LOOPBACK_MULTITHREADING
netif.c:972:/**
netif.c:973: * Calls netif_poll() for every netif on the netif_list.
netif.c:974: */
netif.c:975:void
netif.c:976:netif_poll_all(void)
netif.c:977:{
netif.c:978:  struct netif *netif = netif_list;
netif.c:979:  /* loop through netifs */
netif.c:980:  while (netif != NULL) {
netif.c:981:    netif_poll(netif);
netif.c:982:    /* proceed to next network interface */
netif.c:983:    netif = netif->next;
netif.c:984:  }
netif.c:985:}
netif.c:986:#endif /* !LWIP_NETIF_LOOPBACK_MULTITHREADING */
netif.c:987:#endif /* ENABLE_LOOPBACK */
netif.c:988:
netif.c:989:#if LWIP_NUM_NETIF_CLIENT_DATA > 0
netif.c:990:/**
netif.c:991: * @ingroup netif_cd
netif.c:992: * Allocate an index to store data in client_data member of struct netif.
netif.c:993: * Returned value is an index in mentioned array.
netif.c:994: * @see LWIP_NUM_NETIF_CLIENT_DATA
netif.c:995: */
netif.c:996:u8_t
netif.c:997:netif_alloc_client_data_id(void)
netif.c:998:{
netif.c:999:  u8_t result = netif_client_id;
netif.c:1000:  netif_client_id++;
netif.c:1001:
netif.c:1002:  LWIP_ASSERT("Increase LWIP_NUM_NETIF_CLIENT_DATA in lwipopts.h", result < LWIP_NUM_NETIF_CLIENT_DATA);
netif.c:1003:  return result + LWIP_NETIF_CLIENT_DATA_INDEX_MAX;
netif.c:1004:}
netif.c:1005:#endif
netif.c:1006:
netif.c:1007:#if LWIP_IPV6
netif.c:1008:/**
netif.c:1009: * @ingroup netif_ip6
netif.c:1010: * Change an IPv6 address of a network interface
netif.c:1011: *
netif.c:1012: * @param netif the network interface to change
netif.c:1013: * @param addr_idx index of the IPv6 address
netif.c:1014: * @param addr6 the new IPv6 address
netif.c:1015: *
netif.c:1016: * @note call netif_ip6_addr_set_state() to set the address valid/temptative
netif.c:1017: */
netif.c:1018:void
netif.c:1019:netif_ip6_addr_set(struct netif *netif, s8_t addr_idx, const ip6_addr_t *addr6)
netif.c:1020:{
netif.c:1021:  LWIP_ASSERT("addr6 != NULL", addr6 != NULL);
netif.c:1022:  netif_ip6_addr_set_parts(netif, addr_idx, addr6->addr[0], addr6->addr[1],
netif.c:1023:    addr6->addr[2], addr6->addr[3]);
netif.c:1024:}
netif.c:1025:
netif.c:1026:/*
netif.c:1027: * Change an IPv6 address of a network interface (internal version taking 4 * u32_t)
netif.c:1028: *
netif.c:1029: * @param netif the network interface to change
netif.c:1030: * @param addr_idx index of the IPv6 address
netif.c:1031: * @param i0 word0 of the new IPv6 address
netif.c:1032: * @param i1 word1 of the new IPv6 address
netif.c:1033: * @param i2 word2 of the new IPv6 address
netif.c:1034: * @param i3 word3 of the new IPv6 address
netif.c:1035: */
netif.c:1036:void
netif.c:1037:netif_ip6_addr_set_parts(struct netif *netif, s8_t addr_idx, u32_t i0, u32_t i1, u32_t i2, u32_t i3)
netif.c:1038:{
netif.c:1039:  const ip6_addr_t *old_addr;
netif.c:1040:  LWIP_ASSERT("netif != NULL", netif != NULL);
netif.c:1041:  LWIP_ASSERT("invalid index", addr_idx < LWIP_IPV6_NUM_ADDRESSES);
netif.c:1042:
netif.c:1043:  old_addr = netif_ip6_addr(netif, addr_idx);
netif.c:1044:  /* address is actually being changed? */
netif.c:1045:  if ((old_addr->addr[0] != i0) || (old_addr->addr[1] != i1) ||
netif.c:1046:      (old_addr->addr[2] != i2) || (old_addr->addr[3] != i3)) {
netif.c:1047:    LWIP_DEBUGF(NETIF_DEBUG | LWIP_DBG_STATE, ("netif_ip6_addr_set: netif address being changed\n"));
netif.c:1048:
netif.c:1049:    if (netif_ip6_addr_state(netif, addr_idx) & IP6_ADDR_VALID) {
netif.c:1050:#if LWIP_TCP || LWIP_UDP
netif.c:1051:      ip_addr_t new_ipaddr;
netif.c:1052:      IP_ADDR6(&new_ipaddr, i0, i1, i2, i3);
netif.c:1053:#endif /* LWIP_TCP || LWIP_UDP */
netif.c:1054:#if LWIP_TCP
netif.c:1055:      tcp_netif_ip_addr_changed(netif_ip_addr6(netif, addr_idx), &new_ipaddr);
netif.c:1056:#endif /* LWIP_TCP */
netif.c:1057:#if LWIP_UDP
netif.c:1058:      udp_netif_ip_addr_changed(netif_ip_addr6(netif, addr_idx), &new_ipaddr);
netif.c:1059:#endif /* LWIP_UDP */
netif.c:1060:#if LWIP_RAW
netif.c:1061:    raw_netif_ip_addr_changed(netif_ip_addr6(netif, addr_idx), &new_ipaddr);
netif.c:1062:#endif /* LWIP_RAW */
netif.c:1063:    }
netif.c:1064:    /* @todo: remove/readd mib2 ip6 entries? */
netif.c:1065:
netif.c:1066:    IP6_ADDR(ip_2_ip6(&(netif->ip6_addr[addr_idx])), i0, i1, i2, i3);
netif.c:1067:    IP_SET_TYPE_VAL(netif->ip6_addr[addr_idx], IPADDR_TYPE_V6);
netif.c:1068:
netif.c:1069:    if (netif_ip6_addr_state(netif, addr_idx) & IP6_ADDR_VALID) {
netif.c:1070:      netif_issue_reports(netif, NETIF_REPORT_TYPE_IPV6);
netif.c:1071:      NETIF_STATUS_CALLBACK(netif);
netif.c:1072:    }
netif.c:1073:  }
netif.c:1074:
netif.c:1075:  LWIP_DEBUGF(NETIF_DEBUG | LWIP_DBG_TRACE | LWIP_DBG_STATE, ("netif: IPv6 address %d of interface %c%c set to %s/0x%"X8_F"\n",
netif.c:1076:    addr_idx, netif->name[0], netif->name[1], ip6addr_ntoa(netif_ip6_addr(netif, addr_idx)),
netif.c:1077:    netif_ip6_addr_state(netif, addr_idx)));
netif.c:1078:}
netif.c:1079:
netif.c:1080:/**
netif.c:1081: * @ingroup netif_ip6
netif.c:1082: * Change the state of an IPv6 address of a network interface
netif.c:1083: * (INVALID, TEMPTATIVE, PREFERRED, DEPRECATED, where TEMPTATIVE
netif.c:1084: * includes the number of checks done, see ip6_addr.h)
netif.c:1085: *
netif.c:1086: * @param netif the network interface to change
netif.c:1087: * @param addr_idx index of the IPv6 address
netif.c:1088: * @param state the new IPv6 address state
netif.c:1089: */
netif.c:1090:void
netif.c:1091:netif_ip6_addr_set_state(struct netif* netif, s8_t addr_idx, u8_t state)
netif.c:1092:{
netif.c:1093:  u8_t old_state;
netif.c:1094:  LWIP_ASSERT("netif != NULL", netif != NULL);
netif.c:1095:  LWIP_ASSERT("invalid index", addr_idx < LWIP_IPV6_NUM_ADDRESSES);
netif.c:1096:
netif.c:1097:  old_state = netif_ip6_addr_state(netif, addr_idx);
netif.c:1098:  /* state is actually being changed? */
netif.c:1099:  if (old_state != state) {
netif.c:1100:    u8_t old_valid = old_state & IP6_ADDR_VALID;
netif.c:1101:    u8_t new_valid = state & IP6_ADDR_VALID;
netif.c:1102:    LWIP_DEBUGF(NETIF_DEBUG | LWIP_DBG_STATE, ("netif_ip6_addr_set_state: netif address state being changed\n"));
netif.c:1103:
netif.c:1104:    if (old_valid && !new_valid) {
netif.c:1105:      /* address about to be removed by setting invalid */
netif.c:1106:#if LWIP_TCP
netif.c:1107:      tcp_netif_ip_addr_changed(netif_ip_addr6(netif, addr_idx), NULL);
netif.c:1108:#endif /* LWIP_TCP */
tcp_out.c:43:#if LWIP_TCP /* don't build if not configured for use in lwipopts.h */
tcp_out.c:44:
tcp_out.c:45:#include "lwip/priv/tcp_priv.h"
tcp_out.c:46:#include "lwip/def.h"
tcp_out.c:47:#include "lwip/mem.h"
tcp_out.c:48:#include "lwip/memp.h"
tcp_out.c:49:#include "lwip/ip_addr.h"
tcp_out.c:50:#include "lwip/netif.h"
tcp_out.c:51:#include "lwip/inet_chksum.h"
tcp_out.c:52:#include "lwip/stats.h"
tcp_out.c:53:#include "lwip/ip6.h"
tcp_out.c:54:#include "lwip/ip6_addr.h"
tcp_out.c:55:#if LWIP_TCP_TIMESTAMPS
tcp_out.c:56:#include "lwip/sys.h"
tcp_out.c:57:#endif
tcp_out.c:58:
tcp_out.c:59:#include <string.h>
tcp_out.c:60:
tcp_out.c:61:/* Define some copy-macros for checksum-on-copy so that the code looks
tcp_out.c:62:   nicer by preventing too many ifdef's. */
tcp_out.c:63:#if TCP_CHECKSUM_ON_COPY
tcp_out.c:64:#define TCP_DATA_COPY(dst, src, len, seg) do { \
tcp_out.c:65:  tcp_seg_add_chksum(LWIP_CHKSUM_COPY(dst, src, len), \
tcp_out.c:66:                     len, &seg->chksum, &seg->chksum_swapped); \
tcp_out.c:67:  seg->flags |= TF_SEG_DATA_CHECKSUMMED; } while(0)
tcp_out.c:68:#define TCP_DATA_COPY2(dst, src, len, chksum, chksum_swapped)  \
tcp_out.c:69:  tcp_seg_add_chksum(LWIP_CHKSUM_COPY(dst, src, len), len, chksum, chksum_swapped);
tcp_out.c:70:#else /* TCP_CHECKSUM_ON_COPY*/
tcp_out.c:71:#define TCP_DATA_COPY(dst, src, len, seg)                     MEMCPY(dst, src, len)
tcp_out.c:72:#define TCP_DATA_COPY2(dst, src, len, chksum, chksum_swapped) MEMCPY(dst, src, len)
tcp_out.c:73:#endif /* TCP_CHECKSUM_ON_COPY*/
tcp_out.c:74:
tcp_out.c:75:/** Define this to 1 for an extra check that the output checksum is valid
tcp_out.c:76: * (usefule when the checksum is generated by the application, not the stack) */
tcp_out.c:77:#ifndef TCP_CHECKSUM_ON_COPY_SANITY_CHECK
tcp_out.c:78:#define TCP_CHECKSUM_ON_COPY_SANITY_CHECK   0
tcp_out.c:79:#endif
tcp_out.c:80:/* Allow to override the failure of sanity check from warning to e.g. hard failure */
tcp_out.c:81:#if TCP_CHECKSUM_ON_COPY_SANITY_CHECK
tcp_out.c:82:#ifndef TCP_CHECKSUM_ON_COPY_SANITY_CHECK_FAIL
tcp_out.c:83:#define TCP_CHECKSUM_ON_COPY_SANITY_CHECK_FAIL(msg) LWIP_DEBUGF(TCP_DEBUG | LWIP_DBG_LEVEL_WARNING, msg)
tcp_out.c:84:#endif
tcp_out.c:85:#endif
tcp_out.c:86:
tcp_out.c:87:#if TCP_OVERSIZE
tcp_out.c:88:/** The size of segment pbufs created when TCP_OVERSIZE is enabled */
tcp_out.c:89:#ifndef TCP_OVERSIZE_CALC_LENGTH
tcp_out.c:90:#define TCP_OVERSIZE_CALC_LENGTH(length) ((length) + TCP_OVERSIZE)
tcp_out.c:91:#endif
tcp_out.c:92:#endif
tcp_out.c:93:
tcp_out.c:94:/* Forward declarations.*/
tcp_out.c:95:static err_t tcp_output_segment(struct tcp_seg *seg, struct tcp_pcb *pcb, struct netif *netif);
tcp_out.c:96:
tcp_out.c:97:/** Allocate a pbuf and create a tcphdr at p->payload, used for output
tcp_out.c:98: * functions other than the default tcp_output -> tcp_output_segment
tcp_out.c:99: * (e.g. tcp_send_empty_ack, etc.)
tcp_out.c:100: *
tcp_out.c:101: * @param pcb tcp pcb for which to send a packet (used to initialize tcp_hdr)
tcp_out.c:102: * @param optlen length of header-options
tcp_out.c:103: * @param datalen length of tcp data to reserve in pbuf
tcp_out.c:104: * @param seqno_be seqno in network byte order (big-endian)
tcp_out.c:105: * @return pbuf with p->payload being the tcp_hdr
tcp_out.c:106: */
tcp_out.c:107:static struct pbuf *
tcp_out.c:108:tcp_output_alloc_header(struct tcp_pcb *pcb, u16_t optlen, u16_t datalen,
tcp_out.c:109:                      u32_t seqno_be /* already in network byte order */)
tcp_out.c:110:{
tcp_out.c:111:  struct tcp_hdr *tcphdr;
tcp_out.c:112:  struct pbuf *p = pbuf_alloc(PBUF_IP, TCP_HLEN + optlen + datalen, PBUF_RAM);
tcp_out.c:113:  if (p != NULL) {
tcp_out.c:114:    LWIP_ASSERT("check that first pbuf can hold struct tcp_hdr",
tcp_out.c:115:                 (p->len >= TCP_HLEN + optlen));
tcp_out.c:116:    tcphdr = (struct tcp_hdr *)p->payload;
tcp_out.c:117:    tcphdr->src = lwip_htons(pcb->local_port);
tcp_out.c:118:    tcphdr->dest = lwip_htons(pcb->remote_port);
tcp_out.c:119:    tcphdr->seqno = seqno_be;
tcp_out.c:120:    tcphdr->ackno = lwip_htonl(pcb->rcv_nxt);
tcp_out.c:121:    TCPH_HDRLEN_FLAGS_SET(tcphdr, (5 + optlen / 4), TCP_ACK);
tcp_out.c:122:    tcphdr->wnd = lwip_htons(TCPWND_MIN16(RCV_WND_SCALE(pcb, pcb->rcv_ann_wnd)));
tcp_out.c:123:    tcphdr->chksum = 0;
tcp_out.c:124:    tcphdr->urgp = 0;
tcp_out.c:125:
tcp_out.c:126:    /* If we're sending a packet, update the announced right window edge */
tcp_out.c:127:    pcb->rcv_ann_right_edge = pcb->rcv_nxt + pcb->rcv_ann_wnd;
tcp_out.c:128:  }
tcp_out.c:129:  return p;
tcp_out.c:130:}
tcp_out.c:131:
tcp_out.c:132:/**
tcp_out.c:133: * Called by tcp_close() to send a segment including FIN flag but not data.
tcp_out.c:134: *
tcp_out.c:135: * @param pcb the tcp_pcb over which to send a segment
tcp_out.c:136: * @return ERR_OK if sent, another err_t otherwise
tcp_out.c:137: */
tcp_out.c:138:err_t
tcp_out.c:139:tcp_send_fin(struct tcp_pcb *pcb)
tcp_out.c:140:{
tcp_out.c:141:  /* first, try to add the fin to the last unsent segment */
tcp_out.c:142:  if (pcb->unsent != NULL) {
tcp_out.c:143:    struct tcp_seg *last_unsent;
tcp_out.c:144:    for (last_unsent = pcb->unsent; last_unsent->next != NULL;
tcp_out.c:145:         last_unsent = last_unsent->next);
tcp_out.c:146:
tcp_out.c:147:    if ((TCPH_FLAGS(last_unsent->tcphdr) & (TCP_SYN | TCP_FIN | TCP_RST)) == 0) {
tcp_out.c:148:      /* no SYN/FIN/RST flag in the header, we can add the FIN flag */
tcp_out.c:149:      TCPH_SET_FLAG(last_unsent->tcphdr, TCP_FIN);
tcp_out.c:150:      pcb->flags |= TF_FIN;
tcp_out.c:151:      return ERR_OK;
tcp_out.c:152:    }
tcp_out.c:153:  }
tcp_out.c:154:  /* no data, no length, flags, copy=1, no optdata */
tcp_out.c:155:  return tcp_enqueue_flags(pcb, TCP_FIN);
tcp_out.c:156:}
tcp_out.c:157:
tcp_out.c:158:/**
tcp_out.c:159: * Create a TCP segment with prefilled header.
tcp_out.c:160: *
tcp_out.c:161: * Called by tcp_write and tcp_enqueue_flags.
tcp_out.c:162: *
tcp_out.c:163: * @param pcb Protocol control block for the TCP connection.
tcp_out.c:164: * @param p pbuf that is used to hold the TCP header.
tcp_out.c:165: * @param flags TCP flags for header.
tcp_out.c:166: * @param seqno TCP sequence number of this packet
tcp_out.c:167: * @param optflags options to include in TCP header
tcp_out.c:168: * @return a new tcp_seg pointing to p, or NULL.
tcp_out.c:169: * The TCP header is filled in except ackno and wnd.
tcp_out.c:170: * p is freed on failure.
tcp_out.c:171: */
tcp_out.c:172:static struct tcp_seg *
tcp_out.c:173:tcp_create_segment(struct tcp_pcb *pcb, struct pbuf *p, u8_t flags, u32_t seqno, u8_t optflags)
tcp_out.c:174:{
tcp_out.c:175:  struct tcp_seg *seg;
tcp_out.c:176:  u8_t optlen = LWIP_TCP_OPT_LENGTH(optflags);
tcp_out.c:177:
tcp_out.c:178:  if ((seg = (struct tcp_seg *)memp_malloc(MEMP_TCP_SEG)) == NULL) {
tcp_out.c:179:    LWIP_DEBUGF(TCP_OUTPUT_DEBUG | LWIP_DBG_LEVEL_SERIOUS, ("tcp_create_segment: no memory.\n"));
tcp_out.c:180:    pbuf_free(p);
tcp_out.c:181:    return NULL;
tcp_out.c:182:  }
tcp_out.c:183:  seg->flags = optflags;
tcp_out.c:184:  seg->next = NULL;
tcp_out.c:185:  seg->p = p;
tcp_out.c:186:  LWIP_ASSERT("p->tot_len >= optlen", p->tot_len >= optlen);
tcp_out.c:187:  seg->len = p->tot_len - optlen;
tcp_out.c:188:#if TCP_OVERSIZE_DBGCHECK
tcp_out.c:189:  seg->oversize_left = 0;
tcp_out.c:190:#endif /* TCP_OVERSIZE_DBGCHECK */
tcp_out.c:191:#if TCP_CHECKSUM_ON_COPY
tcp_out.c:192:  seg->chksum = 0;
tcp_out.c:193:  seg->chksum_swapped = 0;
tcp_out.c:194:  /* check optflags */
tcp_out.c:195:  LWIP_ASSERT("invalid optflags passed: TF_SEG_DATA_CHECKSUMMED",
tcp_out.c:196:              (optflags & TF_SEG_DATA_CHECKSUMMED) == 0);
tcp_out.c:197:#endif /* TCP_CHECKSUM_ON_COPY */
tcp_out.c:198:
tcp_out.c:199:  /* build TCP header */
tcp_out.c:200:  if (pbuf_header(p, TCP_HLEN)) {
tcp_out.c:201:    LWIP_DEBUGF(TCP_OUTPUT_DEBUG | LWIP_DBG_LEVEL_SERIOUS, ("tcp_create_segment: no room for TCP header in pbuf.\n"));
tcp_out.c:202:    TCP_STATS_INC(tcp.err);
tcp_out.c:203:    tcp_seg_free(seg);
tcp_out.c:204:    return NULL;
tcp_out.c:205:  }
tcp_out.c:206:  seg->tcphdr = (struct tcp_hdr *)seg->p->payload;
tcp_out.c:207:  seg->tcphdr->src = lwip_htons(pcb->local_port);
tcp_out.c:208:  seg->tcphdr->dest = lwip_htons(pcb->remote_port);
tcp_out.c:209:  seg->tcphdr->seqno = lwip_htonl(seqno);
tcp_out.c:210:  /* ackno is set in tcp_output */
tcp_out.c:211:  TCPH_HDRLEN_FLAGS_SET(seg->tcphdr, (5 + optlen / 4), flags);
tcp_out.c:212:  /* wnd and chksum are set in tcp_output */
tcp_out.c:213:  seg->tcphdr->urgp = 0;
tcp_out.c:214:  return seg;
tcp_out.c:215:}
tcp_out.c:216:
tcp_out.c:217:/**
tcp_out.c:218: * Allocate a PBUF_RAM pbuf, perhaps with extra space at the end.
tcp_out.c:219: *
tcp_out.c:220: * This function is like pbuf_alloc(layer, length, PBUF_RAM) except
tcp_out.c:221: * there may be extra bytes available at the end.
tcp_out.c:222: *
tcp_out.c:223: * @param layer flag to define header size.
tcp_out.c:224: * @param length size of the pbuf's payload.
tcp_out.c:225: * @param max_length maximum usable size of payload+oversize.
tcp_out.c:226: * @param oversize pointer to a u16_t that will receive the number of usable tail bytes.
tcp_out.c:227: * @param pcb The TCP connection that will enqueue the pbuf.
tcp_out.c:228: * @param apiflags API flags given to tcp_write.
tcp_out.c:229: * @param first_seg true when this pbuf will be used in the first enqueued segment.
tcp_out.c:230: */
tcp_out.c:231:#if TCP_OVERSIZE
tcp_out.c:232:static struct pbuf *
tcp_out.c:233:tcp_pbuf_prealloc(pbuf_layer layer, u16_t length, u16_t max_length,
tcp_out.c:234:                  u16_t *oversize, struct tcp_pcb *pcb, u8_t apiflags,
tcp_out.c:235:                  u8_t first_seg)
tcp_out.c:236:{
tcp_out.c:237:  struct pbuf *p;
tcp_out.c:238:  u16_t alloc = length;
tcp_out.c:239:
tcp_out.c:240:#if LWIP_NETIF_TX_SINGLE_PBUF
tcp_out.c:241:  LWIP_UNUSED_ARG(max_length);
tcp_out.c:242:  LWIP_UNUSED_ARG(pcb);
tcp_out.c:243:  LWIP_UNUSED_ARG(apiflags);
tcp_out.c:244:  LWIP_UNUSED_ARG(first_seg);
tcp_out.c:245:  alloc = max_length;
tcp_out.c:246:#else /* LWIP_NETIF_TX_SINGLE_PBUF */
tcp_out.c:247:  if (length < max_length) {
tcp_out.c:248:    /* Should we allocate an oversized pbuf, or just the minimum
tcp_out.c:249:     * length required? If tcp_write is going to be called again
tcp_out.c:250:     * before this segment is transmitted, we want the oversized
tcp_out.c:251:     * buffer. If the segment will be transmitted immediately, we can
tcp_out.c:252:     * save memory by allocating only length. We use a simple
tcp_out.c:253:     * heuristic based on the following information:
tcp_out.c:254:     *
tcp_out.c:255:     * Did the user set TCP_WRITE_FLAG_MORE?
tcp_out.c:256:     *
tcp_out.c:257:     * Will the Nagle algorithm defer transmission of this segment?
tcp_out.c:258:     */
tcp_out.c:259:    if ((apiflags & TCP_WRITE_FLAG_MORE) ||
tcp_out.c:260:        (!(pcb->flags & TF_NODELAY) &&
tcp_out.c:261:         (!first_seg ||
tcp_out.c:262:          pcb->unsent != NULL ||
tcp_out.c:263:          pcb->unacked != NULL))) {
tcp_out.c:264:      alloc = LWIP_MIN(max_length, LWIP_MEM_ALIGN_SIZE(TCP_OVERSIZE_CALC_LENGTH(length)));
tcp_out.c:265:    }
tcp_out.c:266:  }
tcp_out.c:267:#endif /* LWIP_NETIF_TX_SINGLE_PBUF */
tcp_out.c:268:  p = pbuf_alloc(layer, alloc, PBUF_RAM);
tcp_out.c:269:  if (p == NULL) {
tcp_out.c:270:    return NULL;
tcp_out.c:271:  }
tcp_out.c:272:  LWIP_ASSERT("need unchained pbuf", p->next == NULL);
tcp_out.c:273:  *oversize = p->len - length;
tcp_out.c:274:  /* trim p->len to the currently used size */
tcp_out.c:275:  p->len = p->tot_len = length;
tcp_out.c:276:  return p;
tcp_out.c:277:}
tcp_out.c:278:#else /* TCP_OVERSIZE */
tcp_out.c:279:#define tcp_pbuf_prealloc(layer, length, mx, os, pcb, api, fst) pbuf_alloc((layer), (length), PBUF_RAM)
tcp_out.c:280:#endif /* TCP_OVERSIZE */
tcp_out.c:281:
tcp_out.c:282:#if TCP_CHECKSUM_ON_COPY
tcp_out.c:283:/** Add a checksum of newly added data to the segment */
tcp_out.c:284:static void
tcp_out.c:285:tcp_seg_add_chksum(u16_t chksum, u16_t len, u16_t *seg_chksum,
tcp_out.c:286:                   u8_t *seg_chksum_swapped)
tcp_out.c:287:{
tcp_out.c:288:  u32_t helper;
tcp_out.c:289:  /* add chksum to old chksum and fold to u16_t */
tcp_out.c:290:  helper = chksum + *seg_chksum;
tcp_out.c:291:  chksum = FOLD_U32T(helper);
tcp_out.c:292:  if ((len & 1) != 0) {
tcp_out.c:293:    *seg_chksum_swapped = 1 - *seg_chksum_swapped;
tcp_out.c:294:    chksum = SWAP_BYTES_IN_WORD(chksum);
tcp_out.c:295:  }
tcp_out.c:296:  *seg_chksum = chksum;
tcp_out.c:297:}
tcp_out.c:298:#endif /* TCP_CHECKSUM_ON_COPY */
tcp_out.c:299:
tcp_out.c:300:/** Checks if tcp_write is allowed or not (checks state, snd_buf and snd_queuelen).
tcp_out.c:301: *
tcp_out.c:302: * @param pcb the tcp pcb to check for
tcp_out.c:303: * @param len length of data to send (checked agains snd_buf)
tcp_out.c:304: * @return ERR_OK if tcp_write is allowed to proceed, another err_t otherwise
tcp_out.c:305: */
tcp_out.c:306:static err_t
tcp_out.c:307:tcp_write_checks(struct tcp_pcb *pcb, u16_t len)
tcp_out.c:308:{
tcp_out.c:309:  /* connection is in invalid state for data transmission? */
tcp_out.c:310:  if ((pcb->state != ESTABLISHED) &&
tcp_out.c:311:      (pcb->state != CLOSE_WAIT) &&
tcp_out.c:312:      (pcb->state != SYN_SENT) &&
tcp_out.c:313:      (pcb->state != SYN_RCVD)) {
tcp_out.c:314:    LWIP_DEBUGF(TCP_OUTPUT_DEBUG | LWIP_DBG_STATE | LWIP_DBG_LEVEL_SEVERE, ("tcp_write() called in invalid state\n"));
tcp_out.c:315:    return ERR_CONN;
tcp_out.c:316:  } else if (len == 0) {
tcp_out.c:317:    return ERR_OK;
tcp_out.c:318:  }
tcp_out.c:319:
tcp_out.c:320:  /* fail on too much data */
tcp_out.c:321:  if (len > pcb->snd_buf) {
tcp_out.c:322:    LWIP_DEBUGF(TCP_OUTPUT_DEBUG | LWIP_DBG_LEVEL_SEVERE, ("tcp_write: too much data (len=%"U16_F" > snd_buf=%"TCPWNDSIZE_F")\n",
tcp_out.c:323:      len, pcb->snd_buf));
tcp_out.c:324:    pcb->flags |= TF_NAGLEMEMERR;
tcp_out.c:325:    return ERR_MEM;
tcp_out.c:326:  }
tcp_out.c:327:
tcp_out.c:328:  LWIP_DEBUGF(TCP_QLEN_DEBUG, ("tcp_write: queuelen: %"TCPWNDSIZE_F"\n", (tcpwnd_size_t)pcb->snd_queuelen));
tcp_out.c:329:
tcp_out.c:330:  /* If total number of pbufs on the unsent/unacked queues exceeds the
tcp_out.c:331:   * configured maximum, return an error */
tcp_out.c:332:  /* check for configured max queuelen and possible overflow */
tcp_out.c:333:  if ((pcb->snd_queuelen >= TCP_SND_QUEUELEN) || (pcb->snd_queuelen > TCP_SNDQUEUELEN_OVERFLOW)) {
tcp_out.c:334:    LWIP_DEBUGF(TCP_OUTPUT_DEBUG | LWIP_DBG_LEVEL_SEVERE, ("tcp_write: too long queue %"U16_F" (max %"U16_F")\n",
tcp_out.c:335:      pcb->snd_queuelen, (u16_t)TCP_SND_QUEUELEN));
tcp_out.c:336:    TCP_STATS_INC(tcp.memerr);
tcp_out.c:337:    pcb->flags |= TF_NAGLEMEMERR;
tcp_out.c:338:    return ERR_MEM;
tcp_out.c:339:  }
tcp_out.c:340:  if (pcb->snd_queuelen != 0) {
tcp_out.c:341:    LWIP_ASSERT("tcp_write: pbufs on queue => at least one queue non-empty",
tcp_out.c:342:      pcb->unacked != NULL || pcb->unsent != NULL);
tcp_out.c:343:  } else {
tcp_out.c:344:    LWIP_ASSERT("tcp_write: no pbufs on queue => both queues empty",
tcp_out.c:345:      pcb->unacked == NULL && pcb->unsent == NULL);
tcp_out.c:346:  }
tcp_out.c:347:  return ERR_OK;
tcp_out.c:348:}
tcp_out.c:349:
tcp_out.c:350:/**
tcp_out.c:351: * @ingroup tcp_raw
tcp_out.c:352: * Write data for sending (but does not send it immediately).
tcp_out.c:353: *
tcp_out.c:354: * It waits in the expectation of more data being sent soon (as
tcp_out.c:355: * it can send them more efficiently by combining them together).
tcp_out.c:356: * To prompt the system to send data now, call tcp_output() after
tcp_out.c:357: * calling tcp_write().
tcp_out.c:358: *
tcp_out.c:359: * @param pcb Protocol control block for the TCP connection to enqueue data for.
tcp_out.c:360: * @param arg Pointer to the data to be enqueued for sending.
tcp_out.c:361: * @param len Data length in bytes
tcp_out.c:362: * @param apiflags combination of following flags :
tcp_out.c:363: * - TCP_WRITE_FLAG_COPY (0x01) data will be copied into memory belonging to the stack
tcp_out.c:364: * - TCP_WRITE_FLAG_MORE (0x02) for TCP connection, PSH flag will not be set on last segment sent,
tcp_out.c:365: * @return ERR_OK if enqueued, another err_t on error
tcp_out.c:366: */
tcp_out.c:367:err_t
tcp_out.c:368:tcp_write(struct tcp_pcb *pcb, const void *arg, u16_t len, u8_t apiflags)
tcp_out.c:369:{
tcp_out.c:370:  struct pbuf *concat_p = NULL;
tcp_out.c:371:  struct tcp_seg *last_unsent = NULL, *seg = NULL, *prev_seg = NULL, *queue = NULL;
tcp_out.c:372:  u16_t pos = 0; /* position in 'arg' data */
tcp_out.c:373:  u16_t queuelen;
tcp_out.c:374:  u8_t optlen = 0;
tcp_out.c:375:  u8_t optflags = 0;
tcp_out.c:376:#if TCP_OVERSIZE
tcp_out.c:377:  u16_t oversize = 0;
tcp_out.c:378:  u16_t oversize_used = 0;
tcp_out.c:379:#endif /* TCP_OVERSIZE */
tcp_out.c:380:#if TCP_CHECKSUM_ON_COPY
tcp_out.c:381:  u16_t concat_chksum = 0;
tcp_out.c:382:  u8_t concat_chksum_swapped = 0;
tcp_out.c:383:  u16_t concat_chksummed = 0;
tcp_out.c:384:#endif /* TCP_CHECKSUM_ON_COPY */
tcp_out.c:385:  err_t err;
tcp_out.c:386:  /* don't allocate segments bigger than half the maximum window we ever received */
tcp_out.c:387:  u16_t mss_local = LWIP_MIN(pcb->mss, TCPWND_MIN16(pcb->snd_wnd_max/2));
tcp_out.c:388:  mss_local = mss_local ? mss_local : pcb->mss;
tcp_out.c:389:
tcp_out.c:390:#if LWIP_NETIF_TX_SINGLE_PBUF
tcp_out.c:391:  /* Always copy to try to create single pbufs for TX */
tcp_out.c:392:  apiflags |= TCP_WRITE_FLAG_COPY;
tcp_out.c:393:#endif /* LWIP_NETIF_TX_SINGLE_PBUF */
tcp_out.c:394:
tcp_out.c:395:  LWIP_DEBUGF(TCP_OUTPUT_DEBUG, ("tcp_write(pcb=%p, data=%p, len=%"U16_F", apiflags=%"U16_F")\n",
tcp_out.c:396:    (void *)pcb, arg, len, (u16_t)apiflags));
tcp_out.c:397:  LWIP_ERROR("tcp_write: arg == NULL (programmer violates API)",
tcp_out.c:398:             arg != NULL, return ERR_ARG;);
tcp_out.c:399:
tcp_out.c:400:  err = tcp_write_checks(pcb, len);
tcp_out.c:401:  if (err != ERR_OK) {
tcp_out.c:402:    return err;
tcp_out.c:403:  }
tcp_out.c:404:  queuelen = pcb->snd_queuelen;
tcp_out.c:405:
tcp_out.c:406:#if LWIP_TCP_TIMESTAMPS
tcp_out.c:407:  if ((pcb->flags & TF_TIMESTAMP)) {
tcp_out.c:408:    /* Make sure the timestamp option is only included in data segments if we
tcp_out.c:409:       agreed about it with the remote host. */
tcp_out.c:410:    optflags = TF_SEG_OPTS_TS;
tcp_out.c:411:    optlen = LWIP_TCP_OPT_LENGTH(TF_SEG_OPTS_TS);
tcp_out.c:412:    /* ensure that segments can hold at least one data byte... */
tcp_out.c:413:    mss_local = LWIP_MAX(mss_local, LWIP_TCP_OPT_LEN_TS + 1);
tcp_out.c:414:  }
tcp_out.c:415:#endif /* LWIP_TCP_TIMESTAMPS */
tcp_out.c:416:
tcp_out.c:417:
tcp_out.c:418:  /*
tcp_out.c:419:   * TCP segmentation is done in three phases with increasing complexity:
tcp_out.c:420:   *
tcp_out.c:421:   * 1. Copy data directly into an oversized pbuf.
tcp_out.c:422:   * 2. Chain a new pbuf to the end of pcb->unsent.
tcp_out.c:423:   * 3. Create new segments.
tcp_out.c:424:   *
tcp_out.c:425:   * We may run out of memory at any point. In that case we must
tcp_out.c:426:   * return ERR_MEM and not change anything in pcb. Therefore, all
tcp_out.c:427:   * changes are recorded in local variables and committed at the end
tcp_out.c:428:   * of the function. Some pcb fields are maintained in local copies:
tcp_out.c:429:   *
tcp_out.c:430:   * queuelen = pcb->snd_queuelen
tcp_out.c:431:   * oversize = pcb->unsent_oversize
tcp_out.c:432:   *
tcp_out.c:433:   * These variables are set consistently by the phases:
tcp_out.c:434:   *
tcp_out.c:435:   * seg points to the last segment tampered with.
tcp_out.c:436:   *
tcp_out.c:437:   * pos records progress as data is segmented.
tcp_out.c:438:   */
tcp_out.c:439:
tcp_out.c:440:  /* Find the tail of the unsent queue. */
tcp_out.c:441:  if (pcb->unsent != NULL) {
tcp_out.c:442:    u16_t space;
tcp_out.c:443:    u16_t unsent_optlen;
tcp_out.c:444:
tcp_out.c:445:    /* @todo: this could be sped up by keeping last_unsent in the pcb */
tcp_out.c:446:    for (last_unsent = pcb->unsent; last_unsent->next != NULL;
tcp_out.c:447:         last_unsent = last_unsent->next);
tcp_out.c:448:
tcp_out.c:449:    /* Usable space at the end of the last unsent segment */
tcp_out.c:450:    unsent_optlen = LWIP_TCP_OPT_LENGTH(last_unsent->flags);
tcp_out.c:451:    LWIP_ASSERT("mss_local is too small", mss_local >= last_unsent->len + unsent_optlen);
tcp_out.c:452:    space = mss_local - (last_unsent->len + unsent_optlen);
tcp_out.c:453:
tcp_out.c:454:    /*
tcp_out.c:455:     * Phase 1: Copy data directly into an oversized pbuf.
tcp_out.c:456:     *
tcp_out.c:457:     * The number of bytes copied is recorded in the oversize_used
tcp_out.c:458:     * variable. The actual copying is done at the bottom of the
tcp_out.c:459:     * function.
tcp_out.c:460:     */
tcp_out.c:461:#if TCP_OVERSIZE
tcp_out.c:462:#if TCP_OVERSIZE_DBGCHECK
tcp_out.c:463:    /* check that pcb->unsent_oversize matches last_unsent->unsent_oversize */
tcp_out.c:464:    LWIP_ASSERT("unsent_oversize mismatch (pcb vs. last_unsent)",
tcp_out.c:465:                pcb->unsent_oversize == last_unsent->oversize_left);
tcp_out.c:466:#endif /* TCP_OVERSIZE_DBGCHECK */
tcp_out.c:467:    oversize = pcb->unsent_oversize;
tcp_out.c:468:    if (oversize > 0) {
tcp_out.c:469:      LWIP_ASSERT("inconsistent oversize vs. space", oversize_used <= space);
tcp_out.c:470:      seg = last_unsent;
tcp_out.c:471:      oversize_used = LWIP_MIN(space, LWIP_MIN(oversize, len));
tcp_out.c:472:      pos += oversize_used;
tcp_out.c:473:      oversize -= oversize_used;
tcp_out.c:474:      space -= oversize_used;
tcp_out.c:475:    }
tcp_out.c:476:    /* now we are either finished or oversize is zero */
tcp_out.c:477:    LWIP_ASSERT("inconsistend oversize vs. len", (oversize == 0) || (pos == len));
tcp_out.c:478:#endif /* TCP_OVERSIZE */
tcp_out.c:479:
tcp_out.c:480:    /*
tcp_out.c:481:     * Phase 2: Chain a new pbuf to the end of pcb->unsent.
tcp_out.c:482:     *
tcp_out.c:483:     * We don't extend segments containing SYN/FIN flags or options
tcp_out.c:484:     * (len==0). The new pbuf is kept in concat_p and pbuf_cat'ed at
tcp_out.c:485:     * the end.
tcp_out.c:486:     */
tcp_out.c:487:    if ((pos < len) && (space > 0) && (last_unsent->len > 0)) {
tcp_out.c:488:      u16_t seglen = space < len - pos ? space : len - pos;
tcp_out.c:489:      seg = last_unsent;
tcp_out.c:490:
tcp_out.c:491:      /* Create a pbuf with a copy or reference to seglen bytes. We
tcp_out.c:492:       * can use PBUF_RAW here since the data appears in the middle of
tcp_out.c:493:       * a segment. A header will never be prepended. */
tcp_out.c:494:      if (apiflags & TCP_WRITE_FLAG_COPY) {
tcp_out.c:495:        /* Data is copied */
tcp_out.c:496:        if ((concat_p = tcp_pbuf_prealloc(PBUF_RAW, seglen, space, &oversize, pcb, apiflags, 1)) == NULL) {
tcp_out.c:497:          LWIP_DEBUGF(TCP_OUTPUT_DEBUG | LWIP_DBG_LEVEL_SERIOUS,
tcp_out.c:498:                      ("tcp_write : could not allocate memory for pbuf copy size %"U16_F"\n",
tcp_out.c:499:                       seglen));
tcp_out.c:500:          goto memerr;
tcp_out.c:501:        }
tcp_out.c:502:#if TCP_OVERSIZE_DBGCHECK
tcp_out.c:503:        last_unsent->oversize_left += oversize;
tcp_out.c:504:#endif /* TCP_OVERSIZE_DBGCHECK */
tcp_out.c:505:        TCP_DATA_COPY2(concat_p->payload, (const u8_t*)arg + pos, seglen, &concat_chksum, &concat_chksum_swapped);
tcp_out.c:506:#if TCP_CHECKSUM_ON_COPY
tcp_out.c:507:        concat_chksummed += seglen;
tcp_out.c:508:#endif /* TCP_CHECKSUM_ON_COPY */
tcp_out.c:509:      } else {
tcp_out.c:510:        /* Data is not copied */
tcp_out.c:511:        if ((concat_p = pbuf_alloc(PBUF_RAW, seglen, PBUF_ROM)) == NULL) {
tcp_out.c:512:          LWIP_DEBUGF(TCP_OUTPUT_DEBUG | LWIP_DBG_LEVEL_SERIOUS,
tcp_out.c:513:                      ("tcp_write: could not allocate memory for zero-copy pbuf\n"));
tcp_out.c:514:          goto memerr;
tcp_out.c:515:        }
tcp_out.c:516:#if TCP_CHECKSUM_ON_COPY
tcp_out.c:517:        /* calculate the checksum of nocopy-data */
tcp_out.c:518:        tcp_seg_add_chksum(~inet_chksum((const u8_t*)arg + pos, seglen), seglen,
tcp_out.c:519:          &concat_chksum, &concat_chksum_swapped);
tcp_out.c:520:        concat_chksummed += seglen;
tcp_out.c:521:#endif /* TCP_CHECKSUM_ON_COPY */
tcp_out.c:522:        /* reference the non-volatile payload data */
tcp_out.c:523:        ((struct pbuf_rom*)concat_p)->payload = (const u8_t*)arg + pos;
tcp_out.c:524:      }
tcp_out.c:525:
tcp_out.c:526:      pos += seglen;
tcp_out.c:527:      queuelen += pbuf_clen(concat_p);
tcp_out.c:528:    }
tcp_out.c:529:  } else {
tcp_out.c:530:#if TCP_OVERSIZE
tcp_out.c:531:    LWIP_ASSERT("unsent_oversize mismatch (pcb->unsent is NULL)",
tcp_out.c:532:                pcb->unsent_oversize == 0);
tcp_out.c:533:#endif /* TCP_OVERSIZE */
tcp_out.c:534:  }
tcp_out.c:535:
tcp_out.c:536:  /*
tcp_out.c:537:   * Phase 3: Create new segments.
tcp_out.c:538:   *
tcp_out.c:539:   * The new segments are chained together in the local 'queue'
tcp_out.c:540:   * variable, ready to be appended to pcb->unsent.
tcp_out.c:541:   */
tcp_out.c:542:  while (pos < len) {
tcp_out.c:543:    struct pbuf *p;
tcp_out.c:544:    u16_t left = len - pos;
tcp_out.c:545:    u16_t max_len = mss_local - optlen;
tcp_out.c:546:    u16_t seglen = left > max_len ? max_len : left;
tcp_out.c:547:#if TCP_CHECKSUM_ON_COPY
tcp_out.c:548:    u16_t chksum = 0;
tcp_out.c:549:    u8_t chksum_swapped = 0;
tcp_out.c:550:#endif /* TCP_CHECKSUM_ON_COPY */
tcp_out.c:551:
tcp_out.c:552:    if (apiflags & TCP_WRITE_FLAG_COPY) {
tcp_out.c:553:      /* If copy is set, memory should be allocated and data copied
tcp_out.c:554:       * into pbuf */
tcp_out.c:555:      if ((p = tcp_pbuf_prealloc(PBUF_TRANSPORT, seglen + optlen, mss_local, &oversize, pcb, apiflags, queue == NULL)) == NULL) {
tcp_out.c:556:        LWIP_DEBUGF(TCP_OUTPUT_DEBUG | LWIP_DBG_LEVEL_SERIOUS, ("tcp_write : could not allocate memory for pbuf copy size %"U16_F"\n", seglen));
tcp_out.c:557:        goto memerr;
tcp_out.c:558:      }
tcp_out.c:559:      LWIP_ASSERT("tcp_write: check that first pbuf can hold the complete seglen",
tcp_out.c:560:                  (p->len >= seglen));
tcp_out.c:561:      TCP_DATA_COPY2((char *)p->payload + optlen, (const u8_t*)arg + pos, seglen, &chksum, &chksum_swapped);
tcp_out.c:562:    } else {
tcp_out.c:563:      /* Copy is not set: First allocate a pbuf for holding the data.
tcp_out.c:564:       * Since the referenced data is available at least until it is
tcp_out.c:565:       * sent out on the link (as it has to be ACKed by the remote
tcp_out.c:566:       * party) we can safely use PBUF_ROM instead of PBUF_REF here.
tcp_out.c:567:       */
tcp_out.c:568:      struct pbuf *p2;
tcp_out.c:569:#if TCP_OVERSIZE
tcp_out.c:570:      LWIP_ASSERT("oversize == 0", oversize == 0);
tcp_out.c:571:#endif /* TCP_OVERSIZE */
tcp_out.c:572:      if ((p2 = pbuf_alloc(PBUF_TRANSPORT, seglen, PBUF_ROM)) == NULL) {
tcp_out.c:573:        LWIP_DEBUGF(TCP_OUTPUT_DEBUG | LWIP_DBG_LEVEL_SERIOUS, ("tcp_write: could not allocate memory for zero-copy pbuf\n"));
tcp_out.c:574:        goto memerr;
tcp_out.c:575:      }
tcp_out.c:576:#if TCP_CHECKSUM_ON_COPY
tcp_out.c:577:      /* calculate the checksum of nocopy-data */
tcp_out.c:578:      chksum = ~inet_chksum((const u8_t*)arg + pos, seglen);
tcp_out.c:579:      if (seglen & 1) {
tcp_out.c:580:        chksum_swapped = 1;
tcp_out.c:581:        chksum = SWAP_BYTES_IN_WORD(chksum);
tcp_out.c:582:      }
tcp_out.c:583:#endif /* TCP_CHECKSUM_ON_COPY */
tcp_out.c:584:      /* reference the non-volatile payload data */
tcp_out.c:585:      ((struct pbuf_rom*)p2)->payload = (const u8_t*)arg + pos;
tcp_out.c:586:
tcp_out.c:587:      /* Second, allocate a pbuf for the headers. */
tcp_out.c:588:      if ((p = pbuf_alloc(PBUF_TRANSPORT, optlen, PBUF_RAM)) == NULL) {
tcp_out.c:589:        /* If allocation fails, we have to deallocate the data pbuf as
tcp_out.c:590:         * well. */
tcp_out.c:591:        pbuf_free(p2);
tcp_out.c:592:        LWIP_DEBUGF(TCP_OUTPUT_DEBUG | LWIP_DBG_LEVEL_SERIOUS, ("tcp_write: could not allocate memory for header pbuf\n"));
tcp_out.c:593:        goto memerr;
tcp_out.c:594:      }
tcp_out.c:595:      /* Concatenate the headers and data pbufs together. */
tcp_out.c:596:      pbuf_cat(p/*header*/, p2/*data*/);
tcp_out.c:597:    }
tcp_out.c:598:
tcp_out.c:599:    queuelen += pbuf_clen(p);
tcp_out.c:600:
tcp_out.c:601:    /* Now that there are more segments queued, we check again if the
tcp_out.c:602:     * length of the queue exceeds the configured maximum or
tcp_out.c:603:     * overflows. */
tcp_out.c:604:    if ((queuelen > TCP_SND_QUEUELEN) || (queuelen > TCP_SNDQUEUELEN_OVERFLOW)) {
tcp_out.c:605:      LWIP_DEBUGF(TCP_OUTPUT_DEBUG | LWIP_DBG_LEVEL_SERIOUS, ("tcp_write: queue too long %"U16_F" (%d)\n",
tcp_out.c:606:        queuelen, (int)TCP_SND_QUEUELEN));
tcp_out.c:607:      pbuf_free(p);
tcp_out.c:608:      goto memerr;
tcp_out.c:609:    }
tcp_out.c:610:
tcp_out.c:611:    if ((seg = tcp_create_segment(pcb, p, 0, pcb->snd_lbb + pos, optflags)) == NULL) {
tcp_out.c:612:      goto memerr;
tcp_out.c:613:    }
tcp_out.c:614:#if TCP_OVERSIZE_DBGCHECK
tcp_out.c:615:    seg->oversize_left = oversize;
tcp_out.c:616:#endif /* TCP_OVERSIZE_DBGCHECK */
tcp_out.c:617:#if TCP_CHECKSUM_ON_COPY
tcp_out.c:618:    seg->chksum = chksum;
tcp_out.c:619:    seg->chksum_swapped = chksum_swapped;
tcp_out.c:620:    seg->flags |= TF_SEG_DATA_CHECKSUMMED;
tcp_out.c:621:#endif /* TCP_CHECKSUM_ON_COPY */
tcp_out.c:622:
tcp_out.c:623:    /* first segment of to-be-queued data? */
tcp_out.c:624:    if (queue == NULL) {
tcp_out.c:625:      queue = seg;
tcp_out.c:626:    } else {
tcp_out.c:627:      /* Attach the segment to the end of the queued segments */
tcp_out.c:628:      LWIP_ASSERT("prev_seg != NULL", prev_seg != NULL);
tcp_out.c:629:      prev_seg->next = seg;
tcp_out.c:630:    }
tcp_out.c:631:    /* remember last segment of to-be-queued data for next iteration */
tcp_out.c:632:    prev_seg = seg;
tcp_out.c:633:
tcp_out.c:634:    LWIP_DEBUGF(TCP_OUTPUT_DEBUG | LWIP_DBG_TRACE, ("tcp_write: queueing %"U32_F":%"U32_F"\n",
tcp_out.c:635:      lwip_ntohl(seg->tcphdr->seqno),
tcp_out.c:636:      lwip_ntohl(seg->tcphdr->seqno) + TCP_TCPLEN(seg)));
tcp_out.c:637:
tcp_out.c:638:    pos += seglen;
tcp_out.c:639:  }
tcp_out.c:640:
tcp_out.c:641:  /*
tcp_out.c:642:   * All three segmentation phases were successful. We can commit the
tcp_out.c:643:   * transaction.
tcp_out.c:644:   */
tcp_out.c:645:
tcp_out.c:646:  /*
tcp_out.c:647:   * Phase 1: If data has been added to the preallocated tail of
tcp_out.c:648:   * last_unsent, we update the length fields of the pbuf chain.
tcp_out.c:649:   */
tcp_out.c:650:#if TCP_OVERSIZE
tcp_out.c:651:  if (oversize_used > 0) {
tcp_out.c:652:    struct pbuf *p;
tcp_out.c:653:    /* Bump tot_len of whole chain, len of tail */
tcp_out.c:654:    for (p = last_unsent->p; p; p = p->next) {
tcp_out.c:655:      p->tot_len += oversize_used;
tcp_out.c:656:      if (p->next == NULL) {
tcp_out.c:657:        TCP_DATA_COPY((char *)p->payload + p->len, arg, oversize_used, last_unsent);
tcp_out.c:658:        p->len += oversize_used;
tcp_out.c:659:      }
tcp_out.c:660:    }
tcp_out.c:661:    last_unsent->len += oversize_used;
tcp_out.c:662:#if TCP_OVERSIZE_DBGCHECK
tcp_out.c:663:    LWIP_ASSERT("last_unsent->oversize_left >= oversize_used",
tcp_out.c:664:                last_unsent->oversize_left >= oversize_used);
tcp_out.c:665:    last_unsent->oversize_left -= oversize_used;
tcp_out.c:666:#endif /* TCP_OVERSIZE_DBGCHECK */
tcp_out.c:667:  }
tcp_out.c:668:  pcb->unsent_oversize = oversize;
tcp_out.c:669:#endif /* TCP_OVERSIZE */
tcp_out.c:670:
tcp_out.c:671:  /*
tcp_out.c:672:   * Phase 2: concat_p can be concatenated onto last_unsent->p
tcp_out.c:673:   */
tcp_out.c:674:  if (concat_p != NULL) {
tcp_out.c:675:    LWIP_ASSERT("tcp_write: cannot concatenate when pcb->unsent is empty",
tcp_out.c:676:      (last_unsent != NULL));
tcp_out.c:677:    pbuf_cat(last_unsent->p, concat_p);
tcp_out.c:678:    last_unsent->len += concat_p->tot_len;
tcp_out.c:679:#if TCP_CHECKSUM_ON_COPY
tcp_out.c:680:    if (concat_chksummed) {
tcp_out.c:681:      /*if concat checksumm swapped - swap it back */
tcp_out.c:682:      if (concat_chksum_swapped) {
tcp_out.c:683:        concat_chksum = SWAP_BYTES_IN_WORD(concat_chksum);
tcp_out.c:684:      }
tcp_out.c:685:      tcp_seg_add_chksum(concat_chksum, concat_chksummed, &last_unsent->chksum,
tcp_out.c:686:        &last_unsent->chksum_swapped);
tcp_out.c:687:      last_unsent->flags |= TF_SEG_DATA_CHECKSUMMED;
tcp_out.c:688:    }
tcp_out.c:689:#endif /* TCP_CHECKSUM_ON_COPY */
tcp_out.c:690:  }
tcp_out.c:691:
tcp_out.c:692:  /*
tcp_out.c:693:   * Phase 3: Append queue to pcb->unsent. Queue may be NULL, but that
tcp_out.c:694:   * is harmless
tcp_out.c:695:   */
tcp_out.c:696:  if (last_unsent == NULL) {
tcp_out.c:697:    pcb->unsent = queue;
tcp_out.c:698:  } else {
tcp_out.c:699:    last_unsent->next = queue;
tcp_out.c:700:  }
tcp_out.c:701:
tcp_out.c:702:  /*
tcp_out.c:703:   * Finally update the pcb state.
tcp_out.c:704:   */
tcp_out.c:705:  pcb->snd_lbb += len;
tcp_out.c:706:  pcb->snd_buf -= len;
tcp_out.c:707:  pcb->snd_queuelen = queuelen;
tcp_out.c:708:
tcp_out.c:709:  LWIP_DEBUGF(TCP_QLEN_DEBUG, ("tcp_write: %"S16_F" (after enqueued)\n",
tcp_out.c:710:    pcb->snd_queuelen));
tcp_out.c:711:  if (pcb->snd_queuelen != 0) {
tcp_out.c:712:    LWIP_ASSERT("tcp_write: valid queue length",
tcp_out.c:713:                pcb->unacked != NULL || pcb->unsent != NULL);
tcp_out.c:714:  }
tcp_out.c:715:
tcp_out.c:716:  /* Set the PSH flag in the last segment that we enqueued. */
tcp_out.c:717:  if (seg != NULL && seg->tcphdr != NULL && ((apiflags & TCP_WRITE_FLAG_MORE)==0)) {
tcp_out.c:718:    TCPH_SET_FLAG(seg->tcphdr, TCP_PSH);
tcp_out.c:719:  }
tcp_out.c:720:
tcp_out.c:721:  return ERR_OK;
tcp_out.c:722:memerr:
tcp_out.c:723:  pcb->flags |= TF_NAGLEMEMERR;
tcp_out.c:724:  TCP_STATS_INC(tcp.memerr);
tcp_out.c:725:
tcp_out.c:726:  if (concat_p != NULL) {
tcp_out.c:727:    pbuf_free(concat_p);
tcp_out.c:728:  }
tcp_out.c:729:  if (queue != NULL) {
tcp_out.c:730:    tcp_segs_free(queue);
tcp_out.c:731:  }
tcp_out.c:732:  if (pcb->snd_queuelen != 0) {
tcp_out.c:733:    LWIP_ASSERT("tcp_write: valid queue length", pcb->unacked != NULL ||
tcp_out.c:734:      pcb->unsent != NULL);
tcp_out.c:735:  }
tcp_out.c:736:  LWIP_DEBUGF(TCP_QLEN_DEBUG | LWIP_DBG_STATE, ("tcp_write: %"S16_F" (with mem err)\n", pcb->snd_queuelen));
tcp_out.c:737:  return ERR_MEM;
tcp_out.c:738:}
tcp_out.c:739:
tcp_out.c:740:/**
tcp_out.c:741: * Enqueue TCP options for transmission.
tcp_out.c:742: *
tcp_out.c:743: * Called by tcp_connect(), tcp_listen_input(), and tcp_send_ctrl().
tcp_out.c:744: *
tcp_out.c:745: * @param pcb Protocol control block for the TCP connection.
tcp_out.c:746: * @param flags TCP header flags to set in the outgoing segment.
tcp_out.c:747: */
tcp_out.c:748:err_t
tcp_out.c:749:tcp_enqueue_flags(struct tcp_pcb *pcb, u8_t flags)
tcp_out.c:750:{
tcp_out.c:751:  struct pbuf *p;
tcp_out.c:752:  struct tcp_seg *seg;
tcp_out.c:753:  u8_t optflags = 0;
tcp_out.c:754:  u8_t optlen = 0;
tcp_out.c:755:
tcp_out.c:756:  LWIP_DEBUGF(TCP_QLEN_DEBUG, ("tcp_enqueue_flags: queuelen: %"U16_F"\n", (u16_t)pcb->snd_queuelen));
tcp_out.c:757:
tcp_out.c:758:  LWIP_ASSERT("tcp_enqueue_flags: need either TCP_SYN or TCP_FIN in flags (programmer violates API)",
tcp_out.c:759:              (flags & (TCP_SYN | TCP_FIN)) != 0);
tcp_out.c:760:
tcp_out.c:761:  /* check for configured max queuelen and possible overflow (FIN flag should always come through!) */
tcp_out.c:762:  if (((pcb->snd_queuelen >= TCP_SND_QUEUELEN) || (pcb->snd_queuelen > TCP_SNDQUEUELEN_OVERFLOW)) &&
tcp_out.c:763:      ((flags & TCP_FIN) == 0)) {
tcp_out.c:764:    LWIP_DEBUGF(TCP_OUTPUT_DEBUG | LWIP_DBG_LEVEL_SEVERE, ("tcp_enqueue_flags: too long queue %"U16_F" (max %"U16_F")\n",
tcp_out.c:765:                                       pcb->snd_queuelen, (u16_t)TCP_SND_QUEUELEN));
tcp_out.c:766:    TCP_STATS_INC(tcp.memerr);
tcp_out.c:767:    pcb->flags |= TF_NAGLEMEMERR;
tcp_out.c:768:    return ERR_MEM;
tcp_out.c:769:  }
tcp_out.c:770:
tcp_out.c:771:  if (flags & TCP_SYN) {
tcp_out.c:772:    optflags = TF_SEG_OPTS_MSS;
tcp_out.c:773:#if LWIP_WND_SCALE
tcp_out.c:774:    if ((pcb->state != SYN_RCVD) || (pcb->flags & TF_WND_SCALE)) {
tcp_out.c:775:      /* In a <SYN,ACK> (sent in state SYN_RCVD), the window scale option may only
tcp_out.c:776:         be sent if we received a window scale option from the remote host. */
tcp_out.c:777:      optflags |= TF_SEG_OPTS_WND_SCALE;
tcp_out.c:778:    }
tcp_out.c:779:#endif /* LWIP_WND_SCALE */
tcp_out.c:780:  }
tcp_out.c:781:#if LWIP_TCP_TIMESTAMPS
tcp_out.c:782:  if ((pcb->flags & TF_TIMESTAMP)) {
tcp_out.c:783:    /* Make sure the timestamp option is only included in data segments if we
tcp_out.c:784:       agreed about it with the remote host. */
tcp_out.c:785:    optflags |= TF_SEG_OPTS_TS;
tcp_out.c:786:  }
tcp_out.c:787:#endif /* LWIP_TCP_TIMESTAMPS */
tcp_out.c:788:  optlen = LWIP_TCP_OPT_LENGTH(optflags);
tcp_out.c:789:
tcp_out.c:790:  /* Allocate pbuf with room for TCP header + options */
tcp_out.c:791:  if ((p = pbuf_alloc(PBUF_TRANSPORT, optlen, PBUF_RAM)) == NULL) {
tcp_out.c:792:    pcb->flags |= TF_NAGLEMEMERR;
tcp_out.c:793:    TCP_STATS_INC(tcp.memerr);
tcp_out.c:794:    return ERR_MEM;
tcp_out.c:795:  }
tcp_out.c:796:  LWIP_ASSERT("tcp_enqueue_flags: check that first pbuf can hold optlen",
tcp_out.c:797:              (p->len >= optlen));
tcp_out.c:798:
tcp_out.c:799:  /* Allocate memory for tcp_seg, and fill in fields. */
tcp_out.c:800:  if ((seg = tcp_create_segment(pcb, p, flags, pcb->snd_lbb, optflags)) == NULL) {
tcp_out.c:801:    pcb->flags |= TF_NAGLEMEMERR;
tcp_out.c:802:    TCP_STATS_INC(tcp.memerr);
tcp_out.c:803:    return ERR_MEM;
tcp_out.c:804:  }
tcp_out.c:805:  LWIP_ASSERT("seg->tcphdr not aligned", ((mem_ptr_t)seg->tcphdr % LWIP_MIN(MEM_ALIGNMENT, 4)) == 0);
tcp_out.c:806:  LWIP_ASSERT("tcp_enqueue_flags: invalid segment length", seg->len == 0);
tcp_out.c:807:
tcp_out.c:808:  LWIP_DEBUGF(TCP_OUTPUT_DEBUG | LWIP_DBG_TRACE,
tcp_out.c:809:              ("tcp_enqueue_flags: queueing %"U32_F":%"U32_F" (0x%"X16_F")\n",
tcp_out.c:810:               lwip_ntohl(seg->tcphdr->seqno),
tcp_out.c:811:               lwip_ntohl(seg->tcphdr->seqno) + TCP_TCPLEN(seg),
tcp_out.c:812:               (u16_t)flags));
tcp_out.c:813:
tcp_out.c:814:  /* Now append seg to pcb->unsent queue */
tcp_out.c:815:  if (pcb->unsent == NULL) {
tcp_out.c:816:    pcb->unsent = seg;
tcp_out.c:817:  } else {
tcp_out.c:818:    struct tcp_seg *useg;
tcp_out.c:819:    for (useg = pcb->unsent; useg->next != NULL; useg = useg->next);
tcp_out.c:820:    useg->next = seg;
tcp_out.c:821:  }
tcp_out.c:822:#if TCP_OVERSIZE
tcp_out.c:823:  /* The new unsent tail has no space */
tcp_out.c:824:  pcb->unsent_oversize = 0;
tcp_out.c:825:#endif /* TCP_OVERSIZE */
tcp_out.c:826:
tcp_out.c:827:  /* SYN and FIN bump the sequence number */
tcp_out.c:828:  if ((flags & TCP_SYN) || (flags & TCP_FIN)) {
tcp_out.c:829:    pcb->snd_lbb++;
tcp_out.c:830:    /* optlen does not influence snd_buf */
tcp_out.c:831:  }
tcp_out.c:832:  if (flags & TCP_FIN) {
tcp_out.c:833:    pcb->flags |= TF_FIN;
tcp_out.c:834:  }
tcp_out.c:835:
tcp_out.c:836:  /* update number of segments on the queues */
tcp_out.c:837:  pcb->snd_queuelen += pbuf_clen(seg->p);
tcp_out.c:838:  LWIP_DEBUGF(TCP_QLEN_DEBUG, ("tcp_enqueue_flags: %"S16_F" (after enqueued)\n", pcb->snd_queuelen));
tcp_out.c:839:  if (pcb->snd_queuelen != 0) {
tcp_out.c:840:    LWIP_ASSERT("tcp_enqueue_flags: invalid queue length",
tcp_out.c:841:      pcb->unacked != NULL || pcb->unsent != NULL);
tcp_out.c:842:  }
tcp_out.c:843:
tcp_out.c:844:  return ERR_OK;
tcp_out.c:845:}
tcp_out.c:846:
tcp_out.c:847:#if LWIP_TCP_TIMESTAMPS
tcp_out.c:848:/* Build a timestamp option (12 bytes long) at the specified options pointer)
tcp_out.c:849: *
tcp_out.c:850: * @param pcb tcp_pcb
tcp_out.c:851: * @param opts option pointer where to store the timestamp option
tcp_out.c:852: */
tcp_out.c:853:static void
tcp_out.c:854:tcp_build_timestamp_option(struct tcp_pcb *pcb, u32_t *opts)
tcp_out.c:855:{
tcp_out.c:856:  /* Pad with two NOP options to make everything nicely aligned */
tcp_out.c:857:  opts[0] = PP_HTONL(0x0101080A);
tcp_out.c:858:  opts[1] = lwip_htonl(sys_now());
tcp_out.c:859:  opts[2] = lwip_htonl(pcb->ts_recent);
tcp_out.c:860:}
tcp_out.c:861:#endif
tcp_out.c:862:
tcp_out.c:863:#if LWIP_WND_SCALE
tcp_out.c:864:/** Build a window scale option (3 bytes long) at the specified options pointer)
tcp_out.c:865: *
tcp_out.c:866: * @param opts option pointer where to store the window scale option
tcp_out.c:867: */
tcp_out.c:868:static void
tcp_out.c:869:tcp_build_wnd_scale_option(u32_t *opts)
tcp_out.c:870:{
tcp_out.c:871:  /* Pad with one NOP option to make everything nicely aligned */
tcp_out.c:872:  opts[0] = PP_HTONL(0x01030300 | TCP_RCV_SCALE);
tcp_out.c:873:}
tcp_out.c:874:#endif
tcp_out.c:875:
tcp_out.c:876:/**
tcp_out.c:877: * Send an ACK without data.
tcp_out.c:878: *
tcp_out.c:879: * @param pcb Protocol control block for the TCP connection to send the ACK
tcp_out.c:880: */
tcp_out.c:881:err_t
tcp_out.c:882:tcp_send_empty_ack(struct tcp_pcb *pcb)
tcp_out.c:883:{
tcp_out.c:884:  err_t err;
tcp_out.c:885:  struct pbuf *p;
tcp_out.c:886:  u8_t optlen = 0;
tcp_out.c:887:  struct netif *netif;
tcp_out.c:888:#if LWIP_TCP_TIMESTAMPS || CHECKSUM_GEN_TCP
tcp_out.c:889:  struct tcp_hdr *tcphdr;
tcp_out.c:890:#endif /* LWIP_TCP_TIMESTAMPS || CHECKSUM_GEN_TCP */
tcp_out.c:891:
tcp_out.c:892:#if LWIP_TCP_TIMESTAMPS
tcp_out.c:893:  if (pcb->flags & TF_TIMESTAMP) {
tcp_out.c:894:    optlen = LWIP_TCP_OPT_LENGTH(TF_SEG_OPTS_TS);
tcp_out.c:895:  }
tcp_out.c:896:#endif
tcp_out.c:897:
tcp_out.c:898:  p = tcp_output_alloc_header(pcb, optlen, 0, lwip_htonl(pcb->snd_nxt));
tcp_out.c:899:  if (p == NULL) {
tcp_out.c:900:    /* let tcp_fasttmr retry sending this ACK */
tcp_out.c:901:    pcb->flags |= (TF_ACK_DELAY | TF_ACK_NOW);
tcp_out.c:902:    LWIP_DEBUGF(TCP_OUTPUT_DEBUG, ("tcp_output: (ACK) could not allocate pbuf\n"));
tcp_out.c:903:    return ERR_BUF;
tcp_out.c:904:  }
tcp_out.c:905:#if LWIP_TCP_TIMESTAMPS || CHECKSUM_GEN_TCP
tcp_out.c:906:  tcphdr = (struct tcp_hdr *)p->payload;
tcp_out.c:907:#endif /* LWIP_TCP_TIMESTAMPS || CHECKSUM_GEN_TCP */
tcp_out.c:908:  LWIP_DEBUGF(TCP_OUTPUT_DEBUG,
tcp_out.c:909:              ("tcp_output: sending ACK for %"U32_F"\n", pcb->rcv_nxt));
tcp_out.c:910:
tcp_out.c:911:  /* NB. MSS and window scale options are only sent on SYNs, so ignore them here */
tcp_out.c:912:#if LWIP_TCP_TIMESTAMPS
tcp_out.c:913:  pcb->ts_lastacksent = pcb->rcv_nxt;
tcp_out.c:914:
tcp_out.c:915:  if (pcb->flags & TF_TIMESTAMP) {
tcp_out.c:916:    tcp_build_timestamp_option(pcb, (u32_t *)(tcphdr + 1));
tcp_out.c:917:  }
tcp_out.c:918:#endif
tcp_out.c:919:
tcp_out.c:920:  netif = ip_route(&pcb->local_ip, &pcb->remote_ip);
tcp_out.c:921:  if (netif == NULL) {
tcp_out.c:922:    err = ERR_RTE;
tcp_out.c:923:  } else {
tcp_out.c:924:#if CHECKSUM_GEN_TCP
tcp_out.c:925:    IF__NETIF_CHECKSUM_ENABLED(netif, NETIF_CHECKSUM_GEN_TCP) {
tcp_out.c:926:      tcphdr->chksum = ip_chksum_pseudo(p, IP_PROTO_TCP, p->tot_len,
tcp_out.c:927:        &pcb->local_ip, &pcb->remote_ip);
tcp_out.c:928:    }
tcp_out.c:929:#endif
tcp_out.c:930:    NETIF_SET_HWADDRHINT(netif, &(pcb->addr_hint));
tcp_out.c:931:    err = ip_output_if(p, &pcb->local_ip, &pcb->remote_ip,
tcp_out.c:932:      pcb->ttl, pcb->tos, IP_PROTO_TCP, netif);
tcp_out.c:933:    NETIF_SET_HWADDRHINT(netif, NULL);
tcp_out.c:934:  }
tcp_out.c:935:  pbuf_free(p);
tcp_out.c:936:
tcp_out.c:937:  if (err != ERR_OK) {
tcp_out.c:938:    /* let tcp_fasttmr retry sending this ACK */
tcp_out.c:939:    pcb->flags |= (TF_ACK_DELAY | TF_ACK_NOW);
tcp_out.c:940:  } else {
tcp_out.c:941:    /* remove ACK flags from the PCB, as we sent an empty ACK now */
tcp_out.c:942:    pcb->flags &= ~(TF_ACK_DELAY | TF_ACK_NOW);
tcp_out.c:943:  }
tcp_out.c:944:
tcp_out.c:945:  return err;
tcp_out.c:946:}
tcp_out.c:947:
tcp_out.c:948:/**
tcp_out.c:949: * @ingroup tcp_raw
tcp_out.c:950: * Find out what we can send and send it
tcp_out.c:951: *
tcp_out.c:952: * @param pcb Protocol control block for the TCP connection to send data
tcp_out.c:953: * @return ERR_OK if data has been sent or nothing to send
tcp_out.c:954: *         another err_t on error
tcp_out.c:955: */
tcp_out.c:956:err_t
tcp_out.c:957:tcp_output(struct tcp_pcb *pcb)
tcp_out.c:958:{
tcp_out.c:959:  struct tcp_seg *seg, *useg;
tcp_out.c:960:  u32_t wnd, snd_nxt;
tcp_out.c:961:  err_t err;
tcp_out.c:962:  struct netif *netif;
tcp_out.c:963:#if TCP_CWND_DEBUG
tcp_out.c:964:  s16_t i = 0;
tcp_out.c:965:#endif /* TCP_CWND_DEBUG */
tcp_out.c:966:
tcp_out.c:967:  /* pcb->state LISTEN not allowed here */
tcp_out.c:968:  LWIP_ASSERT("don't call tcp_output for listen-pcbs",
tcp_out.c:969:    pcb->state != LISTEN);
tcp_out.c:970:
tcp_out.c:971:  /* First, check if we are invoked by the TCP input processing
tcp_out.c:972:     code. If so, we do not output anything. Instead, we rely on the
tcp_out.c:973:     input processing code to call us when input processing is done
tcp_out.c:974:     with. */
tcp_out.c:975:  if (tcp_input_pcb == pcb) {
tcp_out.c:976:    return ERR_OK;
tcp_out.c:977:  }
tcp_out.c:978:
tcp_out.c:979:  wnd = LWIP_MIN(pcb->snd_wnd, pcb->cwnd);
tcp_out.c:980:
tcp_out.c:981:  seg = pcb->unsent;
tcp_out.c:982:
tcp_out.c:983:  /* If the TF_ACK_NOW flag is set and no data will be sent (either
tcp_out.c:984:   * because the ->unsent queue is empty or because the window does
tcp_out.c:985:   * not allow it), construct an empty ACK segment and send it.
tcp_out.c:986:   *
tcp_out.c:987:   * If data is to be sent, we will just piggyback the ACK (see below).
tcp_out.c:988:   */
tcp_out.c:989:  if (pcb->flags & TF_ACK_NOW &&
tcp_out.c:990:     (seg == NULL ||
tcp_out.c:991:      lwip_ntohl(seg->tcphdr->seqno) - pcb->lastack + seg->len > wnd)) {
tcp_out.c:992:     return tcp_send_empty_ack(pcb);
tcp_out.c:993:  }
tcp_out.c:994:
tcp_out.c:995:  /* useg should point to last segment on unacked queue */
tcp_out.c:996:  useg = pcb->unacked;
tcp_out.c:997:  if (useg != NULL) {
tcp_out.c:998:    for (; useg->next != NULL; useg = useg->next);
tcp_out.c:999:  }
tcp_out.c:1000:
tcp_out.c:1001:  netif = ip_route(&pcb->local_ip, &pcb->remote_ip);
tcp_out.c:1002:  if (netif == NULL) {
tcp_out.c:1003:    return ERR_RTE;
tcp_out.c:1004:  }
tcp_out.c:1005:
tcp_out.c:1006:  /* If we don't have a local IP address, we get one from netif */
tcp_out.c:1007:  if (ip_addr_isany(&pcb->local_ip)) {
tcp_out.c:1008:    const ip_addr_t *local_ip = ip_netif_get_local_ip(netif, &pcb->remote_ip);
tcp_out.c:1009:    if (local_ip == NULL) {
tcp_out.c:1010:      return ERR_RTE;
tcp_out.c:1011:    }
tcp_out.c:1012:    ip_addr_copy(pcb->local_ip, *local_ip);
tcp_out.c:1013:  }
tcp_out.c:1014:
tcp_out.c:1015:#if TCP_OUTPUT_DEBUG
tcp_out.c:1016:  if (seg == NULL) {
tcp_out.c:1017:    LWIP_DEBUGF(TCP_OUTPUT_DEBUG, ("tcp_output: nothing to send (%p)\n",
tcp_out.c:1018:                                   (void*)pcb->unsent));
tcp_out.c:1019:  }
tcp_out.c:1020:#endif /* TCP_OUTPUT_DEBUG */
tcp_out.c:1021:#if TCP_CWND_DEBUG
tcp_out.c:1022:  if (seg == NULL) {
tcp_out.c:1023:    LWIP_DEBUGF(TCP_CWND_DEBUG, ("tcp_output: snd_wnd %"TCPWNDSIZE_F
tcp_out.c:1024:                                 ", cwnd %"TCPWNDSIZE_F", wnd %"U32_F
tcp_out.c:1025:                                 ", seg == NULL, ack %"U32_F"\n",
tcp_out.c:1026:                                 pcb->snd_wnd, pcb->cwnd, wnd, pcb->lastack));
tcp_out.c:1027:  } else {
tcp_out.c:1028:    LWIP_DEBUGF(TCP_CWND_DEBUG,
tcp_out.c:1029:                ("tcp_output: snd_wnd %"TCPWNDSIZE_F", cwnd %"TCPWNDSIZE_F", wnd %"U32_F
tcp_out.c:1030:                 ", effwnd %"U32_F", seq %"U32_F", ack %"U32_F"\n",
tcp_out.c:1031:                 pcb->snd_wnd, pcb->cwnd, wnd,
tcp_out.c:1032:                 lwip_ntohl(seg->tcphdr->seqno) - pcb->lastack + seg->len,
tcp_out.c:1033:                 lwip_ntohl(seg->tcphdr->seqno), pcb->lastack));
tcp_out.c:1034:  }
tcp_out.c:1035:#endif /* TCP_CWND_DEBUG */
tcp_out.c:1036:  /* data available and window allows it to be sent? */
tcp_out.c:1037:  while (seg != NULL &&
tcp_out.c:1038:         lwip_ntohl(seg->tcphdr->seqno) - pcb->lastack + seg->len <= wnd) {
tcp_out.c:1039:    LWIP_ASSERT("RST not expected here!",
tcp_out.c:1040:                (TCPH_FLAGS(seg->tcphdr) & TCP_RST) == 0);
tcp_out.c:1041:    /* Stop sending if the nagle algorithm would prevent it
tcp_out.c:1042:     * Don't stop:
tcp_out.c:1043:     * - if tcp_write had a memory error before (prevent delayed ACK timeout) or
tcp_out.c:1044:     * - if FIN was already enqueued for this PCB (SYN is always alone in a segment -
tcp_out.c:1045:     *   either seg->next != NULL or pcb->unacked == NULL;
tcp_out.c:1046:     *   RST is no sent using tcp_write/tcp_output.
tcp_out.c:1047:     */
tcp_out.c:1048:    if ((tcp_do_output_nagle(pcb) == 0) &&
tcp_out.c:1049:      ((pcb->flags & (TF_NAGLEMEMERR | TF_FIN)) == 0)) {
tcp_out.c:1050:      break;
tcp_out.c:1051:    }
tcp_out.c:1052:#if TCP_CWND_DEBUG
tcp_out.c:1053:    LWIP_DEBUGF(TCP_CWND_DEBUG, ("tcp_output: snd_wnd %"TCPWNDSIZE_F", cwnd %"TCPWNDSIZE_F", wnd %"U32_F", effwnd %"U32_F", seq %"U32_F", ack %"U32_F", i %"S16_F"\n",
tcp_out.c:1054:                            pcb->snd_wnd, pcb->cwnd, wnd,
tcp_out.c:1055:                            lwip_ntohl(seg->tcphdr->seqno) + seg->len -
tcp_out.c:1056:                            pcb->lastack,
tcp_out.c:1057:                            lwip_ntohl(seg->tcphdr->seqno), pcb->lastack, i));
tcp_out.c:1058:    ++i;
tcp_out.c:1059:#endif /* TCP_CWND_DEBUG */
tcp_out.c:1060:
tcp_out.c:1061:    if (pcb->state != SYN_SENT) {
tcp_out.c:1062:      TCPH_SET_FLAG(seg->tcphdr, TCP_ACK);
tcp_out.c:1063:    }
tcp_out.c:1064:
tcp_out.c:1065:#if TCP_OVERSIZE_DBGCHECK
tcp_out.c:1066:    seg->oversize_left = 0;
tcp_out.c:1067:#endif /* TCP_OVERSIZE_DBGCHECK */
tcp_out.c:1068:    err = tcp_output_segment(seg, pcb, netif);
tcp_out.c:1069:    if (err != ERR_OK) {
tcp_out.c:1070:      /* segment could not be sent, for whatever reason */
tcp_out.c:1071:      pcb->flags |= TF_NAGLEMEMERR;
tcp_out.c:1072:      return err;
tcp_out.c:1073:    }
tcp_out.c:1074:    pcb->unsent = seg->next;
tcp_out.c:1075:    if (pcb->state != SYN_SENT) {
tcp_out.c:1076:      pcb->flags &= ~(TF_ACK_DELAY | TF_ACK_NOW);
tcp_out.c:1077:    }
tcp_out.c:1078:    snd_nxt = lwip_ntohl(seg->tcphdr->seqno) + TCP_TCPLEN(seg);
tcp_out.c:1079:    if (TCP_SEQ_LT(pcb->snd_nxt, snd_nxt)) {
tcp_out.c:1080:      pcb->snd_nxt = snd_nxt;
tcp_out.c:1081:    }
tcp_out.c:1082:    /* put segment on unacknowledged list if length > 0 */
tcp_out.c:1083:    if (TCP_TCPLEN(seg) > 0) {
tcp_out.c:1084:      seg->next = NULL;
tcp_out.c:1085:      /* unacked list is empty? */
tcp_out.c:1086:      if (pcb->unacked == NULL) {
tcp_out.c:1087:        pcb->unacked = seg;
tcp_out.c:1088:        useg = seg;
tcp_out.c:1089:      /* unacked list is not empty? */
tcp_out.c:1090:      } else {
tcp_out.c:1091:        /* In the case of fast retransmit, the packet should not go to the tail
tcp_out.c:1092:         * of the unacked queue, but rather somewhere before it. We need to check for
tcp_out.c:1093:         * this case. -STJ Jul 27, 2004 */
tcp_out.c:1094:        if (TCP_SEQ_LT(lwip_ntohl(seg->tcphdr->seqno), lwip_ntohl(useg->tcphdr->seqno))) {
tcp_out.c:1095:          /* add segment to before tail of unacked list, keeping the list sorted */
tcp_out.c:1096:          struct tcp_seg **cur_seg = &(pcb->unacked);
tcp_out.c:1097:          while (*cur_seg &&
tcp_out.c:1098:            TCP_SEQ_LT(lwip_ntohl((*cur_seg)->tcphdr->seqno), lwip_ntohl(seg->tcphdr->seqno))) {
tcp_out.c:1099:              cur_seg = &((*cur_seg)->next );
tcp_out.c:1100:          }
tcp_out.c:1101:          seg->next = (*cur_seg);
tcp_out.c:1102:          (*cur_seg) = seg;
tcp_out.c:1103:        } else {
tcp_out.c:1104:          /* add segment to tail of unacked list */
tcp_out.c:1105:          useg->next = seg;
tcp_out.c:1106:          useg = useg->next;
tcp_out.c:1107:        }
tcp_out.c:1108:      }
tcp_out.c:1109:    /* do not queue empty segments on the unacked list */
tcp_out.c:1110:    } else {
tcp_out.c:1111:      tcp_seg_free(seg);
tcp_out.c:1112:    }
tcp_out.c:1113:    seg = pcb->unsent;
tcp_out.c:1114:  }
tcp_out.c:1115:#if TCP_OVERSIZE
tcp_out.c:1116:  if (pcb->unsent == NULL) {
tcp_out.c:1117:    /* last unsent has been removed, reset unsent_oversize */
tcp_out.c:1118:    pcb->unsent_oversize = 0;
tcp_out.c:1119:  }
tcp_out.c:1120:#endif /* TCP_OVERSIZE */
tcp_out.c:1121:
tcp_out.c:1122:  pcb->flags &= ~TF_NAGLEMEMERR;
tcp_out.c:1123:  return ERR_OK;
tcp_out.c:1124:}
tcp_out.c:1125:
tcp_out.c:1126:/**
tcp_out.c:1127: * Called by tcp_output() to actually send a TCP segment over IP.
tcp_out.c:1128: *
tcp_out.c:1129: * @param seg the tcp_seg to send
tcp_out.c:1130: * @param pcb the tcp_pcb for the TCP connection used to send the segment
tcp_out.c:1131: * @param netif the netif used to send the segment
tcp_out.c:1132: */
tcp_out.c:1133:static err_t
tcp_out.c:1134:tcp_output_segment(struct tcp_seg *seg, struct tcp_pcb *pcb, struct netif *netif)
tcp_out.c:1135:{
tcp_out.c:1136:  err_t err;
tcp_out.c:1137:  u16_t len;
tcp_out.c:1138:  u32_t *opts;
tcp_out.c:1139:
tcp_out.c:1140:  if (seg->p->ref != 1) {
tcp_out.c:1141:    /* This can happen if the pbuf of this segment is still referenced by the
tcp_out.c:1142:       netif driver due to deferred transmission. Since this function modifies
tcp_out.c:1143:       p->len, we must not continue in this case. */
tcp_out.c:1144:    return ERR_OK;
tcp_out.c:1145:  }
tcp_out.c:1146:
tcp_out.c:1147:  /* The TCP header has already been constructed, but the ackno and
tcp_out.c:1148:   wnd fields remain. */
tcp_out.c:1149:  seg->tcphdr->ackno = lwip_htonl(pcb->rcv_nxt);
tcp_out.c:1150:
tcp_out.c:1151:  /* advertise our receive window size in this TCP segment */
tcp_out.c:1152:#if LWIP_WND_SCALE
tcp_out.c:1153:  if (seg->flags & TF_SEG_OPTS_WND_SCALE) {
tcp_out.c:1154:    /* The Window field in a SYN segment itself (the only type where we send
tcp_out.c:1155:       the window scale option) is never scaled. */
tcp_out.c:1156:    seg->tcphdr->wnd = lwip_htons(TCPWND_MIN16(pcb->rcv_ann_wnd));
tcp_out.c:1157:  } else
tcp_out.c:1158:#endif /* LWIP_WND_SCALE */
tcp_out.c:1159:  {
tcp_out.c:1160:    seg->tcphdr->wnd = lwip_htons(TCPWND_MIN16(RCV_WND_SCALE(pcb, pcb->rcv_ann_wnd)));
tcp_out.c:1161:  }
tcp_out.c:1162:
tcp_out.c:1163:  pcb->rcv_ann_right_edge = pcb->rcv_nxt + pcb->rcv_ann_wnd;
tcp_out.c:1164:
tcp_out.c:1165:  /* Add any requested options.  NB MSS option is only set on SYN
tcp_out.c:1166:     packets, so ignore it here */
tcp_out.c:1167:  /* cast through void* to get rid of alignment warnings */
tcp_out.c:1168:  opts = (u32_t *)(void *)(seg->tcphdr + 1);
tcp_out.c:1169:  if (seg->flags & TF_SEG_OPTS_MSS) {
tcp_out.c:1170:    u16_t mss;
tcp_out.c:1171:#if TCP_CALCULATE_EFF_SEND_MSS
tcp_out.c:1172:    mss = tcp_eff_send_mss(TCP_MSS, &pcb->local_ip, &pcb->remote_ip);
tcp_out.c:1173:#else /* TCP_CALCULATE_EFF_SEND_MSS */
tcp_out.c:1174:    mss = TCP_MSS;
tcp_out.c:1175:#endif /* TCP_CALCULATE_EFF_SEND_MSS */
tcp_out.c:1176:    *opts = TCP_BUILD_MSS_OPTION(mss);
tcp_out.c:1177:    opts += 1;
tcp_out.c:1178:  }
tcp_out.c:1179:#if LWIP_TCP_TIMESTAMPS
tcp_out.c:1180:  pcb->ts_lastacksent = pcb->rcv_nxt;
tcp_out.c:1181:
tcp_out.c:1182:  if (seg->flags & TF_SEG_OPTS_TS) {
tcp_out.c:1183:    tcp_build_timestamp_option(pcb, opts);
tcp_out.c:1184:    opts += 3;
tcp_out.c:1185:  }
tcp_out.c:1186:#endif
tcp_out.c:1187:#if LWIP_WND_SCALE
tcp_out.c:1188:  if (seg->flags & TF_SEG_OPTS_WND_SCALE) {
tcp_out.c:1189:    tcp_build_wnd_scale_option(opts);
tcp_out.c:1190:    opts += 1;
tcp_out.c:1191:  }
tcp_out.c:1192:#endif
tcp_out.c:1193:
tcp_out.c:1194:  /* Set retransmission timer running if it is not currently enabled
tcp_out.c:1195:     This must be set before checking the route. */
tcp_out.c:1196:  if (pcb->rtime < 0) {
tcp_out.c:1197:    pcb->rtime = 0;
tcp_out.c:1198:  }
tcp_out.c:1199:
tcp_out.c:1200:  if (pcb->rttest == 0) {
tcp_out.c:1201:    pcb->rttest = tcp_ticks;
tcp_out.c:1202:    pcb->rtseq = lwip_ntohl(seg->tcphdr->seqno);
tcp_out.c:1203:
tcp_out.c:1204:    LWIP_DEBUGF(TCP_RTO_DEBUG, ("tcp_output_segment: rtseq %"U32_F"\n", pcb->rtseq));
tcp_out.c:1205:  }
tcp_out.c:1206:  LWIP_DEBUGF(TCP_OUTPUT_DEBUG, ("tcp_output_segment: %"U32_F":%"U32_F"\n",
tcp_out.c:1207:          lwip_htonl(seg->tcphdr->seqno), lwip_htonl(seg->tcphdr->seqno) +
tcp_out.c:1208:          seg->len));
tcp_out.c:1209:
tcp_out.c:1210:  len = (u16_t)((u8_t *)seg->tcphdr - (u8_t *)seg->p->payload);
tcp_out.c:1211:  if (len == 0) {
tcp_out.c:1212:    /** Exclude retransmitted segments from this count. */
tcp_out.c:1213:    MIB2_STATS_INC(mib2.tcpoutsegs);
tcp_out.c:1214:  }
tcp_out.c:1215:
tcp_out.c:1216:  seg->p->len -= len;
tcp_out.c:1217:  seg->p->tot_len -= len;
tcp_out.c:1218:
tcp_out.c:1219:  seg->p->payload = seg->tcphdr;
tcp_out.c:1220:
tcp_out.c:1221:  seg->tcphdr->chksum = 0;
tcp_out.c:1222:#if CHECKSUM_GEN_TCP
tcp_out.c:1223:  IF__NETIF_CHECKSUM_ENABLED(netif, NETIF_CHECKSUM_GEN_TCP) {
tcp_out.c:1224:#if TCP_CHECKSUM_ON_COPY
tcp_out.c:1225:    u32_t acc;
tcp_out.c:1226:#if TCP_CHECKSUM_ON_COPY_SANITY_CHECK
tcp_out.c:1227:    u16_t chksum_slow = ip_chksum_pseudo(seg->p, IP_PROTO_TCP,
tcp_out.c:1228:      seg->p->tot_len, &pcb->local_ip, &pcb->remote_ip);
tcp_out.c:1229:#endif /* TCP_CHECKSUM_ON_COPY_SANITY_CHECK */
tcp_out.c:1230:    if ((seg->flags & TF_SEG_DATA_CHECKSUMMED) == 0) {
tcp_out.c:1231:      LWIP_ASSERT("data included but not checksummed",
tcp_out.c:1232:        seg->p->tot_len == (TCPH_HDRLEN(seg->tcphdr) * 4));
tcp_out.c:1233:    }
tcp_out.c:1234:
tcp_out.c:1235:    /* rebuild TCP header checksum (TCP header changes for retransmissions!) */
tcp_out.c:1236:    acc = ip_chksum_pseudo_partial(seg->p, IP_PROTO_TCP,
tcp_out.c:1237:      seg->p->tot_len, TCPH_HDRLEN(seg->tcphdr) * 4, &pcb->local_ip, &pcb->remote_ip);
tcp_out.c:1238:    /* add payload checksum */
tcp_out.c:1239:    if (seg->chksum_swapped) {
tcp_out.c:1240:      seg->chksum = SWAP_BYTES_IN_WORD(seg->chksum);
tcp_out.c:1241:      seg->chksum_swapped = 0;
tcp_out.c:1242:    }
tcp_out.c:1243:    acc += (u16_t)~(seg->chksum);
tcp_out.c:1244:    seg->tcphdr->chksum = FOLD_U32T(acc);
tcp_out.c:1245:#if TCP_CHECKSUM_ON_COPY_SANITY_CHECK
tcp_out.c:1246:    if (chksum_slow != seg->tcphdr->chksum) {
tcp_out.c:1247:      TCP_CHECKSUM_ON_COPY_SANITY_CHECK_FAIL(
tcp_out.c:1248:                  ("tcp_output_segment: calculated checksum is %"X16_F" instead of %"X16_F"\n",
tcp_out.c:1249:                  seg->tcphdr->chksum, chksum_slow));
tcp_out.c:1250:      seg->tcphdr->chksum = chksum_slow;
tcp_out.c:1251:    }
tcp_out.c:1252:#endif /* TCP_CHECKSUM_ON_COPY_SANITY_CHECK */
tcp_out.c:1253:#else /* TCP_CHECKSUM_ON_COPY */
tcp_out.c:1254:    seg->tcphdr->chksum = ip_chksum_pseudo(seg->p, IP_PROTO_TCP,
tcp_out.c:1255:      seg->p->tot_len, &pcb->local_ip, &pcb->remote_ip);
tcp_out.c:1256:#endif /* TCP_CHECKSUM_ON_COPY */
tcp_out.c:1257:  }
tcp_out.c:1258:#endif /* CHECKSUM_GEN_TCP */
tcp_out.c:1259:  TCP_STATS_INC(tcp.xmit);
tcp_out.c:1260:
tcp_out.c:1261:  NETIF_SET_HWADDRHINT(netif, &(pcb->addr_hint));
tcp_out.c:1262:  err = ip_output_if(seg->p, &pcb->local_ip, &pcb->remote_ip, pcb->ttl,
tcp_out.c:1263:    pcb->tos, IP_PROTO_TCP, netif);
tcp_out.c:1264:  NETIF_SET_HWADDRHINT(netif, NULL);
tcp_out.c:1265:  return err;
tcp_out.c:1266:}
tcp_out.c:1267:
tcp_out.c:1268:/**
tcp_out.c:1269: * Send a TCP RESET packet (empty segment with RST flag set) either to
tcp_out.c:1270: * abort a connection or to show that there is no matching local connection
tcp_out.c:1271: * for a received segment.
tcp_out.c:1272: *
tcp_out.c:1273: * Called by tcp_abort() (to abort a local connection), tcp_input() (if no
tcp_out.c:1274: * matching local pcb was found), tcp_listen_input() (if incoming segment
tcp_out.c:1275: * has ACK flag set) and tcp_process() (received segment in the wrong state)
tcp_out.c:1276: *
tcp_out.c:1277: * Since a RST segment is in most cases not sent for an active connection,
tcp_out.c:1278: * tcp_rst() has a number of arguments that are taken from a tcp_pcb for
tcp_out.c:1279: * most other segment output functions.
tcp_out.c:1280: *
tcp_out.c:1281: * @param seqno the sequence number to use for the outgoing segment
tcp_out.c:1282: * @param ackno the acknowledge number to use for the outgoing segment
tcp_out.c:1283: * @param local_ip the local IP address to send the segment from
tcp_out.c:1284: * @param remote_ip the remote IP address to send the segment to
tcp_out.c:1285: * @param local_port the local TCP port to send the segment from
tcp_out.c:1286: * @param remote_port the remote TCP port to send the segment to
tcp_out.c:1287: */
tcp_out.c:1288:void
tcp_out.c:1289:tcp_rst(u32_t seqno, u32_t ackno,
tcp_out.c:1290:  const ip_addr_t *local_ip, const ip_addr_t *remote_ip,
tcp_out.c:1291:  u16_t local_port, u16_t remote_port)
tcp_out.c:1292:{
tcp_out.c:1293:  struct pbuf *p;
tcp_out.c:1294:  struct tcp_hdr *tcphdr;
tcp_out.c:1295:  struct netif *netif;
tcp_out.c:1296:  p = pbuf_alloc(PBUF_IP, TCP_HLEN, PBUF_RAM);
tcp_out.c:1297:  if (p == NULL) {
tcp_out.c:1298:    LWIP_DEBUGF(TCP_DEBUG, ("tcp_rst: could not allocate memory for pbuf\n"));
tcp_out.c:1299:    return;
tcp_out.c:1300:  }
tcp_out.c:1301:  LWIP_ASSERT("check that first pbuf can hold struct tcp_hdr",
tcp_out.c:1302:              (p->len >= sizeof(struct tcp_hdr)));
tcp_out.c:1303:
tcp_out.c:1304:  tcphdr = (struct tcp_hdr *)p->payload;
tcp_out.c:1305:  tcphdr->src = lwip_htons(local_port);
tcp_out.c:1306:  tcphdr->dest = lwip_htons(remote_port);
tcp_out.c:1307:  tcphdr->seqno = lwip_htonl(seqno);
tcp_out.c:1308:  tcphdr->ackno = lwip_htonl(ackno);
tcp_out.c:1309:  TCPH_HDRLEN_FLAGS_SET(tcphdr, TCP_HLEN/4, TCP_RST | TCP_ACK);
tcp_out.c:1310:#if LWIP_WND_SCALE
tcp_out.c:1311:  tcphdr->wnd = PP_HTONS(((TCP_WND >> TCP_RCV_SCALE) & 0xFFFF));
tcp_out.c:1312:#else
tcp_out.c:1313:  tcphdr->wnd = PP_HTONS(TCP_WND);
tcp_out.c:1314:#endif
tcp_out.c:1315:  tcphdr->chksum = 0;
tcp_out.c:1316:  tcphdr->urgp = 0;
tcp_out.c:1317:
tcp_out.c:1318:  TCP_STATS_INC(tcp.xmit);
tcp_out.c:1319:  MIB2_STATS_INC(mib2.tcpoutrsts);
tcp_out.c:1320:
tcp_out.c:1321:  netif = ip_route(local_ip, remote_ip);
tcp_out.c:1322:  if (netif != NULL) {
tcp_out.c:1323:#if CHECKSUM_GEN_TCP
tcp_out.c:1324:    IF__NETIF_CHECKSUM_ENABLED(netif, NETIF_CHECKSUM_GEN_TCP) {
tcp_out.c:1325:      tcphdr->chksum = ip_chksum_pseudo(p, IP_PROTO_TCP, p->tot_len,
tcp_out.c:1326:                                        local_ip, remote_ip);
tcp_out.c:1327:    }
tcp_out.c:1328:#endif
tcp_out.c:1329:    /* Send output with hardcoded TTL/HL since we have no access to the pcb */
tcp_out.c:1330:    ip_output_if(p, local_ip, remote_ip, TCP_TTL, 0, IP_PROTO_TCP, netif);
tcp_out.c:1331:  }
tcp_out.c:1332:  pbuf_free(p);
tcp_out.c:1333:  LWIP_DEBUGF(TCP_RST_DEBUG, ("tcp_rst: seqno %"U32_F" ackno %"U32_F".\n", seqno, ackno));
tcp_out.c:1334:}
tcp_out.c:1335:
tcp_out.c:1336:/**
tcp_out.c:1337: * Requeue all unacked segments for retransmission
tcp_out.c:1338: *
tcp_out.c:1339: * Called by tcp_slowtmr() for slow retransmission.
tcp_out.c:1340: *
tcp_out.c:1341: * @param pcb the tcp_pcb for which to re-enqueue all unacked segments
tcp_out.c:1342: */
tcp_out.c:1343:void
tcp_out.c:1344:tcp_rexmit_rto(struct tcp_pcb *pcb)
tcp_out.c:1345:{
tcp_out.c:1346:  struct tcp_seg *seg;
tcp_out.c:1347:
tcp_out.c:1348:  if (pcb->unacked == NULL) {
tcp_out.c:1349:    return;
tcp_out.c:1350:  }
tcp_out.c:1351:
tcp_out.c:1352:  /* Move all unacked segments to the head of the unsent queue */
tcp_out.c:1353:  for (seg = pcb->unacked; seg->next != NULL; seg = seg->next);
tcp_out.c:1354:  /* concatenate unsent queue after unacked queue */
tcp_out.c:1355:  seg->next = pcb->unsent;
tcp_out.c:1356:#if TCP_OVERSIZE_DBGCHECK
tcp_out.c:1357:  /* if last unsent changed, we need to update unsent_oversize */
tcp_out.c:1358:  if (pcb->unsent == NULL) {
tcp_out.c:1359:    pcb->unsent_oversize = seg->oversize_left;
tcp_out.c:1360:  }
tcp_out.c:1361:#endif /* TCP_OVERSIZE_DBGCHECK */
tcp_out.c:1362:  /* unsent queue is the concatenated queue (of unacked, unsent) */
tcp_out.c:1363:  pcb->unsent = pcb->unacked;
tcp_out.c:1364:  /* unacked queue is now empty */
tcp_out.c:1365:  pcb->unacked = NULL;
tcp_out.c:1366:
tcp_out.c:1367:  /* increment number of retransmissions */
tcp_out.c:1368:  ++pcb->nrtx;
tcp_out.c:1369:
tcp_out.c:1370:  /* Don't take any RTT measurements after retransmitting. */
tcp_out.c:1371:  pcb->rttest = 0;
tcp_out.c:1372:
tcp_out.c:1373:  /* Do the actual retransmission */
tcp_out.c:1374:  tcp_output(pcb);
tcp_out.c:1375:}
tcp_out.c:1376:
tcp_out.c:1377:/**
tcp_out.c:1378: * Requeue the first unacked segment for retransmission
tcp_out.c:1379: *
tcp_out.c:1380: * Called by tcp_receive() for fast retransmit.
tcp_out.c:1381: *
tcp_out.c:1382: * @param pcb the tcp_pcb for which to retransmit the first unacked segment
tcp_out.c:1383: */
tcp_out.c:1384:void
tcp_out.c:1385:tcp_rexmit(struct tcp_pcb *pcb)
tcp_out.c:1386:{
tcp_out.c:1387:  struct tcp_seg *seg;
tcp_out.c:1388:  struct tcp_seg **cur_seg;
tcp_out.c:1389:
tcp_out.c:1390:  if (pcb->unacked == NULL) {
tcp_out.c:1391:    return;
tcp_out.c:1392:  }
tcp_out.c:1393:
tcp_out.c:1394:  /* Move the first unacked segment to the unsent queue */
tcp_out.c:1395:  /* Keep the unsent queue sorted. */
tcp_out.c:1396:  seg = pcb->unacked;
tcp_out.c:1397:  pcb->unacked = seg->next;
tcp_out.c:1398:
tcp_out.c:1399:  cur_seg = &(pcb->unsent);
tcp_out.c:1400:  while (*cur_seg &&
tcp_out.c:1401:    TCP_SEQ_LT(lwip_ntohl((*cur_seg)->tcphdr->seqno), lwip_ntohl(seg->tcphdr->seqno))) {
tcp_out.c:1402:      cur_seg = &((*cur_seg)->next );
tcp_out.c:1403:  }
tcp_out.c:1404:  seg->next = *cur_seg;
tcp_out.c:1405:  *cur_seg = seg;
tcp_out.c:1406:#if TCP_OVERSIZE
tcp_out.c:1407:  if (seg->next == NULL) {
tcp_out.c:1408:    /* the retransmitted segment is last in unsent, so reset unsent_oversize */
tcp_out.c:1409:    pcb->unsent_oversize = 0;
tcp_out.c:1410:  }
tcp_out.c:1411:#endif /* TCP_OVERSIZE */
tcp_out.c:1412:
tcp_out.c:1413:  ++pcb->nrtx;
tcp_out.c:1414:
tcp_out.c:1415:  /* Don't take any rtt measurements after retransmitting. */
tcp_out.c:1416:  pcb->rttest = 0;
tcp_out.c:1417:
tcp_out.c:1418:  /* Do the actual retransmission. */
tcp_out.c:1419:  MIB2_STATS_INC(mib2.tcpretranssegs);
tcp_out.c:1420:  /* No need to call tcp_output: we are always called from tcp_input()
tcp_out.c:1421:     and thus tcp_output directly returns. */
tcp_out.c:1422:}
tcp_out.c:1423:
tcp_out.c:1424:
tcp_out.c:1425:/**
tcp_out.c:1426: * Handle retransmission after three dupacks received
tcp_out.c:1427: *
tcp_out.c:1428: * @param pcb the tcp_pcb for which to retransmit the first unacked segment
tcp_out.c:1429: */
tcp_out.c:1430:void
tcp_out.c:1431:tcp_rexmit_fast(struct tcp_pcb *pcb)
tcp_out.c:1432:{
tcp_out.c:1433:  if (pcb->unacked != NULL && !(pcb->flags & TF_INFR)) {
tcp_out.c:1434:    /* This is fast retransmit. Retransmit the first unacked segment. */
tcp_out.c:1435:    LWIP_DEBUGF(TCP_FR_DEBUG,
tcp_out.c:1436:                ("tcp_receive: dupacks %"U16_F" (%"U32_F
tcp_out.c:1437:                 "), fast retransmit %"U32_F"\n",
tcp_out.c:1438:                 (u16_t)pcb->dupacks, pcb->lastack,
tcp_out.c:1439:                 lwip_ntohl(pcb->unacked->tcphdr->seqno)));
tcp_out.c:1440:    tcp_rexmit(pcb);
tcp_out.c:1441:
tcp_out.c:1442:    /* Set ssthresh to half of the minimum of the current
tcp_out.c:1443:     * cwnd and the advertised window */
tcp_out.c:1444:    if (pcb->cwnd > pcb->snd_wnd) {
tcp_out.c:1445:      pcb->ssthresh = pcb->snd_wnd / 2;
tcp_out.c:1446:    } else {
tcp_out.c:1447:      pcb->ssthresh = pcb->cwnd / 2;
tcp_out.c:1448:    }
tcp_out.c:1449:
tcp_out.c:1450:    /* The minimum value for ssthresh should be 2 MSS */
tcp_out.c:1451:    if (pcb->ssthresh < (2U * pcb->mss)) {
tcp_out.c:1452:      LWIP_DEBUGF(TCP_FR_DEBUG,
tcp_out.c:1453:                  ("tcp_receive: The minimum value for ssthresh %"TCPWNDSIZE_F
tcp_out.c:1454:                   " should be min 2 mss %"U16_F"...\n",
tcp_out.c:1455:                   pcb->ssthresh, (u16_t)(2*pcb->mss)));
tcp_out.c:1456:      pcb->ssthresh = 2*pcb->mss;
tcp_out.c:1457:    }
tcp_out.c:1458:
tcp_out.c:1459:    pcb->cwnd = pcb->ssthresh + 3 * pcb->mss;
tcp_out.c:1460:    pcb->flags |= TF_INFR;
tcp_out.c:1461:
tcp_out.c:1462:    /* Reset the retransmission timer to prevent immediate rto retransmissions */
tcp_out.c:1463:    pcb->rtime = 0;
tcp_out.c:1464:  }
tcp_out.c:1465:}
tcp_out.c:1466:
tcp_out.c:1467:
tcp_out.c:1468:/**
tcp_out.c:1469: * Send keepalive packets to keep a connection active although
tcp_out.c:1470: * no data is sent over it.
tcp_out.c:1471: *
tcp_out.c:1472: * Called by tcp_slowtmr()
tcp_out.c:1473: *
tcp_out.c:1474: * @param pcb the tcp_pcb for which to send a keepalive packet
tcp_out.c:1475: */
tcp_out.c:1476:err_t
tcp_out.c:1477:tcp_keepalive(struct tcp_pcb *pcb)
tcp_out.c:1478:{
tcp_out.c:1479:  err_t err;
tcp_out.c:1480:  struct pbuf *p;
tcp_out.c:1481:  struct netif *netif;
tcp_out.c:1482:
tcp_out.c:1483:  LWIP_DEBUGF(TCP_DEBUG, ("tcp_keepalive: sending KEEPALIVE probe to "));
tcp_out.c:1484:  ip_addr_debug_print(TCP_DEBUG, &pcb->remote_ip);
tcp_out.c:1485:  LWIP_DEBUGF(TCP_DEBUG, ("\n"));
tcp_out.c:1486:
tcp_out.c:1487:  LWIP_DEBUGF(TCP_DEBUG, ("tcp_keepalive: tcp_ticks %"U32_F"   pcb->tmr %"U32_F" pcb->keep_cnt_sent %"U16_F"\n",
tcp_out.c:1488:                          tcp_ticks, pcb->tmr, (u16_t)pcb->keep_cnt_sent));
tcp_out.c:1489:
tcp_out.c:1490:  p = tcp_output_alloc_header(pcb, 0, 0, lwip_htonl(pcb->snd_nxt - 1));
tcp_out.c:1491:  if (p == NULL) {
tcp_out.c:1492:    LWIP_DEBUGF(TCP_DEBUG,
tcp_out.c:1493:                ("tcp_keepalive: could not allocate memory for pbuf\n"));
tcp_out.c:1494:    return ERR_MEM;
tcp_out.c:1495:  }
tcp_out.c:1496:  netif = ip_route(&pcb->local_ip, &pcb->remote_ip);
tcp_out.c:1497:  if (netif == NULL) {
tcp_out.c:1498:    err = ERR_RTE;
tcp_out.c:1499:  } else {
tcp_out.c:1500:#if CHECKSUM_GEN_TCP
tcp_out.c:1501:    IF__NETIF_CHECKSUM_ENABLED(netif, NETIF_CHECKSUM_GEN_TCP) {
tcp_out.c:1502:      struct tcp_hdr *tcphdr = (struct tcp_hdr *)p->payload;
tcp_out.c:1503:      tcphdr->chksum = ip_chksum_pseudo(p, IP_PROTO_TCP, p->tot_len,
tcp_out.c:1504:        &pcb->local_ip, &pcb->remote_ip);
tcp_out.c:1505:    }
tcp_out.c:1506:#endif /* CHECKSUM_GEN_TCP */
tcp_out.c:1507:    TCP_STATS_INC(tcp.xmit);
tcp_out.c:1508:
tcp_out.c:1509:    /* Send output to IP */
tcp_out.c:1510:    NETIF_SET_HWADDRHINT(netif, &(pcb->addr_hint));
tcp_out.c:1511:    err = ip_output_if(p, &pcb->local_ip, &pcb->remote_ip, pcb->ttl, 0, IP_PROTO_TCP, netif);
tcp_out.c:1512:    NETIF_SET_HWADDRHINT(netif, NULL);
tcp_out.c:1513:  }
tcp_out.c:1514:  pbuf_free(p);
tcp_out.c:1515:
tcp_out.c:1516:  LWIP_DEBUGF(TCP_DEBUG, ("tcp_keepalive: seqno %"U32_F" ackno %"U32_F" err %d.\n",
tcp_out.c:1517:                          pcb->snd_nxt - 1, pcb->rcv_nxt, (int)err));
tcp_out.c:1518:  return err;
tcp_out.c:1519:}
tcp_out.c:1520:
tcp_out.c:1521:
tcp_out.c:1522:/**
tcp_out.c:1523: * Send persist timer zero-window probes to keep a connection active
tcp_out.c:1524: * when a window update is lost.
tcp_out.c:1525: *
tcp_out.c:1526: * Called by tcp_slowtmr()
tcp_out.c:1527: *
tcp_out.c:1528: * @param pcb the tcp_pcb for which to send a zero-window probe packet
tcp_out.c:1529: */
tcp_out.c:1530:err_t
tcp_out.c:1531:tcp_zero_window_probe(struct tcp_pcb *pcb)
tcp_out.c:1532:{
tcp_out.c:1533:  err_t err;
tcp_out.c:1534:  struct pbuf *p;
tcp_out.c:1535:  struct tcp_hdr *tcphdr;
tcp_out.c:1536:  struct tcp_seg *seg;
tcp_out.c:1537:  u16_t len;
tcp_out.c:1538:  u8_t is_fin;
tcp_out.c:1539:  u32_t snd_nxt;
tcp_out.c:1540:  struct netif *netif;
tcp_out.c:1541:
tcp_out.c:1542:  LWIP_DEBUGF(TCP_DEBUG, ("tcp_zero_window_probe: sending ZERO WINDOW probe to "));
tcp_out.c:1543:  ip_addr_debug_print(TCP_DEBUG, &pcb->remote_ip);
tcp_out.c:1544:  LWIP_DEBUGF(TCP_DEBUG, ("\n"));
tcp_out.c:1545:
tcp_out.c:1546:  LWIP_DEBUGF(TCP_DEBUG,
tcp_out.c:1547:              ("tcp_zero_window_probe: tcp_ticks %"U32_F
tcp_out.c:1548:               "   pcb->tmr %"U32_F" pcb->keep_cnt_sent %"U16_F"\n",
tcp_out.c:1549:               tcp_ticks, pcb->tmr, (u16_t)pcb->keep_cnt_sent));
tcp_out.c:1550:
tcp_out.c:1551:  seg = pcb->unacked;
tcp_out.c:1552:
tcp_out.c:1553:  if (seg == NULL) {
tcp_out.c:1554:    seg = pcb->unsent;
tcp_out.c:1555:  }
tcp_out.c:1556:  if (seg == NULL) {
tcp_out.c:1557:    /* nothing to send, zero window probe not needed */
tcp_out.c:1558:    return ERR_OK;
tcp_out.c:1559:  }
tcp_out.c:1560:
tcp_out.c:1561:  is_fin = ((TCPH_FLAGS(seg->tcphdr) & TCP_FIN) != 0) && (seg->len == 0);
tcp_out.c:1562:  /* we want to send one seqno: either FIN or data (no options) */
tcp_out.c:1563:  len = is_fin ? 0 : 1;
tcp_out.c:1564:
tcp_out.c:1565:  p = tcp_output_alloc_header(pcb, 0, len, seg->tcphdr->seqno);
tcp_out.c:1566:  if (p == NULL) {
tcp_out.c:1567:    LWIP_DEBUGF(TCP_DEBUG, ("tcp_zero_window_probe: no memory for pbuf\n"));
tcp_out.c:1568:    return ERR_MEM;
tcp_out.c:1569:  }
tcp_out.c:1570:  tcphdr = (struct tcp_hdr *)p->payload;
tcp_out.c:1571:
tcp_out.c:1572:  if (is_fin) {
tcp_out.c:1573:    /* FIN segment, no data */
tcp_out.c:1574:    TCPH_FLAGS_SET(tcphdr, TCP_ACK | TCP_FIN);
tcp_out.c:1575:  } else {
tcp_out.c:1576:    /* Data segment, copy in one byte from the head of the unacked queue */
tcp_out.c:1577:    char *d = ((char *)p->payload + TCP_HLEN);
tcp_out.c:1578:    /* Depending on whether the segment has already been sent (unacked) or not
tcp_out.c:1579:       (unsent), seg->p->payload points to the IP header or TCP header.
tcp_out.c:1580:       Ensure we copy the first TCP data byte: */
tcp_out.c:1581:    pbuf_copy_partial(seg->p, d, 1, seg->p->tot_len - seg->len);
tcp_out.c:1582:  }
tcp_out.c:1583:
tcp_out.c:1584:  /* The byte may be acknowledged without the window being opened. */
tcp_out.c:1585:  snd_nxt = lwip_ntohl(seg->tcphdr->seqno) + 1;
tcp_out.c:1586:  if (TCP_SEQ_LT(pcb->snd_nxt, snd_nxt)) {
tcp_out.c:1587:    pcb->snd_nxt = snd_nxt;
tcp_out.c:1588:  }
tcp_out.c:1589:
tcp_out.c:1590:  netif = ip_route(&pcb->local_ip, &pcb->remote_ip);
tcp_out.c:1591:  if (netif == NULL) {
tcp_out.c:1592:    err = ERR_RTE;
tcp_out.c:1593:  } else {
tcp_out.c:1594:#if CHECKSUM_GEN_TCP
tcp_out.c:1595:    IF__NETIF_CHECKSUM_ENABLED(netif, NETIF_CHECKSUM_GEN_TCP) {
tcp_out.c:1596:      tcphdr->chksum = ip_chksum_pseudo(p, IP_PROTO_TCP, p->tot_len,
tcp_out.c:1597:        &pcb->local_ip, &pcb->remote_ip);
tcp_out.c:1598:    }
tcp_out.c:1599:#endif
tcp_out.c:1600:    TCP_STATS_INC(tcp.xmit);
tcp_out.c:1601:
tcp_out.c:1602:    /* Send output to IP */
tcp_out.c:1603:    NETIF_SET_HWADDRHINT(netif, &(pcb->addr_hint));
tcp_out.c:1604:    err = ip_output_if(p, &pcb->local_ip, &pcb->remote_ip, pcb->ttl,
tcp_out.c:1605:      0, IP_PROTO_TCP, netif);
tcp_out.c:1606:    NETIF_SET_HWADDRHINT(netif, NULL);
tcp_out.c:1607:  }
tcp_out.c:1608:
tcp_out.c:1609:  pbuf_free(p);
tcp_out.c:1610:
tcp_out.c:1611:  LWIP_DEBUGF(TCP_DEBUG, ("tcp_zero_window_probe: seqno %"U32_F
tcp_out.c:1612:                          " ackno %"U32_F" err %d.\n",
tcp_out.c:1613:                          pcb->snd_nxt - 1, pcb->rcv_nxt, (int)err));
tcp_out.c:1614:  return err;
tcp_out.c:1615:}
tcp_out.c:1616:#endif /* LWIP_TCP */
pbuf.c:120:#if LWIP_TCP && TCP_QUEUE_OOSEQ
pbuf.c:121:#include "lwip/priv/tcp_priv.h"
pbuf.c:122:#endif
pbuf.c:123:#if LWIP_CHECKSUM_ON_COPY
pbuf.c:124:#include "lwip/inet_chksum.h"
pbuf.c:125:#endif
pbuf.c:126:
pbuf.c:127:#include <string.h>
pbuf.c:128:
pbuf.c:129:#define SIZEOF_STRUCT_PBUF        LWIP_MEM_ALIGN_SIZE(sizeof(struct pbuf))
pbuf.c:130:/* Since the pool is created in memp, PBUF_POOL_BUFSIZE will be automatically
pbuf.c:131:   aligned there. Therefore, PBUF_POOL_BUFSIZE_ALIGNED can be used here. */
pbuf.c:132:#define PBUF_POOL_BUFSIZE_ALIGNED LWIP_MEM_ALIGN_SIZE(PBUF_POOL_BUFSIZE)
pbuf.c:133:
pbuf.c:134:#if !LWIP_TCP || !TCP_QUEUE_OOSEQ || !PBUF_POOL_FREE_OOSEQ
pbuf.c:135:#define PBUF_POOL_IS_EMPTY()
pbuf.c:136:#else /* !LWIP_TCP || !TCP_QUEUE_OOSEQ || !PBUF_POOL_FREE_OOSEQ */
pbuf.c:137:
pbuf.c:138:#if !NO_SYS
pbuf.c:139:#ifndef PBUF_POOL_FREE_OOSEQ_QUEUE_CALL
pbuf.c:140:#include "lwip/tcpip.h"
pbuf.c:141:#define PBUF_POOL_FREE_OOSEQ_QUEUE_CALL()  do { \
pbuf.c:142:  if (tcpip_callback_with_block(pbuf_free_ooseq_callback, NULL, 0) != ERR_OK) { \
pbuf.c:143:      SYS_ARCH_PROTECT(old_level); \
pbuf.c:144:      pbuf_free_ooseq_pending = 0; \
pbuf.c:145:      SYS_ARCH_UNPROTECT(old_level); \
pbuf.c:146:  } } while(0)
pbuf.c:147:#endif /* PBUF_POOL_FREE_OOSEQ_QUEUE_CALL */
pbuf.c:148:#endif /* !NO_SYS */
pbuf.c:149:
pbuf.c:150:volatile u8_t pbuf_free_ooseq_pending;
pbuf.c:151:#define PBUF_POOL_IS_EMPTY() pbuf_pool_is_empty()
pbuf.c:152:
pbuf.c:153:/**
pbuf.c:154: * Attempt to reclaim some memory from queued out-of-sequence TCP segments
pbuf.c:155: * if we run out of pool pbufs. It's better to give priority to new packets
pbuf.c:156: * if we're running out.
pbuf.c:157: *
pbuf.c:158: * This must be done in the correct thread context therefore this function
pbuf.c:159: * can only be used with NO_SYS=0 and through tcpip_callback.
pbuf.c:160: */
pbuf.c:161:#if !NO_SYS
pbuf.c:162:static
pbuf.c:163:#endif /* !NO_SYS */
pbuf.c:164:void
pbuf.c:165:pbuf_free_ooseq(void)
pbuf.c:166:{
pbuf.c:167:  struct tcp_pcb* pcb;
pbuf.c:168:  SYS_ARCH_SET(pbuf_free_ooseq_pending, 0);
pbuf.c:169:
pbuf.c:170:  for (pcb = tcp_active_pcbs; NULL != pcb; pcb = pcb->next) {
pbuf.c:171:    if (NULL != pcb->ooseq) {
pbuf.c:172:      /** Free the ooseq pbufs of one PCB only */
pbuf.c:173:      LWIP_DEBUGF(PBUF_DEBUG | LWIP_DBG_TRACE, ("pbuf_free_ooseq: freeing out-of-sequence pbufs\n"));
pbuf.c:174:      tcp_segs_free(pcb->ooseq);
pbuf.c:175:      pcb->ooseq = NULL;
pbuf.c:176:      return;
pbuf.c:177:    }
pbuf.c:178:  }
pbuf.c:179:}
pbuf.c:180:
pbuf.c:181:#if !NO_SYS
pbuf.c:182:/**
pbuf.c:183: * Just a callback function for tcpip_callback() that calls pbuf_free_ooseq().
pbuf.c:184: */
pbuf.c:185:static void
pbuf.c:186:pbuf_free_ooseq_callback(void *arg)
pbuf.c:187:{
pbuf.c:188:  LWIP_UNUSED_ARG(arg);
pbuf.c:189:  pbuf_free_ooseq();
pbuf.c:190:}
pbuf.c:191:#endif /* !NO_SYS */
pbuf.c:192:
pbuf.c:193:/** Queue a call to pbuf_free_ooseq if not already queued. */
pbuf.c:194:static void
pbuf.c:195:pbuf_pool_is_empty(void)
pbuf.c:196:{
pbuf.c:197:#ifndef PBUF_POOL_FREE_OOSEQ_QUEUE_CALL
pbuf.c:198:  SYS_ARCH_SET(pbuf_free_ooseq_pending, 1);
pbuf.c:199:#else /* PBUF_POOL_FREE_OOSEQ_QUEUE_CALL */
pbuf.c:200:  u8_t queued;
pbuf.c:201:  SYS_ARCH_DECL_PROTECT(old_level);
pbuf.c:202:  SYS_ARCH_PROTECT(old_level);
pbuf.c:203:  queued = pbuf_free_ooseq_pending;
pbuf.c:204:  pbuf_free_ooseq_pending = 1;
pbuf.c:205:  SYS_ARCH_UNPROTECT(old_level);
pbuf.c:206:
pbuf.c:207:  if (!queued) {
pbuf.c:208:    /* queue a call to pbuf_free_ooseq if not already queued */
pbuf.c:209:    PBUF_POOL_FREE_OOSEQ_QUEUE_CALL();
pbuf.c:210:  }
pbuf.c:211:#endif /* PBUF_POOL_FREE_OOSEQ_QUEUE_CALL */
pbuf.c:212:}
pbuf.c:213:#endif /* !LWIP_TCP || !TCP_QUEUE_OOSEQ || !PBUF_POOL_FREE_OOSEQ */
pbuf.c:214:
pbuf.c:215:/**
pbuf.c:216: * @ingroup pbuf
pbuf.c:217: * Allocates a pbuf of the given type (possibly a chain for PBUF_POOL type).
pbuf.c:218: *
pbuf.c:219: * The actual memory allocated for the pbuf is determined by the
pbuf.c:220: * layer at which the pbuf is allocated and the requested size
pbuf.c:221: * (from the size parameter).
pbuf.c:222: *
pbuf.c:223: * @param layer flag to define header size
pbuf.c:224: * @param length size of the pbuf's payload
pbuf.c:225: * @param type this parameter decides how and where the pbuf
pbuf.c:226: * should be allocated as follows:
pbuf.c:227: *
pbuf.c:228: * - PBUF_RAM: buffer memory for pbuf is allocated as one large
pbuf.c:229: *             chunk. This includes protocol headers as well.
pbuf.c:230: * - PBUF_ROM: no buffer memory is allocated for the pbuf, even for
pbuf.c:231: *             protocol headers. Additional headers must be prepended
pbuf.c:232: *             by allocating another pbuf and chain in to the front of
pbuf.c:233: *             the ROM pbuf. It is assumed that the memory used is really
pbuf.c:234: *             similar to ROM in that it is immutable and will not be
pbuf.c:235: *             changed. Memory which is dynamic should generally not
pbuf.c:236: *             be attached to PBUF_ROM pbufs. Use PBUF_REF instead.
pbuf.c:237: * - PBUF_REF: no buffer memory is allocated for the pbuf, even for
pbuf.c:238: *             protocol headers. It is assumed that the pbuf is only
pbuf.c:239: *             being used in a single thread. If the pbuf gets queued,
pbuf.c:240: *             then pbuf_take should be called to copy the buffer.
pbuf.c:241: * - PBUF_POOL: the pbuf is allocated as a pbuf chain, with pbufs from
pbuf.c:242: *              the pbuf pool that is allocated during pbuf_init().
pbuf.c:243: *
pbuf.c:244: * @return the allocated pbuf. If multiple pbufs where allocated, this
pbuf.c:245: * is the first pbuf of a pbuf chain.
pbuf.c:246: */
pbuf.c:247:struct pbuf *
pbuf.c:248:pbuf_alloc(pbuf_layer layer, u16_t length, pbuf_type type)
pbuf.c:249:{
pbuf.c:250:  struct pbuf *p, *q, *r;
pbuf.c:251:  u16_t offset;
pbuf.c:252:  s32_t rem_len; /* remaining length */
pbuf.c:253:  LWIP_DEBUGF(PBUF_DEBUG | LWIP_DBG_TRACE, ("pbuf_alloc(length=%"U16_F")\n", length));
pbuf.c:254:
pbuf.c:255:  /* determine header offset */
pbuf.c:256:  switch (layer) {
pbuf.c:257:  case PBUF_TRANSPORT:
pbuf.c:258:    /* add room for transport (often TCP) layer header */
pbuf.c:259:    offset = PBUF_LINK_ENCAPSULATION_HLEN + PBUF_LINK_HLEN + PBUF_IP_HLEN + PBUF_TRANSPORT_HLEN;
pbuf.c:260:    break;
pbuf.c:261:  case PBUF_IP:
pbuf.c:262:    /* add room for IP layer header */
pbuf.c:263:    offset = PBUF_LINK_ENCAPSULATION_HLEN + PBUF_LINK_HLEN + PBUF_IP_HLEN;
pbuf.c:264:    break;
pbuf.c:265:  case PBUF_LINK:
pbuf.c:266:    /* add room for link layer header */
pbuf.c:267:    offset = PBUF_LINK_ENCAPSULATION_HLEN + PBUF_LINK_HLEN;
pbuf.c:268:    break;
pbuf.c:269:  case PBUF_RAW_TX:
pbuf.c:270:    /* add room for encapsulating link layer headers (e.g. 802.11) */
pbuf.c:271:    offset = PBUF_LINK_ENCAPSULATION_HLEN;
pbuf.c:272:    break;
pbuf.c:273:  case PBUF_RAW:
pbuf.c:274:    /* no offset (e.g. RX buffers or chain successors) */
pbuf.c:275:    offset = 0;
pbuf.c:276:    break;
pbuf.c:277:  default:
pbuf.c:278:    LWIP_ASSERT("pbuf_alloc: bad pbuf layer", 0);
pbuf.c:279:    return NULL;
pbuf.c:280:  }
pbuf.c:281:
pbuf.c:282:  switch (type) {
pbuf.c:283:  case PBUF_POOL:
pbuf.c:284:    /* allocate head of pbuf chain into p */
pbuf.c:285:    p = (struct pbuf *)memp_malloc(MEMP_PBUF_POOL);
pbuf.c:286:    LWIP_DEBUGF(PBUF_DEBUG | LWIP_DBG_TRACE, ("pbuf_alloc: allocated pbuf %p\n", (void *)p));
pbuf.c:287:    if (p == NULL) {
pbuf.c:288:      PBUF_POOL_IS_EMPTY();
pbuf.c:289:      return NULL;
pbuf.c:290:    }
pbuf.c:291:    p->type = type;
pbuf.c:292:    p->next = NULL;
pbuf.c:293:
pbuf.c:294:    /* make the payload pointer point 'offset' bytes into pbuf data memory */
pbuf.c:295:    p->payload = LWIP_MEM_ALIGN((void *)((u8_t *)p + (SIZEOF_STRUCT_PBUF + offset)));
pbuf.c:296:    LWIP_ASSERT("pbuf_alloc: pbuf p->payload properly aligned",
pbuf.c:297:            ((mem_ptr_t)p->payload % MEM_ALIGNMENT) == 0);
pbuf.c:298:    /* the total length of the pbuf chain is the requested size */
pbuf.c:299:    p->tot_len = length;
pbuf.c:300:    /* set the length of the first pbuf in the chain */
pbuf.c:301:    p->len = LWIP_MIN(length, PBUF_POOL_BUFSIZE_ALIGNED - LWIP_MEM_ALIGN_SIZE(offset));
pbuf.c:302:    LWIP_ASSERT("check p->payload + p->len does not overflow pbuf",
pbuf.c:303:                ((u8_t*)p->payload + p->len <=
pbuf.c:304:                 (u8_t*)p + SIZEOF_STRUCT_PBUF + PBUF_POOL_BUFSIZE_ALIGNED));
pbuf.c:305:    LWIP_ASSERT("PBUF_POOL_BUFSIZE must be bigger than MEM_ALIGNMENT",
pbuf.c:306:      (PBUF_POOL_BUFSIZE_ALIGNED - LWIP_MEM_ALIGN_SIZE(offset)) > 0 );
pbuf.c:307:    /* set reference count (needed here in case we fail) */
pbuf.c:308:    p->ref = 1;
pbuf.c:309:
pbuf.c:310:    /* now allocate the tail of the pbuf chain */
pbuf.c:311:
pbuf.c:312:    /* remember first pbuf for linkage in next iteration */
pbuf.c:313:    r = p;
pbuf.c:314:    /* remaining length to be allocated */
pbuf.c:315:    rem_len = length - p->len;
pbuf.c:316:    /* any remaining pbufs to be allocated? */
pbuf.c:317:    while (rem_len > 0) {
pbuf.c:318:      q = (struct pbuf *)memp_malloc(MEMP_PBUF_POOL);
pbuf.c:319:      if (q == NULL) {
pbuf.c:320:        PBUF_POOL_IS_EMPTY();
pbuf.c:321:        /* free chain so far allocated */
pbuf.c:322:        pbuf_free(p);
pbuf.c:323:        /* bail out unsuccessfully */
pbuf.c:324:        return NULL;
pbuf.c:325:      }
pbuf.c:326:      q->type = type;
pbuf.c:327:      q->flags = 0;
pbuf.c:328:      q->next = NULL;
pbuf.c:329:      /* make previous pbuf point to this pbuf */
pbuf.c:330:      r->next = q;
pbuf.c:331:      /* set total length of this pbuf and next in chain */
pbuf.c:332:      LWIP_ASSERT("rem_len < max_u16_t", rem_len < 0xffff);
pbuf.c:333:      q->tot_len = (u16_t)rem_len;
pbuf.c:334:      /* this pbuf length is pool size, unless smaller sized tail */
pbuf.c:335:      q->len = LWIP_MIN((u16_t)rem_len, PBUF_POOL_BUFSIZE_ALIGNED);
pbuf.c:336:      q->payload = (void *)((u8_t *)q + SIZEOF_STRUCT_PBUF);
pbuf.c:337:      LWIP_ASSERT("pbuf_alloc: pbuf q->payload properly aligned",
pbuf.c:338:              ((mem_ptr_t)q->payload % MEM_ALIGNMENT) == 0);
pbuf.c:339:      LWIP_ASSERT("check p->payload + p->len does not overflow pbuf",
pbuf.c:340:                  ((u8_t*)p->payload + p->len <=
pbuf.c:341:                   (u8_t*)p + SIZEOF_STRUCT_PBUF + PBUF_POOL_BUFSIZE_ALIGNED));
pbuf.c:342:      q->ref = 1;
pbuf.c:343:      /* calculate remaining length to be allocated */
pbuf.c:344:      rem_len -= q->len;
pbuf.c:345:      /* remember this pbuf for linkage in next iteration */
pbuf.c:346:      r = q;
pbuf.c:347:    }
pbuf.c:348:    /* end of chain */
pbuf.c:349:    /*r->next = NULL;*/
pbuf.c:350:
pbuf.c:351:    break;
pbuf.c:352:  case PBUF_RAM:
pbuf.c:353:    /* If pbuf is to be allocated in RAM, allocate memory for it. */
pbuf.c:354:    p = (struct pbuf*)mem_malloc(LWIP_MEM_ALIGN_SIZE(SIZEOF_STRUCT_PBUF + offset) + LWIP_MEM_ALIGN_SIZE(length));
pbuf.c:355:    if (p == NULL) {
pbuf.c:356:      return NULL;
pbuf.c:357:    }
pbuf.c:358:    /* Set up internal structure of the pbuf. */
pbuf.c:359:    p->payload = LWIP_MEM_ALIGN((void *)((u8_t *)p + SIZEOF_STRUCT_PBUF + offset));
pbuf.c:360:    p->len = p->tot_len = length;
pbuf.c:361:    p->next = NULL;
pbuf.c:362:    p->type = type;
pbuf.c:363:
pbuf.c:364:    LWIP_ASSERT("pbuf_alloc: pbuf->payload properly aligned",
pbuf.c:365:           ((mem_ptr_t)p->payload % MEM_ALIGNMENT) == 0);
pbuf.c:366:    break;
pbuf.c:367:  /* pbuf references existing (non-volatile static constant) ROM payload? */
pbuf.c:368:  case PBUF_ROM:
pbuf.c:369:  /* pbuf references existing (externally allocated) RAM payload? */
pbuf.c:370:  case PBUF_REF:
pbuf.c:371:    /* only allocate memory for the pbuf structure */
pbuf.c:372:    p = (struct pbuf *)memp_malloc(MEMP_PBUF);
pbuf.c:373:    if (p == NULL) {
pbuf.c:374:      LWIP_DEBUGF(PBUF_DEBUG | LWIP_DBG_LEVEL_SERIOUS,
pbuf.c:375:                  ("pbuf_alloc: Could not allocate MEMP_PBUF for PBUF_%s.\n",
pbuf.c:376:                  (type == PBUF_ROM) ? "ROM" : "REF"));
pbuf.c:377:      return NULL;
pbuf.c:378:    }
pbuf.c:379:    /* caller must set this field properly, afterwards */
pbuf.c:380:    p->payload = NULL;
pbuf.c:381:    p->len = p->tot_len = length;
pbuf.c:382:    p->next = NULL;
pbuf.c:383:    p->type = type;
pbuf.c:384:    break;
pbuf.c:385:  default:
pbuf.c:386:    LWIP_ASSERT("pbuf_alloc: erroneous type", 0);
pbuf.c:387:    return NULL;
pbuf.c:388:  }
pbuf.c:389:  /* set reference count */
pbuf.c:390:  p->ref = 1;
pbuf.c:391:  /* set flags */
pbuf.c:392:  p->flags = 0;
pbuf.c:393:  LWIP_DEBUGF(PBUF_DEBUG | LWIP_DBG_TRACE, ("pbuf_alloc(length=%"U16_F") == %p\n", length, (void *)p));
pbuf.c:394:  return p;
pbuf.c:395:}
pbuf.c:396:
pbuf.c:397:#if LWIP_SUPPORT_CUSTOM_PBUF
pbuf.c:398:/**
pbuf.c:399: * @ingroup pbuf
pbuf.c:400: * Initialize a custom pbuf (already allocated).
pbuf.c:401: *
pbuf.c:402: * @param l flag to define header size
pbuf.c:403: * @param length size of the pbuf's payload
pbuf.c:404: * @param type type of the pbuf (only used to treat the pbuf accordingly, as
pbuf.c:405: *        this function allocates no memory)
pbuf.c:406: * @param p pointer to the custom pbuf to initialize (already allocated)
pbuf.c:407: * @param payload_mem pointer to the buffer that is used for payload and headers,
pbuf.c:408: *        must be at least big enough to hold 'length' plus the header size,
pbuf.c:409: *        may be NULL if set later.
pbuf.c:410: *        ATTENTION: The caller is responsible for correct alignment of this buffer!!
pbuf.c:411: * @param payload_mem_len the size of the 'payload_mem' buffer, must be at least
pbuf.c:412: *        big enough to hold 'length' plus the header size
pbuf.c:413: */
pbuf.c:414:struct pbuf*
pbuf.c:415:pbuf_alloced_custom(pbuf_layer l, u16_t length, pbuf_type type, struct pbuf_custom *p,
pbuf.c:416:                    void *payload_mem, u16_t payload_mem_len)
pbuf.c:417:{
pbuf.c:418:  u16_t offset;
pbuf.c:419:  LWIP_DEBUGF(PBUF_DEBUG | LWIP_DBG_TRACE, ("pbuf_alloced_custom(length=%"U16_F")\n", length));
pbuf.c:420:
pbuf.c:421:  /* determine header offset */
pbuf.c:422:  switch (l) {
pbuf.c:423:  case PBUF_TRANSPORT:
pbuf.c:424:    /* add room for transport (often TCP) layer header */
pbuf.c:425:    offset = PBUF_LINK_ENCAPSULATION_HLEN + PBUF_LINK_HLEN + PBUF_IP_HLEN + PBUF_TRANSPORT_HLEN;
pbuf.c:426:    break;
pbuf.c:427:  case PBUF_IP:
pbuf.c:428:    /* add room for IP layer header */
pbuf.c:429:    offset = PBUF_LINK_ENCAPSULATION_HLEN + PBUF_LINK_HLEN + PBUF_IP_HLEN;
pbuf.c:430:    break;
pbuf.c:431:  case PBUF_LINK:
pbuf.c:432:    /* add room for link layer header */
pbuf.c:433:    offset = PBUF_LINK_ENCAPSULATION_HLEN + PBUF_LINK_HLEN;
pbuf.c:434:    break;
pbuf.c:435:  case PBUF_RAW_TX:
pbuf.c:436:    /* add room for encapsulating link layer headers (e.g. 802.11) */
pbuf.c:437:    offset = PBUF_LINK_ENCAPSULATION_HLEN;
pbuf.c:438:    break;
pbuf.c:439:  case PBUF_RAW:
pbuf.c:440:    offset = 0;
pbuf.c:441:    break;
pbuf.c:442:  default:
pbuf.c:443:    LWIP_ASSERT("pbuf_alloced_custom: bad pbuf layer", 0);
pbuf.c:444:    return NULL;
pbuf.c:445:  }
pbuf.c:446:
pbuf.c:447:  if (LWIP_MEM_ALIGN_SIZE(offset) + length > payload_mem_len) {
pbuf.c:448:    LWIP_DEBUGF(PBUF_DEBUG | LWIP_DBG_LEVEL_WARNING, ("pbuf_alloced_custom(length=%"U16_F") buffer too short\n", length));
pbuf.c:449:    return NULL;
pbuf.c:450:  }
pbuf.c:451:
pbuf.c:452:  p->pbuf.next = NULL;
pbuf.c:453:  if (payload_mem != NULL) {
pbuf.c:454:    p->pbuf.payload = (u8_t *)payload_mem + LWIP_MEM_ALIGN_SIZE(offset);
pbuf.c:455:  } else {
pbuf.c:456:    p->pbuf.payload = NULL;
pbuf.c:457:  }
pbuf.c:458:  p->pbuf.flags = PBUF_FLAG_IS_CUSTOM;
pbuf.c:459:  p->pbuf.len = p->pbuf.tot_len = length;
pbuf.c:460:  p->pbuf.type = type;
pbuf.c:461:  p->pbuf.ref = 1;
pbuf.c:462:  return &p->pbuf;
pbuf.c:463:}
pbuf.c:464:#endif /* LWIP_SUPPORT_CUSTOM_PBUF */
pbuf.c:465:
pbuf.c:466:/**
pbuf.c:467: * @ingroup pbuf
pbuf.c:468: * Shrink a pbuf chain to a desired length.
pbuf.c:469: *
pbuf.c:470: * @param p pbuf to shrink.
pbuf.c:471: * @param new_len desired new length of pbuf chain
pbuf.c:472: *
pbuf.c:473: * Depending on the desired length, the first few pbufs in a chain might
pbuf.c:474: * be skipped and left unchanged. The new last pbuf in the chain will be
pbuf.c:475: * resized, and any remaining pbufs will be freed.
pbuf.c:476: *
pbuf.c:477: * @note If the pbuf is ROM/REF, only the ->tot_len and ->len fields are adjusted.
pbuf.c:478: * @note May not be called on a packet queue.
pbuf.c:479: *
pbuf.c:480: * @note Despite its name, pbuf_realloc cannot grow the size of a pbuf (chain).
pbuf.c:481: */
pbuf.c:482:void
pbuf.c:483:pbuf_realloc(struct pbuf *p, u16_t new_len)
pbuf.c:484:{
pbuf.c:485:  struct pbuf *q;
pbuf.c:486:  u16_t rem_len; /* remaining length */
pbuf.c:487:  s32_t grow;
pbuf.c:488:
pbuf.c:489:  LWIP_ASSERT("pbuf_realloc: p != NULL", p != NULL);
pbuf.c:490:  LWIP_ASSERT("pbuf_realloc: sane p->type", p->type == PBUF_POOL ||
pbuf.c:491:              p->type == PBUF_ROM ||
pbuf.c:492:              p->type == PBUF_RAM ||
pbuf.c:493:              p->type == PBUF_REF);
pbuf.c:494:
pbuf.c:495:  /* desired length larger than current length? */
pbuf.c:496:  if (new_len >= p->tot_len) {
pbuf.c:497:    /* enlarging not yet supported */
pbuf.c:498:    return;
pbuf.c:499:  }
pbuf.c:500:
pbuf.c:501:  /* the pbuf chain grows by (new_len - p->tot_len) bytes
pbuf.c:502:   * (which may be negative in case of shrinking) */
pbuf.c:503:  grow = new_len - p->tot_len;
pbuf.c:504:
pbuf.c:505:  /* first, step over any pbufs that should remain in the chain */
pbuf.c:506:  rem_len = new_len;
pbuf.c:507:  q = p;
pbuf.c:508:  /* should this pbuf be kept? */
pbuf.c:509:  while (rem_len > q->len) {
pbuf.c:510:    /* decrease remaining length by pbuf length */
pbuf.c:511:    rem_len -= q->len;
pbuf.c:512:    /* decrease total length indicator */
pbuf.c:513:    LWIP_ASSERT("grow < max_u16_t", grow < 0xffff);
pbuf.c:514:    q->tot_len += (u16_t)grow;
pbuf.c:515:    /* proceed to next pbuf in chain */
pbuf.c:516:    q = q->next;
pbuf.c:517:    LWIP_ASSERT("pbuf_realloc: q != NULL", q != NULL);
pbuf.c:518:  }
pbuf.c:519:  /* we have now reached the new last pbuf (in q) */
pbuf.c:520:  /* rem_len == desired length for pbuf q */
pbuf.c:521:
pbuf.c:522:  /* shrink allocated memory for PBUF_RAM */
pbuf.c:523:  /* (other types merely adjust their length fields */
pbuf.c:524:  if ((q->type == PBUF_RAM) && (rem_len != q->len)
pbuf.c:525:#if LWIP_SUPPORT_CUSTOM_PBUF
pbuf.c:526:      && ((q->flags & PBUF_FLAG_IS_CUSTOM) == 0)
pbuf.c:527:#endif /* LWIP_SUPPORT_CUSTOM_PBUF */
pbuf.c:528:     ) {
pbuf.c:529:    /* reallocate and adjust the length of the pbuf that will be split */
pbuf.c:530:    q = (struct pbuf *)mem_trim(q, (u16_t)((u8_t *)q->payload - (u8_t *)q) + rem_len);
pbuf.c:531:    LWIP_ASSERT("mem_trim returned q == NULL", q != NULL);
pbuf.c:532:  }
pbuf.c:533:  /* adjust length fields for new last pbuf */
pbuf.c:534:  q->len = rem_len;
pbuf.c:535:  q->tot_len = q->len;
pbuf.c:536:
pbuf.c:537:  /* any remaining pbufs in chain? */
pbuf.c:538:  if (q->next != NULL) {
pbuf.c:539:    /* free remaining pbufs in chain */
pbuf.c:540:    pbuf_free(q->next);
pbuf.c:541:  }
pbuf.c:542:  /* q is last packet in chain */
pbuf.c:543:  q->next = NULL;
pbuf.c:544:
pbuf.c:545:}
pbuf.c:546:
pbuf.c:547:/**
pbuf.c:548: * Adjusts the payload pointer to hide or reveal headers in the payload.
pbuf.c:549: * @see pbuf_header.
pbuf.c:550: *
pbuf.c:551: * @param p pbuf to change the header size.
pbuf.c:552: * @param header_size_increment Number of bytes to increment header size.
pbuf.c:553: * @param force Allow 'header_size_increment > 0' for PBUF_REF/PBUF_ROM types
pbuf.c:554: *
pbuf.c:555: * @return non-zero on failure, zero on success.
pbuf.c:556: *
pbuf.c:557: */
pbuf.c:558:static u8_t
pbuf.c:559:pbuf_header_impl(struct pbuf *p, s16_t header_size_increment, u8_t force)
pbuf.c:560:{
pbuf.c:561:  u16_t type;
pbuf.c:562:  void *payload;
pbuf.c:563:  u16_t increment_magnitude;
pbuf.c:564:
pbuf.c:565:  LWIP_ASSERT("p != NULL", p != NULL);
pbuf.c:566:  if ((header_size_increment == 0) || (p == NULL)) {
pbuf.c:567:    return 0;
pbuf.c:568:  }
pbuf.c:569:
pbuf.c:570:  if (header_size_increment < 0) {
pbuf.c:571:    increment_magnitude = -header_size_increment;
pbuf.c:572:    /* Check that we aren't going to move off the end of the pbuf */
pbuf.c:573:    LWIP_ERROR("increment_magnitude <= p->len", (increment_magnitude <= p->len), return 1;);
pbuf.c:574:  } else {
pbuf.c:575:    increment_magnitude = header_size_increment;
pbuf.c:576:#if 0
pbuf.c:577:    /* Can't assert these as some callers speculatively call
pbuf.c:578:         pbuf_header() to see if it's OK.  Will return 1 below instead. */
pbuf.c:579:    /* Check that we've got the correct type of pbuf to work with */
pbuf.c:580:    LWIP_ASSERT("p->type == PBUF_RAM || p->type == PBUF_POOL",
pbuf.c:581:                p->type == PBUF_RAM || p->type == PBUF_POOL);
pbuf.c:582:    /* Check that we aren't going to move off the beginning of the pbuf */
pbuf.c:583:    LWIP_ASSERT("p->payload - increment_magnitude >= p + SIZEOF_STRUCT_PBUF",
pbuf.c:584:                (u8_t *)p->payload - increment_magnitude >= (u8_t *)p + SIZEOF_STRUCT_PBUF);
pbuf.c:585:#endif
pbuf.c:586:  }
pbuf.c:587:
pbuf.c:588:  type = p->type;
pbuf.c:589:  /* remember current payload pointer */
pbuf.c:590:  payload = p->payload;
pbuf.c:591:
pbuf.c:592:  /* pbuf types containing payloads? */
pbuf.c:593:  if (type == PBUF_RAM || type == PBUF_POOL) {
pbuf.c:594:    /* set new payload pointer */
pbuf.c:595:    p->payload = (u8_t *)p->payload - header_size_increment;
pbuf.c:596:    /* boundary check fails? */
pbuf.c:597:    if ((u8_t *)p->payload < (u8_t *)p + SIZEOF_STRUCT_PBUF) {
pbuf.c:598:      LWIP_DEBUGF( PBUF_DEBUG | LWIP_DBG_TRACE,
pbuf.c:599:        ("pbuf_header: failed as %p < %p (not enough space for new header size)\n",
pbuf.c:600:        (void *)p->payload, (void *)((u8_t *)p + SIZEOF_STRUCT_PBUF)));
pbuf.c:601:      /* restore old payload pointer */
pbuf.c:602:      p->payload = payload;
pbuf.c:603:      /* bail out unsuccessfully */
pbuf.c:604:      return 1;
pbuf.c:605:    }
pbuf.c:606:  /* pbuf types referring to external payloads? */
pbuf.c:607:  } else if (type == PBUF_REF || type == PBUF_ROM) {
pbuf.c:608:    /* hide a header in the payload? */
pbuf.c:609:    if ((header_size_increment < 0) && (increment_magnitude <= p->len)) {
pbuf.c:610:      /* increase payload pointer */
pbuf.c:611:      p->payload = (u8_t *)p->payload - header_size_increment;
pbuf.c:612:    } else if ((header_size_increment > 0) && force) {
pbuf.c:613:      p->payload = (u8_t *)p->payload - header_size_increment;
pbuf.c:614:    } else {
pbuf.c:615:      /* cannot expand payload to front (yet!)
pbuf.c:616:       * bail out unsuccessfully */
pbuf.c:617:      return 1;
pbuf.c:618:    }
pbuf.c:619:  } else {
pbuf.c:620:    /* Unknown type */
pbuf.c:621:    LWIP_ASSERT("bad pbuf type", 0);
pbuf.c:622:    return 1;
pbuf.c:623:  }
pbuf.c:624:  /* modify pbuf length fields */
pbuf.c:625:  p->len += header_size_increment;
pbuf.c:626:  p->tot_len += header_size_increment;
pbuf.c:627:
pbuf.c:628:  LWIP_DEBUGF(PBUF_DEBUG | LWIP_DBG_TRACE, ("pbuf_header: old %p new %p (%"S16_F")\n",
pbuf.c:629:    (void *)payload, (void *)p->payload, header_size_increment));
pbuf.c:630:
pbuf.c:631:  return 0;
pbuf.c:632:}
pbuf.c:633:
pbuf.c:634:/**
pbuf.c:635: * Adjusts the payload pointer to hide or reveal headers in the payload.
pbuf.c:636: *
pbuf.c:637: * Adjusts the ->payload pointer so that space for a header
pbuf.c:638: * (dis)appears in the pbuf payload.
pbuf.c:639: *
pbuf.c:640: * The ->payload, ->tot_len and ->len fields are adjusted.
pbuf.c:641: *
pbuf.c:642: * @param p pbuf to change the header size.
pbuf.c:643: * @param header_size_increment Number of bytes to increment header size which
pbuf.c:644: * increases the size of the pbuf. New space is on the front.
pbuf.c:645: * (Using a negative value decreases the header size.)
pbuf.c:646: * If hdr_size_inc is 0, this function does nothing and returns successful.
pbuf.c:647: *
pbuf.c:648: * PBUF_ROM and PBUF_REF type buffers cannot have their sizes increased, so
pbuf.c:649: * the call will fail. A check is made that the increase in header size does
pbuf.c:650: * not move the payload pointer in front of the start of the buffer.
pbuf.c:651: * @return non-zero on failure, zero on success.
pbuf.c:652: *
pbuf.c:653: */
pbuf.c:654:u8_t
pbuf.c:655:pbuf_header(struct pbuf *p, s16_t header_size_increment)
pbuf.c:656:{
pbuf.c:657:   return pbuf_header_impl(p, header_size_increment, 0);
pbuf.c:658:}
pbuf.c:659:
pbuf.c:660:/**
pbuf.c:661: * Same as pbuf_header but does not check if 'header_size > 0' is allowed.
pbuf.c:662: * This is used internally only, to allow PBUF_REF for RX.
pbuf.c:663: */
pbuf.c:664:u8_t
pbuf.c:665:pbuf_header_force(struct pbuf *p, s16_t header_size_increment)
pbuf.c:666:{
pbuf.c:667:   return pbuf_header_impl(p, header_size_increment, 1);
pbuf.c:668:}
pbuf.c:669:
pbuf.c:670:/**
pbuf.c:671: * @ingroup pbuf
pbuf.c:672: * Dereference a pbuf chain or queue and deallocate any no-longer-used
pbuf.c:673: * pbufs at the head of this chain or queue.
pbuf.c:674: *
pbuf.c:675: * Decrements the pbuf reference count. If it reaches zero, the pbuf is
pbuf.c:676: * deallocated.
pbuf.c:677: *
pbuf.c:678: * For a pbuf chain, this is repeated for each pbuf in the chain,
pbuf.c:679: * up to the first pbuf which has a non-zero reference count after
pbuf.c:680: * decrementing. So, when all reference counts are one, the whole
pbuf.c:681: * chain is free'd.
pbuf.c:682: *
pbuf.c:683: * @param p The pbuf (chain) to be dereferenced.
pbuf.c:684: *
pbuf.c:685: * @return the number of pbufs that were de-allocated
pbuf.c:686: * from the head of the chain.
pbuf.c:687: *
pbuf.c:688: * @note MUST NOT be called on a packet queue (Not verified to work yet).
pbuf.c:689: * @note the reference counter of a pbuf equals the number of pointers
pbuf.c:690: * that refer to the pbuf (or into the pbuf).
pbuf.c:691: *
pbuf.c:692: * @internal examples:
pbuf.c:693: *
pbuf.c:694: * Assuming existing chains a->b->c with the following reference
pbuf.c:695: * counts, calling pbuf_free(a) results in:
pbuf.c:696: *
pbuf.c:697: * 1->2->3 becomes ...1->3
pbuf.c:698: * 3->3->3 becomes 2->3->3
pbuf.c:699: * 1->1->2 becomes ......1
pbuf.c:700: * 2->1->1 becomes 1->1->1
pbuf.c:701: * 1->1->1 becomes .......
pbuf.c:702: *
pbuf.c:703: */
pbuf.c:704:u8_t
pbuf.c:705:pbuf_free(struct pbuf *p)
pbuf.c:706:{
pbuf.c:707:  u16_t type;
pbuf.c:708:  struct pbuf *q;
pbuf.c:709:  u8_t count;
pbuf.c:710:
pbuf.c:711:  if (p == NULL) {
pbuf.c:712:    LWIP_ASSERT("p != NULL", p != NULL);
pbuf.c:713:    /* if assertions are disabled, proceed with debug output */
pbuf.c:714:    LWIP_DEBUGF(PBUF_DEBUG | LWIP_DBG_LEVEL_SERIOUS,
pbuf.c:715:      ("pbuf_free(p == NULL) was called.\n"));
pbuf.c:716:    return 0;
pbuf.c:717:  }
pbuf.c:718:  LWIP_DEBUGF(PBUF_DEBUG | LWIP_DBG_TRACE, ("pbuf_free(%p)\n", (void *)p));
pbuf.c:719:
pbuf.c:720:  PERF_START;
pbuf.c:721:
pbuf.c:722:  LWIP_ASSERT("pbuf_free: sane type",
pbuf.c:723:    p->type == PBUF_RAM || p->type == PBUF_ROM ||
pbuf.c:724:    p->type == PBUF_REF || p->type == PBUF_POOL);
pbuf.c:725:
pbuf.c:726:  count = 0;
pbuf.c:727:  /* de-allocate all consecutive pbufs from the head of the chain that
pbuf.c:728:   * obtain a zero reference count after decrementing*/
pbuf.c:729:  while (p != NULL) {
pbuf.c:730:    u16_t ref;
pbuf.c:731:    SYS_ARCH_DECL_PROTECT(old_level);
pbuf.c:732:    /* Since decrementing ref cannot be guaranteed to be a single machine operation
pbuf.c:733:     * we must protect it. We put the new ref into a local variable to prevent
pbuf.c:734:     * further protection. */
pbuf.c:735:    SYS_ARCH_PROTECT(old_level);
pbuf.c:736:    /* all pbufs in a chain are referenced at least once */
pbuf.c:737:    LWIP_ASSERT("pbuf_free: p->ref > 0", p->ref > 0);
pbuf.c:738:    /* decrease reference count (number of pointers to pbuf) */
pbuf.c:739:    ref = --(p->ref);
pbuf.c:740:    SYS_ARCH_UNPROTECT(old_level);
pbuf.c:741:    /* this pbuf is no longer referenced to? */
pbuf.c:742:    if (ref == 0) {
pbuf.c:743:      /* remember next pbuf in chain for next iteration */
pbuf.c:744:      q = p->next;
pbuf.c:745:      LWIP_DEBUGF( PBUF_DEBUG | LWIP_DBG_TRACE, ("pbuf_free: deallocating %p\n", (void *)p));
pbuf.c:746:      type = p->type;
pbuf.c:747:#if LWIP_SUPPORT_CUSTOM_PBUF
pbuf.c:748:      /* is this a custom pbuf? */
pbuf.c:749:      if ((p->flags & PBUF_FLAG_IS_CUSTOM) != 0) {
pbuf.c:750:        struct pbuf_custom *pc = (struct pbuf_custom*)p;
pbuf.c:751:        LWIP_ASSERT("pc->custom_free_function != NULL", pc->custom_free_function != NULL);
pbuf.c:752:        pc->custom_free_function(p);
pbuf.c:753:      } else
pbuf.c:754:#endif /* LWIP_SUPPORT_CUSTOM_PBUF */
pbuf.c:755:      {
pbuf.c:756:        /* is this a pbuf from the pool? */
pbuf.c:757:        if (type == PBUF_POOL) {
pbuf.c:758:          memp_free(MEMP_PBUF_POOL, p);
pbuf.c:759:        /* is this a ROM or RAM referencing pbuf? */
pbuf.c:760:        } else if (type == PBUF_ROM || type == PBUF_REF) {
pbuf.c:761:          memp_free(MEMP_PBUF, p);
pbuf.c:762:        /* type == PBUF_RAM */
pbuf.c:763:        } else {
pbuf.c:764:          mem_free(p);
pbuf.c:765:        }
pbuf.c:766:      }
pbuf.c:767:      count++;
pbuf.c:768:      /* proceed to next pbuf */
pbuf.c:769:      p = q;
pbuf.c:770:    /* p->ref > 0, this pbuf is still referenced to */
pbuf.c:771:    /* (and so the remaining pbufs in chain as well) */
pbuf.c:772:    } else {
pbuf.c:773:      LWIP_DEBUGF( PBUF_DEBUG | LWIP_DBG_TRACE, ("pbuf_free: %p has ref %"U16_F", ending here.\n", (void *)p, ref));
pbuf.c:774:      /* stop walking through the chain */
pbuf.c:775:      p = NULL;
pbuf.c:776:    }
pbuf.c:777:  }
pbuf.c:778:  PERF_STOP("pbuf_free");
pbuf.c:779:  /* return number of de-allocated pbufs */
pbuf.c:780:  return count;
pbuf.c:781:}
pbuf.c:782:
pbuf.c:783:/**
pbuf.c:784: * Count number of pbufs in a chain
pbuf.c:785: *
pbuf.c:786: * @param p first pbuf of chain
pbuf.c:787: * @return the number of pbufs in a chain
pbuf.c:788: */
pbuf.c:789:u16_t
pbuf.c:790:pbuf_clen(const struct pbuf *p)
pbuf.c:791:{
pbuf.c:792:  u16_t len;
pbuf.c:793:
pbuf.c:794:  len = 0;
pbuf.c:795:  while (p != NULL) {
pbuf.c:796:    ++len;
pbuf.c:797:    p = p->next;
pbuf.c:798:  }
pbuf.c:799:  return len;
pbuf.c:800:}
pbuf.c:801:
pbuf.c:802:/**
pbuf.c:803: * @ingroup pbuf
pbuf.c:804: * Increment the reference count of the pbuf.
pbuf.c:805: *
pbuf.c:806: * @param p pbuf to increase reference counter of
pbuf.c:807: *
pbuf.c:808: */
pbuf.c:809:void
pbuf.c:810:pbuf_ref(struct pbuf *p)
pbuf.c:811:{
pbuf.c:812:  /* pbuf given? */
pbuf.c:813:  if (p != NULL) {
pbuf.c:814:    SYS_ARCH_INC(p->ref, 1);
pbuf.c:815:  }
pbuf.c:816:}
pbuf.c:817:
pbuf.c:818:/**
pbuf.c:819: * @ingroup pbuf
pbuf.c:820: * Concatenate two pbufs (each may be a pbuf chain) and take over
pbuf.c:821: * the caller's reference of the tail pbuf.
pbuf.c:822: *
pbuf.c:823: * @note The caller MAY NOT reference the tail pbuf afterwards.
pbuf.c:824: * Use pbuf_chain() for that purpose.
pbuf.c:825: *
pbuf.c:826: * @see pbuf_chain()
pbuf.c:827: */
pbuf.c:828:void
pbuf.c:829:pbuf_cat(struct pbuf *h, struct pbuf *t)
pbuf.c:830:{
pbuf.c:831:  struct pbuf *p;
pbuf.c:832:
pbuf.c:833:  LWIP_ERROR("(h != NULL) && (t != NULL) (programmer violates API)",
pbuf.c:834:             ((h != NULL) && (t != NULL)), return;);
pbuf.c:835:
pbuf.c:836:  /* proceed to last pbuf of chain */
pbuf.c:837:  for (p = h; p->next != NULL; p = p->next) {
pbuf.c:838:    /* add total length of second chain to all totals of first chain */
pbuf.c:839:    p->tot_len += t->tot_len;
pbuf.c:840:  }
pbuf.c:841:  /* { p is last pbuf of first h chain, p->next == NULL } */
pbuf.c:842:  LWIP_ASSERT("p->tot_len == p->len (of last pbuf in chain)", p->tot_len == p->len);
pbuf.c:843:  LWIP_ASSERT("p->next == NULL", p->next == NULL);
pbuf.c:844:  /* add total length of second chain to last pbuf total of first chain */
pbuf.c:845:  p->tot_len += t->tot_len;
pbuf.c:846:  /* chain last pbuf of head (p) with first of tail (t) */
pbuf.c:847:  p->next = t;
pbuf.c:848:  /* p->next now references t, but the caller will drop its reference to t,
pbuf.c:849:   * so netto there is no change to the reference count of t.
pbuf.c:850:   */
pbuf.c:851:}
pbuf.c:852:
pbuf.c:853:/**
pbuf.c:854: * @ingroup pbuf
pbuf.c:855: * Chain two pbufs (or pbuf chains) together.
pbuf.c:856: *
pbuf.c:857: * The caller MUST call pbuf_free(t) once it has stopped
pbuf.c:858: * using it. Use pbuf_cat() instead if you no longer use t.
pbuf.c:859: *
pbuf.c:860: * @param h head pbuf (chain)
pbuf.c:861: * @param t tail pbuf (chain)
pbuf.c:862: * @note The pbufs MUST belong to the same packet.
pbuf.c:863: * @note MAY NOT be called on a packet queue.
pbuf.c:864: *
pbuf.c:865: * The ->tot_len fields of all pbufs of the head chain are adjusted.
pbuf.c:866: * The ->next field of the last pbuf of the head chain is adjusted.
pbuf.c:867: * The ->ref field of the first pbuf of the tail chain is adjusted.
pbuf.c:868: *
pbuf.c:869: */
pbuf.c:870:void
pbuf.c:871:pbuf_chain(struct pbuf *h, struct pbuf *t)
pbuf.c:872:{
pbuf.c:873:  pbuf_cat(h, t);
pbuf.c:874:  /* t is now referenced by h */
pbuf.c:875:  pbuf_ref(t);
pbuf.c:876:  LWIP_DEBUGF(PBUF_DEBUG | LWIP_DBG_TRACE, ("pbuf_chain: %p references %p\n", (void *)h, (void *)t));
pbuf.c:877:}
pbuf.c:878:
pbuf.c:879:/**
pbuf.c:880: * Dechains the first pbuf from its succeeding pbufs in the chain.
pbuf.c:881: *
pbuf.c:882: * Makes p->tot_len field equal to p->len.
pbuf.c:883: * @param p pbuf to dechain
pbuf.c:884: * @return remainder of the pbuf chain, or NULL if it was de-allocated.
pbuf.c:885: * @note May not be called on a packet queue.
pbuf.c:886: */
pbuf.c:887:struct pbuf *
pbuf.c:888:pbuf_dechain(struct pbuf *p)
pbuf.c:889:{
pbuf.c:890:  struct pbuf *q;
pbuf.c:891:  u8_t tail_gone = 1;
pbuf.c:892:  /* tail */
pbuf.c:893:  q = p->next;
pbuf.c:894:  /* pbuf has successor in chain? */
pbuf.c:895:  if (q != NULL) {
pbuf.c:896:    /* assert tot_len invariant: (p->tot_len == p->len + (p->next? p->next->tot_len: 0) */
pbuf.c:897:    LWIP_ASSERT("p->tot_len == p->len + q->tot_len", q->tot_len == p->tot_len - p->len);
pbuf.c:898:    /* enforce invariant if assertion is disabled */
pbuf.c:899:    q->tot_len = p->tot_len - p->len;
pbuf.c:900:    /* decouple pbuf from remainder */
pbuf.c:901:    p->next = NULL;
pbuf.c:902:    /* total length of pbuf p is its own length only */
pbuf.c:903:    p->tot_len = p->len;
pbuf.c:904:    /* q is no longer referenced by p, free it */
pbuf.c:905:    LWIP_DEBUGF(PBUF_DEBUG | LWIP_DBG_TRACE, ("pbuf_dechain: unreferencing %p\n", (void *)q));
pbuf.c:906:    tail_gone = pbuf_free(q);
pbuf.c:907:    if (tail_gone > 0) {
pbuf.c:908:      LWIP_DEBUGF(PBUF_DEBUG | LWIP_DBG_TRACE,
pbuf.c:909:                  ("pbuf_dechain: deallocated %p (as it is no longer referenced)\n", (void *)q));
pbuf.c:910:    }
pbuf.c:911:    /* return remaining tail or NULL if deallocated */
pbuf.c:912:  }
pbuf.c:913:  /* assert tot_len invariant: (p->tot_len == p->len + (p->next? p->next->tot_len: 0) */
pbuf.c:914:  LWIP_ASSERT("p->tot_len == p->len", p->tot_len == p->len);
pbuf.c:915:  return ((tail_gone > 0) ? NULL : q);
pbuf.c:916:}
pbuf.c:917:
pbuf.c:918:/**
pbuf.c:919: * @ingroup pbuf
pbuf.c:920: * Create PBUF_RAM copies of pbufs.
pbuf.c:921: *
pbuf.c:922: * Used to queue packets on behalf of the lwIP stack, such as
pbuf.c:923: * ARP based queueing.
pbuf.c:924: *
pbuf.c:925: * @note You MUST explicitly use p = pbuf_take(p);
pbuf.c:926: *
pbuf.c:927: * @note Only one packet is copied, no packet queue!
pbuf.c:928: *
pbuf.c:929: * @param p_to pbuf destination of the copy
pbuf.c:930: * @param p_from pbuf source of the copy
pbuf.c:931: *
pbuf.c:932: * @return ERR_OK if pbuf was copied
pbuf.c:933: *         ERR_ARG if one of the pbufs is NULL or p_to is not big
pbuf.c:934: *                 enough to hold p_from
pbuf.c:935: */
pbuf.c:936:err_t
pbuf.c:937:pbuf_copy(struct pbuf *p_to, const struct pbuf *p_from)
pbuf.c:938:{
pbuf.c:939:  u16_t offset_to=0, offset_from=0, len;
pbuf.c:940:
pbuf.c:941:  LWIP_DEBUGF(PBUF_DEBUG | LWIP_DBG_TRACE, ("pbuf_copy(%p, %p)\n",
pbuf.c:942:    (const void*)p_to, (const void*)p_from));
pbuf.c:943:
pbuf.c:944:  /* is the target big enough to hold the source? */
pbuf.c:945:  LWIP_ERROR("pbuf_copy: target not big enough to hold source", ((p_to != NULL) &&
pbuf.c:946:             (p_from != NULL) && (p_to->tot_len >= p_from->tot_len)), return ERR_ARG;);
pbuf.c:947:
pbuf.c:948:  /* iterate through pbuf chain */
pbuf.c:949:  do
pbuf.c:950:  {
pbuf.c:951:    /* copy one part of the original chain */
pbuf.c:952:    if ((p_to->len - offset_to) >= (p_from->len - offset_from)) {
pbuf.c:953:      /* complete current p_from fits into current p_to */
pbuf.c:954:      len = p_from->len - offset_from;
pbuf.c:955:    } else {
pbuf.c:956:      /* current p_from does not fit into current p_to */
pbuf.c:957:      len = p_to->len - offset_to;
pbuf.c:958:    }
pbuf.c:959:    MEMCPY((u8_t*)p_to->payload + offset_to, (u8_t*)p_from->payload + offset_from, len);
pbuf.c:960:    offset_to += len;
pbuf.c:961:    offset_from += len;
pbuf.c:962:    LWIP_ASSERT("offset_to <= p_to->len", offset_to <= p_to->len);
pbuf.c:963:    LWIP_ASSERT("offset_from <= p_from->len", offset_from <= p_from->len);
pbuf.c:964:    if (offset_from >= p_from->len) {
pbuf.c:965:      /* on to next p_from (if any) */
pbuf.c:966:      offset_from = 0;
pbuf.c:967:      p_from = p_from->next;
pbuf.c:968:    }
pbuf.c:969:    if (offset_to == p_to->len) {
pbuf.c:970:      /* on to next p_to (if any) */
pbuf.c:971:      offset_to = 0;
pbuf.c:972:      p_to = p_to->next;
pbuf.c:973:      LWIP_ERROR("p_to != NULL", (p_to != NULL) || (p_from == NULL) , return ERR_ARG;);
pbuf.c:974:    }
pbuf.c:975:
pbuf.c:976:    if ((p_from != NULL) && (p_from->len == p_from->tot_len)) {
pbuf.c:977:      /* don't copy more than one packet! */
pbuf.c:978:      LWIP_ERROR("pbuf_copy() does not allow packet queues!",
pbuf.c:979:                 (p_from->next == NULL), return ERR_VAL;);
pbuf.c:980:    }
pbuf.c:981:    if ((p_to != NULL) && (p_to->len == p_to->tot_len)) {
pbuf.c:982:      /* don't copy more than one packet! */
pbuf.c:983:      LWIP_ERROR("pbuf_copy() does not allow packet queues!",
pbuf.c:984:                  (p_to->next == NULL), return ERR_VAL;);
pbuf.c:985:    }
pbuf.c:986:  } while (p_from);
pbuf.c:987:  LWIP_DEBUGF(PBUF_DEBUG | LWIP_DBG_TRACE, ("pbuf_copy: end of chain reached.\n"));
pbuf.c:988:  return ERR_OK;
pbuf.c:989:}
pbuf.c:990:
pbuf.c:991:/**
pbuf.c:992: * @ingroup pbuf
pbuf.c:993: * Copy (part of) the contents of a packet buffer
pbuf.c:994: * to an application supplied buffer.
pbuf.c:995: *
pbuf.c:996: * @param buf the pbuf from which to copy data
pbuf.c:997: * @param dataptr the application supplied buffer
pbuf.c:998: * @param len length of data to copy (dataptr must be big enough). No more
pbuf.c:999: * than buf->tot_len will be copied, irrespective of len
pbuf.c:1000: * @param offset offset into the packet buffer from where to begin copying len bytes
pbuf.c:1001: * @return the number of bytes copied, or 0 on failure
pbuf.c:1002: */
pbuf.c:1003:u16_t
pbuf.c:1004:pbuf_copy_partial(const struct pbuf *buf, void *dataptr, u16_t len, u16_t offset)
pbuf.c:1005:{
pbuf.c:1006:  const struct pbuf *p;
pbuf.c:1007:  u16_t left;
pbuf.c:1008:  u16_t buf_copy_len;
pbuf.c:1009:  u16_t copied_total = 0;
pbuf.c:1010:
pbuf.c:1011:  LWIP_ERROR("pbuf_copy_partial: invalid buf", (buf != NULL), return 0;);
pbuf.c:1012:  LWIP_ERROR("pbuf_copy_partial: invalid dataptr", (dataptr != NULL), return 0;);
pbuf.c:1013:
pbuf.c:1014:  left = 0;
pbuf.c:1015:
pbuf.c:1016:  if ((buf == NULL) || (dataptr == NULL)) {
pbuf.c:1017:    return 0;
pbuf.c:1018:  }
pbuf.c:1019:
pbuf.c:1020:  /* Note some systems use byte copy if dataptr or one of the pbuf payload pointers are unaligned. */
pbuf.c:1021:  for (p = buf; len != 0 && p != NULL; p = p->next) {
pbuf.c:1022:    if ((offset != 0) && (offset >= p->len)) {
pbuf.c:1023:      /* don't copy from this buffer -> on to the next */
pbuf.c:1024:      offset -= p->len;
pbuf.c:1025:    } else {
pbuf.c:1026:      /* copy from this buffer. maybe only partially. */
pbuf.c:1027:      buf_copy_len = p->len - offset;
pbuf.c:1028:      if (buf_copy_len > len) {
pbuf.c:1029:        buf_copy_len = len;
pbuf.c:1030:      }
pbuf.c:1031:      /* copy the necessary parts of the buffer */
pbuf.c:1032:      MEMCPY(&((char*)dataptr)[left], &((char*)p->payload)[offset], buf_copy_len);
pbuf.c:1033:      copied_total += buf_copy_len;
pbuf.c:1034:      left += buf_copy_len;
pbuf.c:1035:      len -= buf_copy_len;
pbuf.c:1036:      offset = 0;
pbuf.c:1037:    }
pbuf.c:1038:  }
pbuf.c:1039:  return copied_total;
pbuf.c:1040:}
pbuf.c:1041:
pbuf.c:1042:#if LWIP_TCP && TCP_QUEUE_OOSEQ && LWIP_WND_SCALE
pbuf.c:1043:/**
pbuf.c:1044: * This method modifies a 'pbuf chain', so that its total length is
pbuf.c:1045: * smaller than 64K. The remainder of the original pbuf chain is stored
pbuf.c:1046: * in *rest.
pbuf.c:1047: * This function never creates new pbufs, but splits an existing chain
pbuf.c:1048: * in two parts. The tot_len of the modified packet queue will likely be
pbuf.c:1049: * smaller than 64K.
pbuf.c:1050: * 'packet queues' are not supported by this function.
pbuf.c:1051: *
pbuf.c:1052: * @param p the pbuf queue to be split
pbuf.c:1053: * @param rest pointer to store the remainder (after the first 64K)
pbuf.c:1054: */
pbuf.c:1055:void pbuf_split_64k(struct pbuf *p, struct pbuf **rest)
pbuf.c:1056:{
pbuf.c:1057:  *rest = NULL;
pbuf.c:1058:  if ((p != NULL) && (p->next != NULL)) {
pbuf.c:1059:    u16_t tot_len_front = p->len;
pbuf.c:1060:    struct pbuf *i = p;
pbuf.c:1061:    struct pbuf *r = p->next;
pbuf.c:1062:
pbuf.c:1063:    /* continue until the total length (summed up as u16_t) overflows */
pbuf.c:1064:    while ((r != NULL) && ((u16_t)(tot_len_front + r->len) > tot_len_front)) {
pbuf.c:1065:      tot_len_front += r->len;
pbuf.c:1066:      i = r;
pbuf.c:1067:      r = r->next;
pbuf.c:1068:    }
pbuf.c:1069:    /* i now points to last packet of the first segment. Set next
pbuf.c:1070:       pointer to NULL */
pbuf.c:1071:    i->next = NULL;
pbuf.c:1072:
pbuf.c:1073:    if (r != NULL) {
pbuf.c:1074:      /* Update the tot_len field in the first part */
pbuf.c:1075:      for (i = p; i != NULL; i = i->next) {
pbuf.c:1076:        i->tot_len -= r->tot_len;
pbuf.c:1077:        LWIP_ASSERT("tot_len/len mismatch in last pbuf",
pbuf.c:1078:                    (i->next != NULL) || (i->tot_len == i->len));
pbuf.c:1079:      }
pbuf.c:1080:      if (p->flags & PBUF_FLAG_TCP_FIN) {
pbuf.c:1081:        r->flags |= PBUF_FLAG_TCP_FIN;
pbuf.c:1082:      }
pbuf.c:1083:
pbuf.c:1084:      /* tot_len field in rest does not need modifications */
pbuf.c:1085:      /* reference counters do not need modifications */
pbuf.c:1086:      *rest = r;
pbuf.c:1087:    }
pbuf.c:1088:  }
pbuf.c:1089:}
pbuf.c:1090:#endif /* LWIP_TCP && TCP_QUEUE_OOSEQ && LWIP_WND_SCALE */
tcp_in.c:46:#if LWIP_TCP /* don't build if not configured for use in lwipopts.h */
tcp_in.c:47:
tcp_in.c:48:#include "lwip/priv/tcp_priv.h"
tcp_in.c:49:#include "lwip/def.h"
tcp_in.c:50:#include "lwip/ip_addr.h"
tcp_in.c:51:#include "lwip/netif.h"
tcp_in.c:52:#include "lwip/mem.h"
tcp_in.c:53:#include "lwip/memp.h"
tcp_in.c:54:#include "lwip/inet_chksum.h"
tcp_in.c:55:#include "lwip/stats.h"
tcp_in.c:56:#include "lwip/ip6.h"
tcp_in.c:57:#include "lwip/ip6_addr.h"
tcp_in.c:58:#if LWIP_ND6_TCP_REACHABILITY_HINTS
tcp_in.c:59:#include "lwip/nd6.h"
tcp_in.c:60:#endif /* LWIP_ND6_TCP_REACHABILITY_HINTS */
tcp_in.c:61:
tcp_in.c:62:/** Initial CWND calculation as defined RFC 2581 */
tcp_in.c:63:#define LWIP_TCP_CALC_INITIAL_CWND(mss) LWIP_MIN((4U * (mss)), LWIP_MAX((2U * (mss)), 4380U));
tcp_in.c:64:/** Initial slow start threshold value: we use the full window */
tcp_in.c:65:#define LWIP_TCP_INITIAL_SSTHRESH(pcb)  ((pcb)->snd_wnd)
tcp_in.c:66:
tcp_in.c:67:/* These variables are global to all functions involved in the input
tcp_in.c:68:   processing of TCP segments. They are set by the tcp_input()
tcp_in.c:69:   function. */
tcp_in.c:70:static struct tcp_seg inseg;
tcp_in.c:71:static struct tcp_hdr *tcphdr;
tcp_in.c:72:static u16_t tcphdr_optlen;
tcp_in.c:73:static u16_t tcphdr_opt1len;
tcp_in.c:74:static u8_t* tcphdr_opt2;
tcp_in.c:75:static u16_t tcp_optidx;
tcp_in.c:76:static u32_t seqno, ackno;
tcp_in.c:77:static tcpwnd_size_t recv_acked;
tcp_in.c:78:static u16_t tcplen;
tcp_in.c:79:static u8_t flags;
tcp_in.c:80:
tcp_in.c:81:static u8_t recv_flags;
tcp_in.c:82:static struct pbuf *recv_data;
tcp_in.c:83:
tcp_in.c:84:struct tcp_pcb *tcp_input_pcb;
tcp_in.c:85:
tcp_in.c:86:/* Forward declarations. */
tcp_in.c:87:static err_t tcp_process(struct tcp_pcb *pcb);
tcp_in.c:88:static void tcp_receive(struct tcp_pcb *pcb);
tcp_in.c:89:static void tcp_parseopt(struct tcp_pcb *pcb);
tcp_in.c:90:
tcp_in.c:91:static void tcp_listen_input(struct tcp_pcb_listen *pcb);
tcp_in.c:92:static void tcp_timewait_input(struct tcp_pcb *pcb);
tcp_in.c:93:
tcp_in.c:94:/**
tcp_in.c:95: * The initial input processing of TCP. It verifies the TCP header, demultiplexes
tcp_in.c:96: * the segment between the PCBs and passes it on to tcp_process(), which implements
tcp_in.c:97: * the TCP finite state machine. This function is called by the IP layer (in
tcp_in.c:98: * ip_input()).
tcp_in.c:99: *
tcp_in.c:100: * @param p received TCP segment to process (p->payload pointing to the TCP header)
tcp_in.c:101: * @param inp network interface on which this segment was received
tcp_in.c:102: */
tcp_in.c:103:void
tcp_in.c:104:tcp_input(struct pbuf *p, struct netif *inp)
tcp_in.c:105:{
tcp_in.c:106:  struct tcp_pcb *pcb, *prev;
tcp_in.c:107:  struct tcp_pcb_listen *lpcb;
tcp_in.c:108:#if SO_REUSE
tcp_in.c:109:  struct tcp_pcb *lpcb_prev = NULL;
tcp_in.c:110:  struct tcp_pcb_listen *lpcb_any = NULL;
tcp_in.c:111:#endif /* SO_REUSE */
tcp_in.c:112:  u8_t hdrlen_bytes;
tcp_in.c:113:  err_t err;
tcp_in.c:114:
tcp_in.c:115:  LWIP_UNUSED_ARG(inp);
tcp_in.c:116:
tcp_in.c:117:  PERF_START;
tcp_in.c:118:
tcp_in.c:119:  TCP_STATS_INC(tcp.recv);
tcp_in.c:120:  MIB2_STATS_INC(mib2.tcpinsegs);
tcp_in.c:121:
tcp_in.c:122:  tcphdr = (struct tcp_hdr *)p->payload;
tcp_in.c:123:
tcp_in.c:124:#if TCP_INPUT_DEBUG
tcp_in.c:125:  tcp_debug_print(tcphdr);
tcp_in.c:126:#endif
tcp_in.c:127:
tcp_in.c:128:  /* Check that TCP header fits in payload */
tcp_in.c:129:  if (p->len < TCP_HLEN) {
tcp_in.c:130:    /* drop short packets */
tcp_in.c:131:    LWIP_DEBUGF(TCP_INPUT_DEBUG, ("tcp_input: short packet (%"U16_F" bytes) discarded\n", p->tot_len));
tcp_in.c:132:    TCP_STATS_INC(tcp.lenerr);
tcp_in.c:133:    goto dropped;
tcp_in.c:134:  }
tcp_in.c:135:
tcp_in.c:136:  /* Don't even process incoming broadcasts/multicasts. */
tcp_in.c:137:  if (ip_addr_isbroadcast(ip_current_dest_addr(), ip_current_netif()) ||
tcp_in.c:138:      ip_addr_ismulticast(ip_current_dest_addr())) {
tcp_in.c:139:    TCP_STATS_INC(tcp.proterr);
tcp_in.c:140:    goto dropped;
tcp_in.c:141:  }
tcp_in.c:142:
tcp_in.c:143:#if CHECKSUM_CHECK_TCP
tcp_in.c:144:  IF__NETIF_CHECKSUM_ENABLED(inp, NETIF_CHECKSUM_CHECK_TCP) {
tcp_in.c:145:    /* Verify TCP checksum. */
tcp_in.c:146:    u16_t chksum = ip_chksum_pseudo(p, IP_PROTO_TCP, p->tot_len,
tcp_in.c:147:                               ip_current_src_addr(), ip_current_dest_addr());
tcp_in.c:148:    if (chksum != 0) {
tcp_in.c:149:        LWIP_DEBUGF(TCP_INPUT_DEBUG, ("tcp_input: packet discarded due to failing checksum 0x%04"X16_F"\n",
tcp_in.c:150:          chksum));
tcp_in.c:151:      tcp_debug_print(tcphdr);
tcp_in.c:152:      TCP_STATS_INC(tcp.chkerr);
tcp_in.c:153:      goto dropped;
tcp_in.c:154:    }
tcp_in.c:155:  }
tcp_in.c:156:#endif /* CHECKSUM_CHECK_TCP */
tcp_in.c:157:
tcp_in.c:158:  /* sanity-check header length */
tcp_in.c:159:  hdrlen_bytes = TCPH_HDRLEN(tcphdr) * 4;
tcp_in.c:160:  if ((hdrlen_bytes < TCP_HLEN) || (hdrlen_bytes > p->tot_len)) {
tcp_in.c:161:    LWIP_DEBUGF(TCP_INPUT_DEBUG, ("tcp_input: invalid header length (%"U16_F")\n", (u16_t)hdrlen_bytes));
tcp_in.c:162:    TCP_STATS_INC(tcp.lenerr);
tcp_in.c:163:    goto dropped;
tcp_in.c:164:  }
tcp_in.c:165:
tcp_in.c:166:  /* Move the payload pointer in the pbuf so that it points to the
tcp_in.c:167:     TCP data instead of the TCP header. */
tcp_in.c:168:  tcphdr_optlen = hdrlen_bytes - TCP_HLEN;
tcp_in.c:169:  tcphdr_opt2 = NULL;
tcp_in.c:170:  if (p->len >= hdrlen_bytes) {
tcp_in.c:171:    /* all options are in the first pbuf */
tcp_in.c:172:    tcphdr_opt1len = tcphdr_optlen;
tcp_in.c:173:    pbuf_header(p, -(s16_t)hdrlen_bytes); /* cannot fail */
tcp_in.c:174:  } else {
tcp_in.c:175:    u16_t opt2len;
tcp_in.c:176:    /* TCP header fits into first pbuf, options don't - data is in the next pbuf */
tcp_in.c:177:    /* there must be a next pbuf, due to hdrlen_bytes sanity check above */
tcp_in.c:178:    LWIP_ASSERT("p->next != NULL", p->next != NULL);
tcp_in.c:179:
tcp_in.c:180:    /* advance over the TCP header (cannot fail) */
tcp_in.c:181:    pbuf_header(p, -TCP_HLEN);
tcp_in.c:182:
tcp_in.c:183:    /* determine how long the first and second parts of the options are */
tcp_in.c:184:    tcphdr_opt1len = p->len;
tcp_in.c:185:    opt2len = tcphdr_optlen - tcphdr_opt1len;
tcp_in.c:186:
tcp_in.c:187:    /* options continue in the next pbuf: set p to zero length and hide the
tcp_in.c:188:        options in the next pbuf (adjusting p->tot_len) */
tcp_in.c:189:    pbuf_header(p, -(s16_t)tcphdr_opt1len);
tcp_in.c:190:
tcp_in.c:191:    /* check that the options fit in the second pbuf */
tcp_in.c:192:    if (opt2len > p->next->len) {
tcp_in.c:193:      /* drop short packets */
tcp_in.c:194:      LWIP_DEBUGF(TCP_INPUT_DEBUG, ("tcp_input: options overflow second pbuf (%"U16_F" bytes)\n", p->next->len));
tcp_in.c:195:      TCP_STATS_INC(tcp.lenerr);
tcp_in.c:196:      goto dropped;
tcp_in.c:197:    }
tcp_in.c:198:
tcp_in.c:199:    /* remember the pointer to the second part of the options */
tcp_in.c:200:    tcphdr_opt2 = (u8_t*)p->next->payload;
tcp_in.c:201:
tcp_in.c:202:    /* advance p->next to point after the options, and manually
tcp_in.c:203:        adjust p->tot_len to keep it consistent with the changed p->next */
tcp_in.c:204:    pbuf_header(p->next, -(s16_t)opt2len);
tcp_in.c:205:    p->tot_len -= opt2len;
tcp_in.c:206:
tcp_in.c:207:    LWIP_ASSERT("p->len == 0", p->len == 0);
tcp_in.c:208:    LWIP_ASSERT("p->tot_len == p->next->tot_len", p->tot_len == p->next->tot_len);
tcp_in.c:209:  }
tcp_in.c:210:
tcp_in.c:211:  /* Convert fields in TCP header to host byte order. */
tcp_in.c:212:  tcphdr->src = lwip_ntohs(tcphdr->src);
tcp_in.c:213:  tcphdr->dest = lwip_ntohs(tcphdr->dest);
tcp_in.c:214:  seqno = tcphdr->seqno = lwip_ntohl(tcphdr->seqno);
tcp_in.c:215:  ackno = tcphdr->ackno = lwip_ntohl(tcphdr->ackno);
tcp_in.c:216:  tcphdr->wnd = lwip_ntohs(tcphdr->wnd);
tcp_in.c:217:
tcp_in.c:218:  flags = TCPH_FLAGS(tcphdr);
tcp_in.c:219:  tcplen = p->tot_len + ((flags & (TCP_FIN | TCP_SYN)) ? 1 : 0);
tcp_in.c:220:
tcp_in.c:221:  /* Demultiplex an incoming segment. First, we check if it is destined
tcp_in.c:222:     for an active connection. */
tcp_in.c:223:  prev = NULL;
tcp_in.c:224:
tcp_in.c:225:  for (pcb = tcp_active_pcbs; pcb != NULL; pcb = pcb->next) {
tcp_in.c:226:    LWIP_ASSERT("tcp_input: active pcb->state != CLOSED", pcb->state != CLOSED);
tcp_in.c:227:    LWIP_ASSERT("tcp_input: active pcb->state != TIME-WAIT", pcb->state != TIME_WAIT);
tcp_in.c:228:    LWIP_ASSERT("tcp_input: active pcb->state != LISTEN", pcb->state != LISTEN);
tcp_in.c:229:    if (pcb->remote_port == tcphdr->src &&
tcp_in.c:230:        pcb->local_port == tcphdr->dest &&
tcp_in.c:231:        ip_addr_cmp(&pcb->remote_ip, ip_current_src_addr()) &&
tcp_in.c:232:        ip_addr_cmp(&pcb->local_ip, ip_current_dest_addr())) {
tcp_in.c:233:      /* Move this PCB to the front of the list so that subsequent
tcp_in.c:234:         lookups will be faster (we exploit locality in TCP segment
tcp_in.c:235:         arrivals). */
tcp_in.c:236:      LWIP_ASSERT("tcp_input: pcb->next != pcb (before cache)", pcb->next != pcb);
tcp_in.c:237:      if (prev != NULL) {
tcp_in.c:238:        prev->next = pcb->next;
tcp_in.c:239:        pcb->next = tcp_active_pcbs;
tcp_in.c:240:        tcp_active_pcbs = pcb;
tcp_in.c:241:      } else {
tcp_in.c:242:        TCP_STATS_INC(tcp.cachehit);
tcp_in.c:243:      }
tcp_in.c:244:      LWIP_ASSERT("tcp_input: pcb->next != pcb (after cache)", pcb->next != pcb);
tcp_in.c:245:      break;
tcp_in.c:246:    }
tcp_in.c:247:    prev = pcb;
tcp_in.c:248:  }
tcp_in.c:249:
tcp_in.c:250:  if (pcb == NULL) {
tcp_in.c:251:    /* If it did not go to an active connection, we check the connections
tcp_in.c:252:       in the TIME-WAIT state. */
tcp_in.c:253:    for (pcb = tcp_tw_pcbs; pcb != NULL; pcb = pcb->next) {
tcp_in.c:254:      LWIP_ASSERT("tcp_input: TIME-WAIT pcb->state == TIME-WAIT", pcb->state == TIME_WAIT);
tcp_in.c:255:      if (pcb->remote_port == tcphdr->src &&
tcp_in.c:256:          pcb->local_port == tcphdr->dest &&
tcp_in.c:257:          ip_addr_cmp(&pcb->remote_ip, ip_current_src_addr()) &&
tcp_in.c:258:          ip_addr_cmp(&pcb->local_ip, ip_current_dest_addr())) {
tcp_in.c:259:        /* We don't really care enough to move this PCB to the front
tcp_in.c:260:           of the list since we are not very likely to receive that
tcp_in.c:261:           many segments for connections in TIME-WAIT. */
tcp_in.c:262:        LWIP_DEBUGF(TCP_INPUT_DEBUG, ("tcp_input: packed for TIME_WAITing connection.\n"));
tcp_in.c:263:        tcp_timewait_input(pcb);
tcp_in.c:264:        pbuf_free(p);
tcp_in.c:265:        return;
tcp_in.c:266:      }
tcp_in.c:267:    }
tcp_in.c:268:
tcp_in.c:269:    /* Finally, if we still did not get a match, we check all PCBs that
tcp_in.c:270:       are LISTENing for incoming connections. */
tcp_in.c:271:    prev = NULL;
tcp_in.c:272:    for (lpcb = tcp_listen_pcbs.listen_pcbs; lpcb != NULL; lpcb = lpcb->next) {
tcp_in.c:273:      if (lpcb->local_port == tcphdr->dest) {
tcp_in.c:274:        if (IP_IS_ANY_TYPE_VAL(lpcb->local_ip)) {
tcp_in.c:275:          /* found an ANY TYPE (IPv4/IPv6) match */
tcp_in.c:276:#if SO_REUSE
tcp_in.c:277:          lpcb_any = lpcb;
tcp_in.c:278:          lpcb_prev = prev;
tcp_in.c:279:#else /* SO_REUSE */
tcp_in.c:280:          break;
tcp_in.c:281:#endif /* SO_REUSE */
tcp_in.c:282:        } else if (IP_ADDR_PCB_VERSION_MATCH_EXACT(lpcb, ip_current_dest_addr())) {
tcp_in.c:283:          if (ip_addr_cmp(&lpcb->local_ip, ip_current_dest_addr())) {
tcp_in.c:284:            /* found an exact match */
tcp_in.c:285:            break;
tcp_in.c:286:          } else if (ip_addr_isany(&lpcb->local_ip)) {
tcp_in.c:287:            /* found an ANY-match */
tcp_in.c:288:#if SO_REUSE
tcp_in.c:289:            lpcb_any = lpcb;
tcp_in.c:290:            lpcb_prev = prev;
tcp_in.c:291:#else /* SO_REUSE */
tcp_in.c:292:            break;
tcp_in.c:293: #endif /* SO_REUSE */
tcp_in.c:294:          }
tcp_in.c:295:        }
tcp_in.c:296:      }
tcp_in.c:297:      prev = (struct tcp_pcb *)lpcb;
tcp_in.c:298:    }
tcp_in.c:299:#if SO_REUSE
tcp_in.c:300:    /* first try specific local IP */
tcp_in.c:301:    if (lpcb == NULL) {
tcp_in.c:302:      /* only pass to ANY if no specific local IP has been found */
tcp_in.c:303:      lpcb = lpcb_any;
tcp_in.c:304:      prev = lpcb_prev;
tcp_in.c:305:    }
tcp_in.c:306:#endif /* SO_REUSE */
tcp_in.c:307:    if (lpcb != NULL) {
tcp_in.c:308:      /* Move this PCB to the front of the list so that subsequent
tcp_in.c:309:         lookups will be faster (we exploit locality in TCP segment
tcp_in.c:310:         arrivals). */
tcp_in.c:311:      if (prev != NULL) {
tcp_in.c:312:        ((struct tcp_pcb_listen *)prev)->next = lpcb->next;
tcp_in.c:313:              /* our successor is the remainder of the listening list */
tcp_in.c:314:        lpcb->next = tcp_listen_pcbs.listen_pcbs;
tcp_in.c:315:              /* put this listening pcb at the head of the listening list */
tcp_in.c:316:        tcp_listen_pcbs.listen_pcbs = lpcb;
tcp_in.c:317:      } else {
tcp_in.c:318:        TCP_STATS_INC(tcp.cachehit);
tcp_in.c:319:      }
tcp_in.c:320:
tcp_in.c:321:      LWIP_DEBUGF(TCP_INPUT_DEBUG, ("tcp_input: packed for LISTENing connection.\n"));
tcp_in.c:322:      tcp_listen_input(lpcb);
tcp_in.c:323:      pbuf_free(p);
tcp_in.c:324:      return;
tcp_in.c:325:    }
tcp_in.c:326:  }
tcp_in.c:327:
tcp_in.c:328:#if TCP_INPUT_DEBUG
tcp_in.c:329:  LWIP_DEBUGF(TCP_INPUT_DEBUG, ("+-+-+-+-+-+-+-+-+-+-+-+-+-+- tcp_input: flags "));
tcp_in.c:330:  tcp_debug_print_flags(TCPH_FLAGS(tcphdr));
tcp_in.c:331:  LWIP_DEBUGF(TCP_INPUT_DEBUG, ("-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n"));
tcp_in.c:332:#endif /* TCP_INPUT_DEBUG */
tcp_in.c:333:
tcp_in.c:334:
tcp_in.c:335:  if (pcb != NULL) {
tcp_in.c:336:    /* The incoming segment belongs to a connection. */
tcp_in.c:337:#if TCP_INPUT_DEBUG
tcp_in.c:338:    tcp_debug_print_state(pcb->state);
tcp_in.c:339:#endif /* TCP_INPUT_DEBUG */
tcp_in.c:340:
tcp_in.c:341:    /* Set up a tcp_seg structure. */
tcp_in.c:342:    inseg.next = NULL;
tcp_in.c:343:    inseg.len = p->tot_len;
tcp_in.c:344:    inseg.p = p;
tcp_in.c:345:    inseg.tcphdr = tcphdr;
tcp_in.c:346:
tcp_in.c:347:    recv_data = NULL;
tcp_in.c:348:    recv_flags = 0;
tcp_in.c:349:    recv_acked = 0;
tcp_in.c:350:
tcp_in.c:351:    if (flags & TCP_PSH) {
tcp_in.c:352:      p->flags |= PBUF_FLAG_PUSH;
tcp_in.c:353:    }
tcp_in.c:354:
tcp_in.c:355:    /* If there is data which was previously "refused" by upper layer */
tcp_in.c:356:    if (pcb->refused_data != NULL) {
tcp_in.c:357:      if ((tcp_process_refused_data(pcb) == ERR_ABRT) ||
tcp_in.c:358:        ((pcb->refused_data != NULL) && (tcplen > 0))) {
tcp_in.c:359:        /* pcb has been aborted or refused data is still refused and the new
tcp_in.c:360:           segment contains data */
tcp_in.c:361:        TCP_STATS_INC(tcp.drop);
tcp_in.c:362:        MIB2_STATS_INC(mib2.tcpinerrs);
tcp_in.c:363:        goto aborted;
tcp_in.c:364:      }
tcp_in.c:365:    }
tcp_in.c:366:    tcp_input_pcb = pcb;
tcp_in.c:367:    err = tcp_process(pcb);
tcp_in.c:368:    /* A return value of ERR_ABRT means that tcp_abort() was called
tcp_in.c:369:       and that the pcb has been freed. If so, we don't do anything. */
tcp_in.c:370:    if (err != ERR_ABRT) {
tcp_in.c:371:      if (recv_flags & TF_RESET) {
tcp_in.c:372:        /* TF_RESET means that the connection was reset by the other
tcp_in.c:373:           end. We then call the error callback to inform the
tcp_in.c:374:           application that the connection is dead before we
tcp_in.c:375:           deallocate the PCB. */
tcp_in.c:376:        TCP_EVENT_ERR(pcb->errf, pcb->callback_arg, ERR_RST);
tcp_in.c:377:        tcp_pcb_remove(&tcp_active_pcbs, pcb);
tcp_in.c:378:        memp_free(MEMP_TCP_PCB, pcb);
tcp_in.c:379:      } else {
tcp_in.c:380:        err = ERR_OK;
tcp_in.c:381:        /* If the application has registered a "sent" function to be
tcp_in.c:382:           called when new send buffer space is available, we call it
tcp_in.c:383:           now. */
tcp_in.c:384:        if (recv_acked > 0) {
tcp_in.c:385:          u16_t acked16;
tcp_in.c:386:#if LWIP_WND_SCALE
tcp_in.c:387:          /* recv_acked is u32_t but the sent callback only takes a u16_t,
tcp_in.c:388:             so we might have to call it multiple times. */
tcp_in.c:389:          u32_t acked = recv_acked;
tcp_in.c:390:          while (acked > 0) {
tcp_in.c:391:            acked16 = (u16_t)LWIP_MIN(acked, 0xffffu);
tcp_in.c:392:            acked -= acked16;
tcp_in.c:393:#else
tcp_in.c:394:          {
tcp_in.c:395:            acked16 = recv_acked;
tcp_in.c:396:#endif
tcp_in.c:397:            TCP_EVENT_SENT(pcb, (u16_t)acked16, err);
tcp_in.c:398:            if (err == ERR_ABRT) {
tcp_in.c:399:              goto aborted;
tcp_in.c:400:            }
tcp_in.c:401:          }
tcp_in.c:402:          recv_acked = 0;
tcp_in.c:403:        }
tcp_in.c:404:        if (recv_flags & TF_CLOSED) {
tcp_in.c:405:          /* The connection has been closed and we will deallocate the
tcp_in.c:406:             PCB. */
tcp_in.c:407:          if (!(pcb->flags & TF_RXCLOSED)) {
tcp_in.c:408:            /* Connection closed although the application has only shut down the
tcp_in.c:409:               tx side: call the PCB's err callback and indicate the closure to
tcp_in.c:410:               ensure the application doesn't continue using the PCB. */
tcp_in.c:411:            TCP_EVENT_ERR(pcb->errf, pcb->callback_arg, ERR_CLSD);
tcp_in.c:412:          }
tcp_in.c:413:          tcp_pcb_remove(&tcp_active_pcbs, pcb);
tcp_in.c:414:          memp_free(MEMP_TCP_PCB, pcb);
tcp_in.c:415:          goto aborted;
tcp_in.c:416:        }
tcp_in.c:417:#if TCP_QUEUE_OOSEQ && LWIP_WND_SCALE
tcp_in.c:418:        while (recv_data != NULL) {
tcp_in.c:419:          struct pbuf *rest = NULL;
tcp_in.c:420:          pbuf_split_64k(recv_data, &rest);
tcp_in.c:421:#else /* TCP_QUEUE_OOSEQ && LWIP_WND_SCALE */
tcp_in.c:422:        if (recv_data != NULL) {
tcp_in.c:423:#endif /* TCP_QUEUE_OOSEQ && LWIP_WND_SCALE */
tcp_in.c:424:
tcp_in.c:425:          LWIP_ASSERT("pcb->refused_data == NULL", pcb->refused_data == NULL);
tcp_in.c:426:          if (pcb->flags & TF_RXCLOSED) {
tcp_in.c:427:            /* received data although already closed -> abort (send RST) to
tcp_in.c:428:               notify the remote host that not all data has been processed */
tcp_in.c:429:            pbuf_free(recv_data);
tcp_in.c:430:#if TCP_QUEUE_OOSEQ && LWIP_WND_SCALE
tcp_in.c:431:            if (rest != NULL) {
tcp_in.c:432:              pbuf_free(rest);
tcp_in.c:433:            }
tcp_in.c:434:#endif /* TCP_QUEUE_OOSEQ && LWIP_WND_SCALE */
tcp_in.c:435:            tcp_abort(pcb);
tcp_in.c:436:            goto aborted;
tcp_in.c:437:          }
tcp_in.c:438:
tcp_in.c:439:          /* Notify application that data has been received. */
tcp_in.c:440:          TCP_EVENT_RECV(pcb, recv_data, ERR_OK, err);
tcp_in.c:441:          if (err == ERR_ABRT) {
tcp_in.c:442:#if TCP_QUEUE_OOSEQ && LWIP_WND_SCALE
tcp_in.c:443:            if (rest != NULL) {
tcp_in.c:444:              pbuf_free(rest);
tcp_in.c:445:            }
tcp_in.c:446:#endif /* TCP_QUEUE_OOSEQ && LWIP_WND_SCALE */
tcp_in.c:447:            goto aborted;
tcp_in.c:448:          }
tcp_in.c:449:
tcp_in.c:450:          /* If the upper layer can't receive this data, store it */
tcp_in.c:451:          if (err != ERR_OK) {
tcp_in.c:452:#if TCP_QUEUE_OOSEQ && LWIP_WND_SCALE
tcp_in.c:453:            if (rest != NULL) {
tcp_in.c:454:              pbuf_cat(recv_data, rest);
tcp_in.c:455:            }
tcp_in.c:456:#endif /* TCP_QUEUE_OOSEQ && LWIP_WND_SCALE */
tcp_in.c:457:            pcb->refused_data = recv_data;
tcp_in.c:458:            LWIP_DEBUGF(TCP_INPUT_DEBUG, ("tcp_input: keep incoming packet, because pcb is \"full\"\n"));
tcp_in.c:459:#if TCP_QUEUE_OOSEQ && LWIP_WND_SCALE
tcp_in.c:460:            break;
tcp_in.c:461:          } else {
tcp_in.c:462:            /* Upper layer received the data, go on with the rest if > 64K */
tcp_in.c:463:            recv_data = rest;
tcp_in.c:464:#endif /* TCP_QUEUE_OOSEQ && LWIP_WND_SCALE */
tcp_in.c:465:          }
tcp_in.c:466:        }
tcp_in.c:467:
tcp_in.c:468:        /* If a FIN segment was received, we call the callback
tcp_in.c:469:           function with a NULL buffer to indicate EOF. */
tcp_in.c:470:        if (recv_flags & TF_GOT_FIN) {
tcp_in.c:471:          if (pcb->refused_data != NULL) {
tcp_in.c:472:            /* Delay this if we have refused data. */
tcp_in.c:473:            pcb->refused_data->flags |= PBUF_FLAG_TCP_FIN;
tcp_in.c:474:          } else {
tcp_in.c:475:            /* correct rcv_wnd as the application won't call tcp_recved()
tcp_in.c:476:               for the FIN's seqno */
tcp_in.c:477:            if (pcb->rcv_wnd != TCP_WND_MAX(pcb)) {
tcp_in.c:478:              pcb->rcv_wnd++;
tcp_in.c:479:            }
tcp_in.c:480:            TCP_EVENT_CLOSED(pcb, err);
tcp_in.c:481:            if (err == ERR_ABRT) {
tcp_in.c:482:              goto aborted;
tcp_in.c:483:            }
tcp_in.c:484:          }
tcp_in.c:485:        }
tcp_in.c:486:
tcp_in.c:487:        tcp_input_pcb = NULL;
tcp_in.c:488:        /* Try to send something out. */
tcp_in.c:489:        tcp_output(pcb);
tcp_in.c:490:#if TCP_INPUT_DEBUG
tcp_in.c:491:#if TCP_DEBUG
tcp_in.c:492:        tcp_debug_print_state(pcb->state);
tcp_in.c:493:#endif /* TCP_DEBUG */
tcp_in.c:494:#endif /* TCP_INPUT_DEBUG */
tcp_in.c:495:      }
tcp_in.c:496:    }
tcp_in.c:497:    /* Jump target if pcb has been aborted in a callback (by calling tcp_abort()).
tcp_in.c:498:       Below this line, 'pcb' may not be dereferenced! */
tcp_in.c:499:aborted:
tcp_in.c:500:    tcp_input_pcb = NULL;
tcp_in.c:501:    recv_data = NULL;
tcp_in.c:502:
tcp_in.c:503:    /* give up our reference to inseg.p */
tcp_in.c:504:    if (inseg.p != NULL)
tcp_in.c:505:    {
tcp_in.c:506:      pbuf_free(inseg.p);
tcp_in.c:507:      inseg.p = NULL;
tcp_in.c:508:    }
tcp_in.c:509:  } else {
tcp_in.c:510:
tcp_in.c:511:    /* If no matching PCB was found, send a TCP RST (reset) to the
tcp_in.c:512:       sender. */
tcp_in.c:513:    LWIP_DEBUGF(TCP_RST_DEBUG, ("tcp_input: no PCB match found, resetting.\n"));
tcp_in.c:514:    if (!(TCPH_FLAGS(tcphdr) & TCP_RST)) {
tcp_in.c:515:      TCP_STATS_INC(tcp.proterr);
tcp_in.c:516:      TCP_STATS_INC(tcp.drop);
tcp_in.c:517:      tcp_rst(ackno, seqno + tcplen, ip_current_dest_addr(),
tcp_in.c:518:        ip_current_src_addr(), tcphdr->dest, tcphdr->src);
tcp_in.c:519:    }
tcp_in.c:520:    pbuf_free(p);
tcp_in.c:521:  }
tcp_in.c:522:
tcp_in.c:523:  LWIP_ASSERT("tcp_input: tcp_pcbs_sane()", tcp_pcbs_sane());
tcp_in.c:524:  PERF_STOP("tcp_input");
tcp_in.c:525:  return;
tcp_in.c:526:dropped:
tcp_in.c:527:  TCP_STATS_INC(tcp.drop);
tcp_in.c:528:  MIB2_STATS_INC(mib2.tcpinerrs);
tcp_in.c:529:  pbuf_free(p);
tcp_in.c:530:}
tcp_in.c:531:
tcp_in.c:532:/**
tcp_in.c:533: * Called by tcp_input() when a segment arrives for a listening
tcp_in.c:534: * connection (from tcp_input()).
tcp_in.c:535: *
tcp_in.c:536: * @param pcb the tcp_pcb_listen for which a segment arrived
tcp_in.c:537: *
tcp_in.c:538: * @note the segment which arrived is saved in global variables, therefore only the pcb
tcp_in.c:539: *       involved is passed as a parameter to this function
tcp_in.c:540: */
tcp_in.c:541:static void
tcp_in.c:542:tcp_listen_input(struct tcp_pcb_listen *pcb)
tcp_in.c:543:{
tcp_in.c:544:  struct tcp_pcb *npcb;
tcp_in.c:545:  err_t rc;
tcp_in.c:546:
tcp_in.c:547:  if (flags & TCP_RST) {
tcp_in.c:548:    /* An incoming RST should be ignored. Return. */
tcp_in.c:549:    return;
tcp_in.c:550:  }
tcp_in.c:551:
tcp_in.c:552:  /* In the LISTEN state, we check for incoming SYN segments,
tcp_in.c:553:     creates a new PCB, and responds with a SYN|ACK. */
tcp_in.c:554:  if (flags & TCP_ACK) {
tcp_in.c:555:    /* For incoming segments with the ACK flag set, respond with a
tcp_in.c:556:       RST. */
tcp_in.c:557:    LWIP_DEBUGF(TCP_RST_DEBUG, ("tcp_listen_input: ACK in LISTEN, sending reset\n"));
tcp_in.c:558:    tcp_rst(ackno, seqno + tcplen, ip_current_dest_addr(),
tcp_in.c:559:      ip_current_src_addr(), tcphdr->dest, tcphdr->src);
tcp_in.c:560:  } else if (flags & TCP_SYN) {
tcp_in.c:561:    LWIP_DEBUGF(TCP_DEBUG, ("TCP connection request %"U16_F" -> %"U16_F".\n", tcphdr->src, tcphdr->dest));
tcp_in.c:562:#if TCP_LISTEN_BACKLOG
tcp_in.c:563:    if (pcb->accepts_pending >= pcb->backlog) {
tcp_in.c:564:      LWIP_DEBUGF(TCP_DEBUG, ("tcp_listen_input: listen backlog exceeded for port %"U16_F"\n", tcphdr->dest));
tcp_in.c:565:      return;
tcp_in.c:566:    }
tcp_in.c:567:#endif /* TCP_LISTEN_BACKLOG */
tcp_in.c:568:    npcb = tcp_alloc(pcb->prio);
tcp_in.c:569:    /* If a new PCB could not be created (probably due to lack of memory),
tcp_in.c:570:       we don't do anything, but rely on the sender will retransmit the
tcp_in.c:571:       SYN at a time when we have more memory available. */
tcp_in.c:572:    if (npcb == NULL) {
tcp_in.c:573:      err_t err;
tcp_in.c:574:      LWIP_DEBUGF(TCP_DEBUG, ("tcp_listen_input: could not allocate PCB\n"));
tcp_in.c:575:      TCP_STATS_INC(tcp.memerr);
tcp_in.c:576:      TCP_EVENT_ACCEPT(pcb, NULL, pcb->callback_arg, ERR_MEM, err);
tcp_in.c:577:      LWIP_UNUSED_ARG(err); /* err not useful here */
tcp_in.c:578:      return;
tcp_in.c:579:    }
tcp_in.c:580:#if TCP_LISTEN_BACKLOG
tcp_in.c:581:    pcb->accepts_pending++;
tcp_in.c:582:    npcb->flags |= TF_BACKLOGPEND;
tcp_in.c:583:#endif /* TCP_LISTEN_BACKLOG */
tcp_in.c:584:    /* Set up the new PCB. */
tcp_in.c:585:    ip_addr_copy(npcb->local_ip, *ip_current_dest_addr());
tcp_in.c:586:    ip_addr_copy(npcb->remote_ip, *ip_current_src_addr());
tcp_in.c:587:    npcb->local_port = pcb->local_port;
tcp_in.c:588:    npcb->remote_port = tcphdr->src;
tcp_in.c:589:    npcb->state = SYN_RCVD;
tcp_in.c:590:    npcb->rcv_nxt = seqno + 1;
tcp_in.c:591:    npcb->rcv_ann_right_edge = npcb->rcv_nxt;
tcp_in.c:592:    npcb->snd_wl1 = seqno - 1;/* initialise to seqno-1 to force window update */
tcp_in.c:593:    npcb->callback_arg = pcb->callback_arg;
tcp_in.c:594:#if LWIP_CALLBACK_API || TCP_LISTEN_BACKLOG
tcp_in.c:595:    npcb->listener = pcb;
tcp_in.c:596:#endif /* LWIP_CALLBACK_API || TCP_LISTEN_BACKLOG */
tcp_in.c:597:    /* inherit socket options */
tcp_in.c:598:    npcb->so_options = pcb->so_options & SOF_INHERITED;
tcp_in.c:599:    /* Register the new PCB so that we can begin receiving segments
tcp_in.c:600:       for it. */
tcp_in.c:601:    TCP_REG_ACTIVE(npcb);
tcp_in.c:602:
tcp_in.c:603:    /* Parse any options in the SYN. */
tcp_in.c:604:    tcp_parseopt(npcb);
tcp_in.c:605:    npcb->snd_wnd = SND_WND_SCALE(npcb, tcphdr->wnd);
tcp_in.c:606:    npcb->snd_wnd_max = npcb->snd_wnd;
tcp_in.c:607:    npcb->ssthresh = LWIP_TCP_INITIAL_SSTHRESH(npcb);
tcp_in.c:608:
tcp_in.c:609:#if TCP_CALCULATE_EFF_SEND_MSS
tcp_in.c:610:    npcb->mss = tcp_eff_send_mss(npcb->mss, &npcb->local_ip, &npcb->remote_ip);
tcp_in.c:611:#endif /* TCP_CALCULATE_EFF_SEND_MSS */
tcp_in.c:612:
tcp_in.c:613:    MIB2_STATS_INC(mib2.tcppassiveopens);
tcp_in.c:614:
tcp_in.c:615:    /* Send a SYN|ACK together with the MSS option. */
tcp_in.c:616:    rc = tcp_enqueue_flags(npcb, TCP_SYN | TCP_ACK);
tcp_in.c:617:    if (rc != ERR_OK) {
tcp_in.c:618:      tcp_abandon(npcb, 0);
tcp_in.c:619:      return;
tcp_in.c:620:    }
tcp_in.c:621:    tcp_output(npcb);
tcp_in.c:622:  }
tcp_in.c:623:  return;
tcp_in.c:624:}
tcp_in.c:625:
tcp_in.c:626:/**
tcp_in.c:627: * Called by tcp_input() when a segment arrives for a connection in
tcp_in.c:628: * TIME_WAIT.
tcp_in.c:629: *
tcp_in.c:630: * @param pcb the tcp_pcb for which a segment arrived
tcp_in.c:631: *
tcp_in.c:632: * @note the segment which arrived is saved in global variables, therefore only the pcb
tcp_in.c:633: *       involved is passed as a parameter to this function
tcp_in.c:634: */
tcp_in.c:635:static void
tcp_in.c:636:tcp_timewait_input(struct tcp_pcb *pcb)
tcp_in.c:637:{
tcp_in.c:638:  /* RFC 1337: in TIME_WAIT, ignore RST and ACK FINs + any 'acceptable' segments */
tcp_in.c:639:  /* RFC 793 3.9 Event Processing - Segment Arrives:
tcp_in.c:640:   * - first check sequence number - we skip that one in TIME_WAIT (always
tcp_in.c:641:   *   acceptable since we only send ACKs)
tcp_in.c:642:   * - second check the RST bit (... return) */
tcp_in.c:643:  if (flags & TCP_RST) {
tcp_in.c:644:    return;
tcp_in.c:645:  }
tcp_in.c:646:  /* - fourth, check the SYN bit, */
tcp_in.c:647:  if (flags & TCP_SYN) {
tcp_in.c:648:    /* If an incoming segment is not acceptable, an acknowledgment
tcp_in.c:649:       should be sent in reply */
tcp_in.c:650:    if (TCP_SEQ_BETWEEN(seqno, pcb->rcv_nxt, pcb->rcv_nxt + pcb->rcv_wnd)) {
tcp_in.c:651:      /* If the SYN is in the window it is an error, send a reset */
tcp_in.c:652:      tcp_rst(ackno, seqno + tcplen, ip_current_dest_addr(),
tcp_in.c:653:        ip_current_src_addr(), tcphdr->dest, tcphdr->src);
tcp_in.c:654:      return;
tcp_in.c:655:    }
tcp_in.c:656:  } else if (flags & TCP_FIN) {
tcp_in.c:657:    /* - eighth, check the FIN bit: Remain in the TIME-WAIT state.
tcp_in.c:658:         Restart the 2 MSL time-wait timeout.*/
tcp_in.c:659:    pcb->tmr = tcp_ticks;
tcp_in.c:660:  }
tcp_in.c:661:
tcp_in.c:662:  if ((tcplen > 0)) {
tcp_in.c:663:    /* Acknowledge data, FIN or out-of-window SYN */
tcp_in.c:664:    pcb->flags |= TF_ACK_NOW;
tcp_in.c:665:    tcp_output(pcb);
tcp_in.c:666:  }
tcp_in.c:667:  return;
tcp_in.c:668:}
tcp_in.c:669:
tcp_in.c:670:/**
tcp_in.c:671: * Implements the TCP state machine. Called by tcp_input. In some
tcp_in.c:672: * states tcp_receive() is called to receive data. The tcp_seg
tcp_in.c:673: * argument will be freed by the caller (tcp_input()) unless the
tcp_in.c:674: * recv_data pointer in the pcb is set.
tcp_in.c:675: *
tcp_in.c:676: * @param pcb the tcp_pcb for which a segment arrived
tcp_in.c:677: *
tcp_in.c:678: * @note the segment which arrived is saved in global variables, therefore only the pcb
tcp_in.c:679: *       involved is passed as a parameter to this function
tcp_in.c:680: */
tcp_in.c:681:static err_t
tcp_in.c:682:tcp_process(struct tcp_pcb *pcb)
tcp_in.c:683:{
tcp_in.c:684:  struct tcp_seg *rseg;
tcp_in.c:685:  u8_t acceptable = 0;
tcp_in.c:686:  err_t err;
tcp_in.c:687:
tcp_in.c:688:  err = ERR_OK;
tcp_in.c:689:
tcp_in.c:690:  /* Process incoming RST segments. */
tcp_in.c:691:  if (flags & TCP_RST) {
tcp_in.c:692:    /* First, determine if the reset is acceptable. */
tcp_in.c:693:    if (pcb->state == SYN_SENT) {
tcp_in.c:694:      /* "In the SYN-SENT state (a RST received in response to an initial SYN),
tcp_in.c:695:          the RST is acceptable if the ACK field acknowledges the SYN." */
tcp_in.c:696:      if (ackno == pcb->snd_nxt) {
tcp_in.c:697:        acceptable = 1;
tcp_in.c:698:      }
tcp_in.c:699:    } else {
tcp_in.c:700:      /* "In all states except SYN-SENT, all reset (RST) segments are validated
tcp_in.c:701:          by checking their SEQ-fields." */
tcp_in.c:702:      if (seqno == pcb->rcv_nxt) {
tcp_in.c:703:        acceptable = 1;
tcp_in.c:704:      } else  if (TCP_SEQ_BETWEEN(seqno, pcb->rcv_nxt,
tcp_in.c:705:                                  pcb->rcv_nxt + pcb->rcv_wnd)) {
tcp_in.c:706:        /* If the sequence number is inside the window, we only send an ACK
tcp_in.c:707:           and wait for a re-send with matching sequence number.
tcp_in.c:708:           This violates RFC 793, but is required to protection against
tcp_in.c:709:           CVE-2004-0230 (RST spoofing attack). */
tcp_in.c:710:        tcp_ack_now(pcb);
tcp_in.c:711:      }
tcp_in.c:712:    }
tcp_in.c:713:
tcp_in.c:714:    if (acceptable) {
tcp_in.c:715:      LWIP_DEBUGF(TCP_INPUT_DEBUG, ("tcp_process: Connection RESET\n"));
tcp_in.c:716:      LWIP_ASSERT("tcp_input: pcb->state != CLOSED", pcb->state != CLOSED);
tcp_in.c:717:      recv_flags |= TF_RESET;
tcp_in.c:718:      pcb->flags &= ~TF_ACK_DELAY;
tcp_in.c:719:      return ERR_RST;
tcp_in.c:720:    } else {
tcp_in.c:721:      LWIP_DEBUGF(TCP_INPUT_DEBUG, ("tcp_process: unacceptable reset seqno %"U32_F" rcv_nxt %"U32_F"\n",
tcp_in.c:722:       seqno, pcb->rcv_nxt));
tcp_in.c:723:      LWIP_DEBUGF(TCP_DEBUG, ("tcp_process: unacceptable reset seqno %"U32_F" rcv_nxt %"U32_F"\n",
tcp_in.c:724:       seqno, pcb->rcv_nxt));
tcp_in.c:725:      return ERR_OK;
tcp_in.c:726:    }
tcp_in.c:727:  }
tcp_in.c:728:
tcp_in.c:729:  if ((flags & TCP_SYN) && (pcb->state != SYN_SENT && pcb->state != SYN_RCVD)) {
tcp_in.c:730:    /* Cope with new connection attempt after remote end crashed */
tcp_in.c:731:    tcp_ack_now(pcb);
tcp_in.c:732:    return ERR_OK;
tcp_in.c:733:  }
tcp_in.c:734:
tcp_in.c:735:  if ((pcb->flags & TF_RXCLOSED) == 0) {
tcp_in.c:736:    /* Update the PCB (in)activity timer unless rx is closed (see tcp_shutdown) */
tcp_in.c:737:    pcb->tmr = tcp_ticks;
tcp_in.c:738:  }
tcp_in.c:739:  pcb->keep_cnt_sent = 0;
tcp_in.c:740:
tcp_in.c:741:  tcp_parseopt(pcb);
tcp_in.c:742:
tcp_in.c:743:  /* Do different things depending on the TCP state. */
tcp_in.c:744:  switch (pcb->state) {
tcp_in.c:745:  case SYN_SENT:
tcp_in.c:746:    LWIP_DEBUGF(TCP_INPUT_DEBUG, ("SYN-SENT: ackno %"U32_F" pcb->snd_nxt %"U32_F" unacked %"U32_F"\n", ackno,
tcp_in.c:747:     pcb->snd_nxt, lwip_ntohl(pcb->unacked->tcphdr->seqno)));
tcp_in.c:748:    /* received SYN ACK with expected sequence number? */
tcp_in.c:749:    if ((flags & TCP_ACK) && (flags & TCP_SYN)
tcp_in.c:750:        && (ackno == pcb->lastack + 1)) {
tcp_in.c:751:      pcb->rcv_nxt = seqno + 1;
tcp_in.c:752:      pcb->rcv_ann_right_edge = pcb->rcv_nxt;
tcp_in.c:753:      pcb->lastack = ackno;
tcp_in.c:754:      pcb->snd_wnd = SND_WND_SCALE(pcb, tcphdr->wnd);
tcp_in.c:755:      pcb->snd_wnd_max = pcb->snd_wnd;
tcp_in.c:756:      pcb->snd_wl1 = seqno - 1; /* initialise to seqno - 1 to force window update */
tcp_in.c:757:      pcb->state = ESTABLISHED;
tcp_in.c:758:
tcp_in.c:759:#if TCP_CALCULATE_EFF_SEND_MSS
tcp_in.c:760:      pcb->mss = tcp_eff_send_mss(pcb->mss, &pcb->local_ip, &pcb->remote_ip);
tcp_in.c:761:#endif /* TCP_CALCULATE_EFF_SEND_MSS */
tcp_in.c:762:
tcp_in.c:763:      /* Set ssthresh again after changing 'mss' and 'snd_wnd' */
tcp_in.c:764:      pcb->ssthresh = LWIP_TCP_INITIAL_SSTHRESH(pcb);
tcp_in.c:765:
tcp_in.c:766:      pcb->cwnd = LWIP_TCP_CALC_INITIAL_CWND(pcb->mss);
tcp_in.c:767:      LWIP_DEBUGF(TCP_CWND_DEBUG, ("tcp_process (SENT): cwnd %"TCPWNDSIZE_F
tcp_in.c:768:                                   " ssthresh %"TCPWNDSIZE_F"\n",
tcp_in.c:769:                                   pcb->cwnd, pcb->ssthresh));
tcp_in.c:770:      LWIP_ASSERT("pcb->snd_queuelen > 0", (pcb->snd_queuelen > 0));
tcp_in.c:771:      --pcb->snd_queuelen;
tcp_in.c:772:      LWIP_DEBUGF(TCP_QLEN_DEBUG, ("tcp_process: SYN-SENT --queuelen %"TCPWNDSIZE_F"\n", (tcpwnd_size_t)pcb->snd_queuelen));
tcp_in.c:773:      rseg = pcb->unacked;
tcp_in.c:774:      if (rseg == NULL) {
tcp_in.c:775:        /* might happen if tcp_output fails in tcp_rexmit_rto()
tcp_in.c:776:           in which case the segment is on the unsent list */
tcp_in.c:777:        rseg = pcb->unsent;
tcp_in.c:778:        LWIP_ASSERT("no segment to free", rseg != NULL);
tcp_in.c:779:        pcb->unsent = rseg->next;
tcp_in.c:780:      } else {
tcp_in.c:781:        pcb->unacked = rseg->next;
tcp_in.c:782:      }
tcp_in.c:783:      tcp_seg_free(rseg);
tcp_in.c:784:
tcp_in.c:785:      /* If there's nothing left to acknowledge, stop the retransmit
tcp_in.c:786:         timer, otherwise reset it to start again */
tcp_in.c:787:      if (pcb->unacked == NULL) {
tcp_in.c:788:        pcb->rtime = -1;
tcp_in.c:789:      } else {
tcp_in.c:790:        pcb->rtime = 0;
tcp_in.c:791:        pcb->nrtx = 0;
tcp_in.c:792:      }
tcp_in.c:793:
tcp_in.c:794:      /* Call the user specified function to call when successfully
tcp_in.c:795:       * connected. */
tcp_in.c:796:      TCP_EVENT_CONNECTED(pcb, ERR_OK, err);
tcp_in.c:797:      if (err == ERR_ABRT) {
tcp_in.c:798:        return ERR_ABRT;
tcp_in.c:799:      }
tcp_in.c:800:      tcp_ack_now(pcb);
tcp_in.c:801:    }
tcp_in.c:802:    /* received ACK? possibly a half-open connection */
tcp_in.c:803:    else if (flags & TCP_ACK) {
tcp_in.c:804:      /* send a RST to bring the other side in a non-synchronized state. */
tcp_in.c:805:      tcp_rst(ackno, seqno + tcplen, ip_current_dest_addr(),
tcp_in.c:806:        ip_current_src_addr(), tcphdr->dest, tcphdr->src);
tcp_in.c:807:      /* Resend SYN immediately (don't wait for rto timeout) to establish
tcp_in.c:808:        connection faster */
tcp_in.c:809:      pcb->rtime = 0;
tcp_in.c:810:      tcp_rexmit_rto(pcb);
tcp_in.c:811:    }
tcp_in.c:812:    break;
tcp_in.c:813:  case SYN_RCVD:
tcp_in.c:814:    if (flags & TCP_ACK) {
tcp_in.c:815:      /* expected ACK number? */
tcp_in.c:816:      if (TCP_SEQ_BETWEEN(ackno, pcb->lastack+1, pcb->snd_nxt)) {
tcp_in.c:817:        pcb->state = ESTABLISHED;
tcp_in.c:818:        LWIP_DEBUGF(TCP_DEBUG, ("TCP connection established %"U16_F" -> %"U16_F".\n", inseg.tcphdr->src, inseg.tcphdr->dest));
tcp_in.c:819:#if LWIP_CALLBACK_API
tcp_in.c:820:        LWIP_ASSERT("pcb->listener->accept != NULL",
tcp_in.c:821:          (pcb->listener == NULL) || (pcb->listener->accept != NULL));
tcp_in.c:822:        if (pcb->listener == NULL) {
tcp_in.c:823:          /* listen pcb might be closed by now */
tcp_in.c:824:          err = ERR_VAL;
tcp_in.c:825:        } else
tcp_in.c:826:#endif
tcp_in.c:827:        {
tcp_in.c:828:          tcp_backlog_accepted(pcb);
tcp_in.c:829:          /* Call the accept function. */
tcp_in.c:830:          TCP_EVENT_ACCEPT(pcb->listener, pcb, pcb->callback_arg, ERR_OK, err);
tcp_in.c:831:        }
tcp_in.c:832:        if (err != ERR_OK) {
tcp_in.c:833:          /* If the accept function returns with an error, we abort
tcp_in.c:834:           * the connection. */
tcp_in.c:835:          /* Already aborted? */
tcp_in.c:836:          if (err != ERR_ABRT) {
tcp_in.c:837:            tcp_abort(pcb);
tcp_in.c:838:          }
tcp_in.c:839:          return ERR_ABRT;
tcp_in.c:840:        }
tcp_in.c:841:        /* If there was any data contained within this ACK,
tcp_in.c:842:         * we'd better pass it on to the application as well. */
tcp_in.c:843:        tcp_receive(pcb);
tcp_in.c:844:
tcp_in.c:845:        /* passive open: update initial ssthresh now that the correct window is
tcp_in.c:846:           known: if the remote side supports window scaling, the window sent
tcp_in.c:847:           with the initial SYN can be smaller than the one used later */
tcp_in.c:848:        pcb->ssthresh = LWIP_TCP_INITIAL_SSTHRESH(pcb);
tcp_in.c:849:
tcp_in.c:850:        /* Prevent ACK for SYN to generate a sent event */
tcp_in.c:851:        if (recv_acked != 0) {
tcp_in.c:852:          recv_acked--;
tcp_in.c:853:        }
tcp_in.c:854:
tcp_in.c:855:        pcb->cwnd = LWIP_TCP_CALC_INITIAL_CWND(pcb->mss);
tcp_in.c:856:        LWIP_DEBUGF(TCP_CWND_DEBUG, ("tcp_process (SYN_RCVD): cwnd %"TCPWNDSIZE_F
tcp_in.c:857:                                     " ssthresh %"TCPWNDSIZE_F"\n",
tcp_in.c:858:                                     pcb->cwnd, pcb->ssthresh));
tcp_in.c:859:
tcp_in.c:860:        if (recv_flags & TF_GOT_FIN) {
tcp_in.c:861:          tcp_ack_now(pcb);
tcp_in.c:862:          pcb->state = CLOSE_WAIT;
tcp_in.c:863:        }
tcp_in.c:864:      } else {
tcp_in.c:865:        /* incorrect ACK number, send RST */
tcp_in.c:866:        tcp_rst(ackno, seqno + tcplen, ip_current_dest_addr(),
tcp_in.c:867:          ip_current_src_addr(), tcphdr->dest, tcphdr->src);
tcp_in.c:868:      }
tcp_in.c:869:    } else if ((flags & TCP_SYN) && (seqno == pcb->rcv_nxt - 1)) {
tcp_in.c:870:      /* Looks like another copy of the SYN - retransmit our SYN-ACK */
tcp_in.c:871:      tcp_rexmit(pcb);
tcp_in.c:872:    }
tcp_in.c:873:    break;
tcp_in.c:874:  case CLOSE_WAIT:
tcp_in.c:875:    /* FALLTHROUGH */
tcp_in.c:876:  case ESTABLISHED:
tcp_in.c:877:    tcp_receive(pcb);
tcp_in.c:878:    if (recv_flags & TF_GOT_FIN) { /* passive close */
tcp_in.c:879:      tcp_ack_now(pcb);
tcp_in.c:880:      pcb->state = CLOSE_WAIT;
tcp_in.c:881:    }
tcp_in.c:882:    break;
tcp_in.c:883:  case FIN_WAIT_1:
tcp_in.c:884:    tcp_receive(pcb);
tcp_in.c:885:    if (recv_flags & TF_GOT_FIN) {
tcp_in.c:886:      if ((flags & TCP_ACK) && (ackno == pcb->snd_nxt) &&
tcp_in.c:887:          pcb->unsent == NULL) {
tcp_in.c:888:        LWIP_DEBUGF(TCP_DEBUG,
tcp_in.c:889:          ("TCP connection closed: FIN_WAIT_1 %"U16_F" -> %"U16_F".\n", inseg.tcphdr->src, inseg.tcphdr->dest));
tcp_in.c:890:        tcp_ack_now(pcb);
tcp_in.c:891:        tcp_pcb_purge(pcb);
tcp_in.c:892:        TCP_RMV_ACTIVE(pcb);
tcp_in.c:893:        pcb->state = TIME_WAIT;
tcp_in.c:894:        TCP_REG(&tcp_tw_pcbs, pcb);
tcp_in.c:895:      } else {
tcp_in.c:896:        tcp_ack_now(pcb);
tcp_in.c:897:        pcb->state = CLOSING;
tcp_in.c:898:      }
tcp_in.c:899:    } else if ((flags & TCP_ACK) && (ackno == pcb->snd_nxt) &&
tcp_in.c:900:               pcb->unsent == NULL) {
tcp_in.c:901:      pcb->state = FIN_WAIT_2;
tcp_in.c:902:    }
tcp_in.c:903:    break;
tcp_in.c:904:  case FIN_WAIT_2:
tcp_in.c:905:    tcp_receive(pcb);
tcp_in.c:906:    if (recv_flags & TF_GOT_FIN) {
tcp_in.c:907:      LWIP_DEBUGF(TCP_DEBUG, ("TCP connection closed: FIN_WAIT_2 %"U16_F" -> %"U16_F".\n", inseg.tcphdr->src, inseg.tcphdr->dest));
tcp_in.c:908:      tcp_ack_now(pcb);
tcp_in.c:909:      tcp_pcb_purge(pcb);
tcp_in.c:910:      TCP_RMV_ACTIVE(pcb);
tcp_in.c:911:      pcb->state = TIME_WAIT;
tcp_in.c:912:      TCP_REG(&tcp_tw_pcbs, pcb);
tcp_in.c:913:    }
tcp_in.c:914:    break;
tcp_in.c:915:  case CLOSING:
tcp_in.c:916:    tcp_receive(pcb);
tcp_in.c:917:    if (flags & TCP_ACK && ackno == pcb->snd_nxt && pcb->unsent == NULL) {
tcp_in.c:918:      LWIP_DEBUGF(TCP_DEBUG, ("TCP connection closed: CLOSING %"U16_F" -> %"U16_F".\n", inseg.tcphdr->src, inseg.tcphdr->dest));
tcp_in.c:919:      tcp_pcb_purge(pcb);
tcp_in.c:920:      TCP_RMV_ACTIVE(pcb);
tcp_in.c:921:      pcb->state = TIME_WAIT;
tcp_in.c:922:      TCP_REG(&tcp_tw_pcbs, pcb);
tcp_in.c:923:    }
tcp_in.c:924:    break;
tcp_in.c:925:  case LAST_ACK:
tcp_in.c:926:    tcp_receive(pcb);
tcp_in.c:927:    if (flags & TCP_ACK && ackno == pcb->snd_nxt && pcb->unsent == NULL) {
tcp_in.c:928:      LWIP_DEBUGF(TCP_DEBUG, ("TCP connection closed: LAST_ACK %"U16_F" -> %"U16_F".\n", inseg.tcphdr->src, inseg.tcphdr->dest));
tcp_in.c:929:      /* bugfix #21699: don't set pcb->state to CLOSED here or we risk leaking segments */
tcp_in.c:930:      recv_flags |= TF_CLOSED;
tcp_in.c:931:    }
tcp_in.c:932:    break;
tcp_in.c:933:  default:
tcp_in.c:934:    break;
tcp_in.c:935:  }
tcp_in.c:936:  return ERR_OK;
tcp_in.c:937:}
tcp_in.c:938:
tcp_in.c:939:#if TCP_QUEUE_OOSEQ
tcp_in.c:940:/**
tcp_in.c:941: * Insert segment into the list (segments covered with new one will be deleted)
tcp_in.c:942: *
tcp_in.c:943: * Called from tcp_receive()
tcp_in.c:944: */
tcp_in.c:945:static void
tcp_in.c:946:tcp_oos_insert_segment(struct tcp_seg *cseg, struct tcp_seg *next)
tcp_in.c:947:{
tcp_in.c:948:  struct tcp_seg *old_seg;
tcp_in.c:949:
tcp_in.c:950:  if (TCPH_FLAGS(cseg->tcphdr) & TCP_FIN) {
tcp_in.c:951:    /* received segment overlaps all following segments */
tcp_in.c:952:    tcp_segs_free(next);
tcp_in.c:953:    next = NULL;
tcp_in.c:954:  } else {
tcp_in.c:955:    /* delete some following segments
tcp_in.c:956:       oos queue may have segments with FIN flag */
tcp_in.c:957:    while (next &&
tcp_in.c:958:           TCP_SEQ_GEQ((seqno + cseg->len),
tcp_in.c:959:                      (next->tcphdr->seqno + next->len))) {
tcp_in.c:960:      /* cseg with FIN already processed */
tcp_in.c:961:      if (TCPH_FLAGS(next->tcphdr) & TCP_FIN) {
tcp_in.c:962:        TCPH_SET_FLAG(cseg->tcphdr, TCP_FIN);
tcp_in.c:963:      }
tcp_in.c:964:      old_seg = next;
tcp_in.c:965:      next = next->next;
tcp_in.c:966:      tcp_seg_free(old_seg);
tcp_in.c:967:    }
tcp_in.c:968:    if (next &&
tcp_in.c:969:        TCP_SEQ_GT(seqno + cseg->len, next->tcphdr->seqno)) {
tcp_in.c:970:      /* We need to trim the incoming segment. */
tcp_in.c:971:      cseg->len = (u16_t)(next->tcphdr->seqno - seqno);
tcp_in.c:972:      pbuf_realloc(cseg->p, cseg->len);
tcp_in.c:973:    }
tcp_in.c:974:  }
tcp_in.c:975:  cseg->next = next;
tcp_in.c:976:}
tcp_in.c:977:#endif /* TCP_QUEUE_OOSEQ */
tcp_in.c:978:
tcp_in.c:979:/**
tcp_in.c:980: * Called by tcp_process. Checks if the given segment is an ACK for outstanding
tcp_in.c:981: * data, and if so frees the memory of the buffered data. Next, it places the
tcp_in.c:982: * segment on any of the receive queues (pcb->recved or pcb->ooseq). If the segment
tcp_in.c:983: * is buffered, the pbuf is referenced by pbuf_ref so that it will not be freed until
tcp_in.c:984: * it has been removed from the buffer.
tcp_in.c:985: *
tcp_in.c:986: * If the incoming segment constitutes an ACK for a segment that was used for RTT
tcp_in.c:987: * estimation, the RTT is estimated here as well.
tcp_in.c:988: *
tcp_in.c:989: * Called from tcp_process().
tcp_in.c:990: */
tcp_in.c:991:static void
tcp_in.c:992:tcp_receive(struct tcp_pcb *pcb)
tcp_in.c:993:{
tcp_in.c:994:  struct tcp_seg *next;
tcp_in.c:995:#if TCP_QUEUE_OOSEQ
tcp_in.c:996:  struct tcp_seg *prev, *cseg;
tcp_in.c:997:#endif /* TCP_QUEUE_OOSEQ */
tcp_in.c:998:  s32_t off;
tcp_in.c:999:  s16_t m;
tcp_in.c:1000:  u32_t right_wnd_edge;
tcp_in.c:1001:  u16_t new_tot_len;
tcp_in.c:1002:  int found_dupack = 0;
tcp_in.c:1003:#if TCP_OOSEQ_MAX_BYTES || TCP_OOSEQ_MAX_PBUFS
tcp_in.c:1004:  u32_t ooseq_blen;
tcp_in.c:1005:  u16_t ooseq_qlen;
tcp_in.c:1006:#endif /* TCP_OOSEQ_MAX_BYTES || TCP_OOSEQ_MAX_PBUFS */
tcp_in.c:1007:
tcp_in.c:1008:  LWIP_ASSERT("tcp_receive: wrong state", pcb->state >= ESTABLISHED);
tcp_in.c:1009:
tcp_in.c:1010:  if (flags & TCP_ACK) {
tcp_in.c:1011:    right_wnd_edge = pcb->snd_wnd + pcb->snd_wl2;
tcp_in.c:1012:
tcp_in.c:1013:    /* Update window. */
tcp_in.c:1014:    if (TCP_SEQ_LT(pcb->snd_wl1, seqno) ||
tcp_in.c:1015:       (pcb->snd_wl1 == seqno && TCP_SEQ_LT(pcb->snd_wl2, ackno)) ||
tcp_in.c:1016:       (pcb->snd_wl2 == ackno && (u32_t)SND_WND_SCALE(pcb, tcphdr->wnd) > pcb->snd_wnd)) {
tcp_in.c:1017:      pcb->snd_wnd = SND_WND_SCALE(pcb, tcphdr->wnd);
tcp_in.c:1018:      /* keep track of the biggest window announced by the remote host to calculate
tcp_in.c:1019:         the maximum segment size */
tcp_in.c:1020:      if (pcb->snd_wnd_max < pcb->snd_wnd) {
tcp_in.c:1021:        pcb->snd_wnd_max = pcb->snd_wnd;
tcp_in.c:1022:      }
tcp_in.c:1023:      pcb->snd_wl1 = seqno;
tcp_in.c:1024:      pcb->snd_wl2 = ackno;
tcp_in.c:1025:      if (pcb->snd_wnd == 0) {
tcp_in.c:1026:        if (pcb->persist_backoff == 0) {
tcp_in.c:1027:          /* start persist timer */
tcp_in.c:1028:          pcb->persist_cnt = 0;
tcp_in.c:1029:          pcb->persist_backoff = 1;
tcp_in.c:1030:        }
tcp_in.c:1031:      } else if (pcb->persist_backoff > 0) {
tcp_in.c:1032:        /* stop persist timer */
tcp_in.c:1033:          pcb->persist_backoff = 0;
tcp_in.c:1034:      }
tcp_in.c:1035:      LWIP_DEBUGF(TCP_WND_DEBUG, ("tcp_receive: window update %"TCPWNDSIZE_F"\n", pcb->snd_wnd));
tcp_in.c:1036:#if TCP_WND_DEBUG
tcp_in.c:1037:    } else {
tcp_in.c:1038:      if (pcb->snd_wnd != (tcpwnd_size_t)SND_WND_SCALE(pcb, tcphdr->wnd)) {
tcp_in.c:1039:        LWIP_DEBUGF(TCP_WND_DEBUG,
tcp_in.c:1040:                    ("tcp_receive: no window update lastack %"U32_F" ackno %"
tcp_in.c:1041:                     U32_F" wl1 %"U32_F" seqno %"U32_F" wl2 %"U32_F"\n",
tcp_in.c:1042:                     pcb->lastack, ackno, pcb->snd_wl1, seqno, pcb->snd_wl2));
tcp_in.c:1043:      }
tcp_in.c:1044:#endif /* TCP_WND_DEBUG */
tcp_in.c:1045:    }
tcp_in.c:1046:
tcp_in.c:1047:    /* (From Stevens TCP/IP Illustrated Vol II, p970.) Its only a
tcp_in.c:1048:     * duplicate ack if:
tcp_in.c:1049:     * 1) It doesn't ACK new data
tcp_in.c:1050:     * 2) length of received packet is zero (i.e. no payload)
tcp_in.c:1051:     * 3) the advertised window hasn't changed
tcp_in.c:1052:     * 4) There is outstanding unacknowledged data (retransmission timer running)
tcp_in.c:1053:     * 5) The ACK is == biggest ACK sequence number so far seen (snd_una)
tcp_in.c:1054:     *
tcp_in.c:1055:     * If it passes all five, should process as a dupack:
tcp_in.c:1056:     * a) dupacks < 3: do nothing
tcp_in.c:1057:     * b) dupacks == 3: fast retransmit
tcp_in.c:1058:     * c) dupacks > 3: increase cwnd
tcp_in.c:1059:     *
tcp_in.c:1060:     * If it only passes 1-3, should reset dupack counter (and add to
tcp_in.c:1061:     * stats, which we don't do in lwIP)
tcp_in.c:1062:     *
tcp_in.c:1063:     * If it only passes 1, should reset dupack counter
tcp_in.c:1064:     *
tcp_in.c:1065:     */
tcp_in.c:1066:
tcp_in.c:1067:    /* Clause 1 */
tcp_in.c:1068:    if (TCP_SEQ_LEQ(ackno, pcb->lastack)) {
tcp_in.c:1069:      /* Clause 2 */
tcp_in.c:1070:      if (tcplen == 0) {
tcp_in.c:1071:        /* Clause 3 */
tcp_in.c:1072:        if (pcb->snd_wl2 + pcb->snd_wnd == right_wnd_edge) {
tcp_in.c:1073:          /* Clause 4 */
tcp_in.c:1074:          if (pcb->rtime >= 0) {
tcp_in.c:1075:            /* Clause 5 */
tcp_in.c:1076:            if (pcb->lastack == ackno) {
tcp_in.c:1077:              found_dupack = 1;
tcp_in.c:1078:              if ((u8_t)(pcb->dupacks + 1) > pcb->dupacks) {
tcp_in.c:1079:                ++pcb->dupacks;
tcp_in.c:1080:              }
tcp_in.c:1081:              if (pcb->dupacks > 3) {
tcp_in.c:1082:                /* Inflate the congestion window, but not if it means that
tcp_in.c:1083:                   the value overflows. */
tcp_in.c:1084:                if ((tcpwnd_size_t)(pcb->cwnd + pcb->mss) > pcb->cwnd) {
tcp_in.c:1085:                  pcb->cwnd += pcb->mss;
tcp_in.c:1086:                }
tcp_in.c:1087:              } else if (pcb->dupacks == 3) {
tcp_in.c:1088:                /* Do fast retransmit */
tcp_in.c:1089:                tcp_rexmit_fast(pcb);
tcp_in.c:1090:              }
tcp_in.c:1091:            }
tcp_in.c:1092:          }
tcp_in.c:1093:        }
tcp_in.c:1094:      }
tcp_in.c:1095:      /* If Clause (1) or more is true, but not a duplicate ack, reset
tcp_in.c:1096:       * count of consecutive duplicate acks */
tcp_in.c:1097:      if (!found_dupack) {
tcp_in.c:1098:        pcb->dupacks = 0;
tcp_in.c:1099:      }
tcp_in.c:1100:    } else if (TCP_SEQ_BETWEEN(ackno, pcb->lastack+1, pcb->snd_nxt)) {
tcp_in.c:1101:      /* We come here when the ACK acknowledges new data. */
tcp_in.c:1102:
tcp_in.c:1103:      /* Reset the "IN Fast Retransmit" flag, since we are no longer
tcp_in.c:1104:         in fast retransmit. Also reset the congestion window to the
tcp_in.c:1105:         slow start threshold. */
tcp_in.c:1106:      if (pcb->flags & TF_INFR) {
tcp_in.c:1107:        pcb->flags &= ~TF_INFR;
tcp_in.c:1108:        pcb->cwnd = pcb->ssthresh;
tcp_in.c:1109:      }
tcp_in.c:1110:
tcp_in.c:1111:      /* Reset the number of retransmissions. */
tcp_in.c:1112:      pcb->nrtx = 0;
tcp_in.c:1113:
tcp_in.c:1114:      /* Reset the retransmission time-out. */
tcp_in.c:1115:      pcb->rto = (pcb->sa >> 3) + pcb->sv;
tcp_in.c:1116:
tcp_in.c:1117:      /* Reset the fast retransmit variables. */
tcp_in.c:1118:      pcb->dupacks = 0;
tcp_in.c:1119:      pcb->lastack = ackno;
tcp_in.c:1120:
tcp_in.c:1121:      /* Update the congestion control variables (cwnd and
tcp_in.c:1122:         ssthresh). */
tcp_in.c:1123:      if (pcb->state >= ESTABLISHED) {
tcp_in.c:1124:        if (pcb->cwnd < pcb->ssthresh) {
tcp_in.c:1125:          if ((tcpwnd_size_t)(pcb->cwnd + pcb->mss) > pcb->cwnd) {
tcp_in.c:1126:            pcb->cwnd += pcb->mss;
tcp_in.c:1127:          }
tcp_in.c:1128:          LWIP_DEBUGF(TCP_CWND_DEBUG, ("tcp_receive: slow start cwnd %"TCPWNDSIZE_F"\n", pcb->cwnd));
tcp_in.c:1129:        } else {
tcp_in.c:1130:          tcpwnd_size_t new_cwnd = (pcb->cwnd + pcb->mss * pcb->mss / pcb->cwnd);
tcp_in.c:1131:          if (new_cwnd > pcb->cwnd) {
tcp_in.c:1132:            pcb->cwnd = new_cwnd;
tcp_in.c:1133:          }
tcp_in.c:1134:          LWIP_DEBUGF(TCP_CWND_DEBUG, ("tcp_receive: congestion avoidance cwnd %"TCPWNDSIZE_F"\n", pcb->cwnd));
tcp_in.c:1135:        }
tcp_in.c:1136:      }
tcp_in.c:1137:      LWIP_DEBUGF(TCP_INPUT_DEBUG, ("tcp_receive: ACK for %"U32_F", unacked->seqno %"U32_F":%"U32_F"\n",
tcp_in.c:1138:                                    ackno,
tcp_in.c:1139:                                    pcb->unacked != NULL?
tcp_in.c:1140:                                    lwip_ntohl(pcb->unacked->tcphdr->seqno): 0,
tcp_in.c:1141:                                    pcb->unacked != NULL?
tcp_in.c:1142:                                    lwip_ntohl(pcb->unacked->tcphdr->seqno) + TCP_TCPLEN(pcb->unacked): 0));
tcp_in.c:1143:
tcp_in.c:1144:      /* Remove segment from the unacknowledged list if the incoming
tcp_in.c:1145:         ACK acknowledges them. */
tcp_in.c:1146:      while (pcb->unacked != NULL &&
tcp_in.c:1147:             TCP_SEQ_LEQ(lwip_ntohl(pcb->unacked->tcphdr->seqno) +
tcp_in.c:1148:                         TCP_TCPLEN(pcb->unacked), ackno)) {
tcp_in.c:1149:        LWIP_DEBUGF(TCP_INPUT_DEBUG, ("tcp_receive: removing %"U32_F":%"U32_F" from pcb->unacked\n",
tcp_in.c:1150:                                      lwip_ntohl(pcb->unacked->tcphdr->seqno),
tcp_in.c:1151:                                      lwip_ntohl(pcb->unacked->tcphdr->seqno) +
tcp_in.c:1152:                                      TCP_TCPLEN(pcb->unacked)));
tcp_in.c:1153:
tcp_in.c:1154:        next = pcb->unacked;
tcp_in.c:1155:        pcb->unacked = pcb->unacked->next;
tcp_in.c:1156:
tcp_in.c:1157:        LWIP_DEBUGF(TCP_QLEN_DEBUG, ("tcp_receive: queuelen %"TCPWNDSIZE_F" ... ", (tcpwnd_size_t)pcb->snd_queuelen));
tcp_in.c:1158:        LWIP_ASSERT("pcb->snd_queuelen >= pbuf_clen(next->p)", (pcb->snd_queuelen >= pbuf_clen(next->p)));
tcp_in.c:1159:
tcp_in.c:1160:        pcb->snd_queuelen -= pbuf_clen(next->p);
tcp_in.c:1161:        recv_acked += next->len;
tcp_in.c:1162:        tcp_seg_free(next);
tcp_in.c:1163:
tcp_in.c:1164:        LWIP_DEBUGF(TCP_QLEN_DEBUG, ("%"TCPWNDSIZE_F" (after freeing unacked)\n", (tcpwnd_size_t)pcb->snd_queuelen));
tcp_in.c:1165:        if (pcb->snd_queuelen != 0) {
tcp_in.c:1166:          LWIP_ASSERT("tcp_receive: valid queue length", pcb->unacked != NULL ||
tcp_in.c:1167:                      pcb->unsent != NULL);
tcp_in.c:1168:        }
tcp_in.c:1169:      }
tcp_in.c:1170:
tcp_in.c:1171:      /* If there's nothing left to acknowledge, stop the retransmit
tcp_in.c:1172:         timer, otherwise reset it to start again */
tcp_in.c:1173:      if (pcb->unacked == NULL) {
tcp_in.c:1174:        pcb->rtime = -1;
tcp_in.c:1175:      } else {
tcp_in.c:1176:        pcb->rtime = 0;
tcp_in.c:1177:      }
tcp_in.c:1178:
tcp_in.c:1179:      pcb->polltmr = 0;
tcp_in.c:1180:
tcp_in.c:1181:#if LWIP_IPV6 && LWIP_ND6_TCP_REACHABILITY_HINTS
tcp_in.c:1182:      if (ip_current_is_v6()) {
tcp_in.c:1183:        /* Inform neighbor reachability of forward progress. */
tcp_in.c:1184:        nd6_reachability_hint(ip6_current_src_addr());
tcp_in.c:1185:      }
tcp_in.c:1186:#endif /* LWIP_IPV6 && LWIP_ND6_TCP_REACHABILITY_HINTS*/
tcp_in.c:1187:    } else {
tcp_in.c:1188:      /* Out of sequence ACK, didn't really ack anything */
tcp_in.c:1189:      tcp_send_empty_ack(pcb);
tcp_in.c:1190:    }
tcp_in.c:1191:
tcp_in.c:1192:    /* We go through the ->unsent list to see if any of the segments
tcp_in.c:1193:       on the list are acknowledged by the ACK. This may seem
tcp_in.c:1194:       strange since an "unsent" segment shouldn't be acked. The
tcp_in.c:1195:       rationale is that lwIP puts all outstanding segments on the
tcp_in.c:1196:       ->unsent list after a retransmission, so these segments may
tcp_in.c:1197:       in fact have been sent once. */
tcp_in.c:1198:    while (pcb->unsent != NULL &&
tcp_in.c:1199:           TCP_SEQ_BETWEEN(ackno, lwip_ntohl(pcb->unsent->tcphdr->seqno) +
tcp_in.c:1200:                           TCP_TCPLEN(pcb->unsent), pcb->snd_nxt)) {
tcp_in.c:1201:      LWIP_DEBUGF(TCP_INPUT_DEBUG, ("tcp_receive: removing %"U32_F":%"U32_F" from pcb->unsent\n",
tcp_in.c:1202:                                    lwip_ntohl(pcb->unsent->tcphdr->seqno), lwip_ntohl(pcb->unsent->tcphdr->seqno) +
tcp_in.c:1203:                                    TCP_TCPLEN(pcb->unsent)));
tcp_in.c:1204:
tcp_in.c:1205:      next = pcb->unsent;
tcp_in.c:1206:      pcb->unsent = pcb->unsent->next;
tcp_in.c:1207:#if TCP_OVERSIZE
tcp_in.c:1208:      if (pcb->unsent == NULL) {
tcp_in.c:1209:        pcb->unsent_oversize = 0;
tcp_in.c:1210:      }
tcp_in.c:1211:#endif /* TCP_OVERSIZE */
tcp_in.c:1212:      LWIP_DEBUGF(TCP_QLEN_DEBUG, ("tcp_receive: queuelen %"TCPWNDSIZE_F" ... ", (tcpwnd_size_t)pcb->snd_queuelen));
tcp_in.c:1213:      LWIP_ASSERT("pcb->snd_queuelen >= pbuf_clen(next->p)", (pcb->snd_queuelen >= pbuf_clen(next->p)));
tcp_in.c:1214:      /* Prevent ACK for FIN to generate a sent event */
tcp_in.c:1215:      pcb->snd_queuelen -= pbuf_clen(next->p);
tcp_in.c:1216:      recv_acked += next->len;
tcp_in.c:1217:      tcp_seg_free(next);
tcp_in.c:1218:      LWIP_DEBUGF(TCP_QLEN_DEBUG, ("%"TCPWNDSIZE_F" (after freeing unsent)\n", (tcpwnd_size_t)pcb->snd_queuelen));
tcp_in.c:1219:      if (pcb->snd_queuelen != 0) {
tcp_in.c:1220:        LWIP_ASSERT("tcp_receive: valid queue length",
tcp_in.c:1221:          pcb->unacked != NULL || pcb->unsent != NULL);
tcp_in.c:1222:      }
tcp_in.c:1223:    }
tcp_in.c:1224:    pcb->snd_buf += recv_acked;
tcp_in.c:1225:    /* End of ACK for new data processing. */
tcp_in.c:1226:
tcp_in.c:1227:    LWIP_DEBUGF(TCP_RTO_DEBUG, ("tcp_receive: pcb->rttest %"U32_F" rtseq %"U32_F" ackno %"U32_F"\n",
tcp_in.c:1228:                                pcb->rttest, pcb->rtseq, ackno));
tcp_in.c:1229:
tcp_in.c:1230:    /* RTT estimation calculations. This is done by checking if the
tcp_in.c:1231:       incoming segment acknowledges the segment we use to take a
tcp_in.c:1232:       round-trip time measurement. */
tcp_in.c:1233:    if (pcb->rttest && TCP_SEQ_LT(pcb->rtseq, ackno)) {
tcp_in.c:1234:      /* diff between this shouldn't exceed 32K since this are tcp timer ticks
tcp_in.c:1235:         and a round-trip shouldn't be that long... */
tcp_in.c:1236:      m = (s16_t)(tcp_ticks - pcb->rttest);
tcp_in.c:1237:
tcp_in.c:1238:      LWIP_DEBUGF(TCP_RTO_DEBUG, ("tcp_receive: experienced rtt %"U16_F" ticks (%"U16_F" msec).\n",
tcp_in.c:1239:                                  m, (u16_t)(m * TCP_SLOW_INTERVAL)));
tcp_in.c:1240:
tcp_in.c:1241:      /* This is taken directly from VJs original code in his paper */
tcp_in.c:1242:      m = m - (pcb->sa >> 3);
tcp_in.c:1243:      pcb->sa += m;
tcp_in.c:1244:      if (m < 0) {
tcp_in.c:1245:        m = -m;
tcp_in.c:1246:      }
tcp_in.c:1247:      m = m - (pcb->sv >> 2);
tcp_in.c:1248:      pcb->sv += m;
tcp_in.c:1249:      pcb->rto = (pcb->sa >> 3) + pcb->sv;
tcp_in.c:1250:
tcp_in.c:1251:      LWIP_DEBUGF(TCP_RTO_DEBUG, ("tcp_receive: RTO %"U16_F" (%"U16_F" milliseconds)\n",
tcp_in.c:1252:                                  pcb->rto, (u16_t)(pcb->rto * TCP_SLOW_INTERVAL)));
tcp_in.c:1253:
tcp_in.c:1254:      pcb->rttest = 0;
tcp_in.c:1255:    }
tcp_in.c:1256:  }
tcp_in.c:1257:
tcp_in.c:1258:  /* If the incoming segment contains data, we must process it
tcp_in.c:1259:     further unless the pcb already received a FIN.
tcp_in.c:1260:     (RFC 793, chapter 3.9, "SEGMENT ARRIVES" in states CLOSE-WAIT, CLOSING,
tcp_in.c:1261:     LAST-ACK and TIME-WAIT: "Ignore the segment text.") */
tcp_in.c:1262:  if ((tcplen > 0) && (pcb->state < CLOSE_WAIT)) {
tcp_in.c:1263:    /* This code basically does three things:
tcp_in.c:1264:
tcp_in.c:1265:    +) If the incoming segment contains data that is the next
tcp_in.c:1266:    in-sequence data, this data is passed to the application. This
tcp_in.c:1267:    might involve trimming the first edge of the data. The rcv_nxt
tcp_in.c:1268:    variable and the advertised window are adjusted.
tcp_in.c:1269:
tcp_in.c:1270:    +) If the incoming segment has data that is above the next
tcp_in.c:1271:    sequence number expected (->rcv_nxt), the segment is placed on
tcp_in.c:1272:    the ->ooseq queue. This is done by finding the appropriate
tcp_in.c:1273:    place in the ->ooseq queue (which is ordered by sequence
tcp_in.c:1274:    number) and trim the segment in both ends if needed. An
tcp_in.c:1275:    immediate ACK is sent to indicate that we received an
tcp_in.c:1276:    out-of-sequence segment.
tcp_in.c:1277:
tcp_in.c:1278:    +) Finally, we check if the first segment on the ->ooseq queue
tcp_in.c:1279:    now is in sequence (i.e., if rcv_nxt >= ooseq->seqno). If
tcp_in.c:1280:    rcv_nxt > ooseq->seqno, we must trim the first edge of the
tcp_in.c:1281:    segment on ->ooseq before we adjust rcv_nxt. The data in the
tcp_in.c:1282:    segments that are now on sequence are chained onto the
tcp_in.c:1283:    incoming segment so that we only need to call the application
tcp_in.c:1284:    once.
tcp_in.c:1285:    */
tcp_in.c:1286:
tcp_in.c:1287:    /* First, we check if we must trim the first edge. We have to do
tcp_in.c:1288:       this if the sequence number of the incoming segment is less
tcp_in.c:1289:       than rcv_nxt, and the sequence number plus the length of the
tcp_in.c:1290:       segment is larger than rcv_nxt. */
tcp_in.c:1291:    /*    if (TCP_SEQ_LT(seqno, pcb->rcv_nxt)) {
tcp_in.c:1292:          if (TCP_SEQ_LT(pcb->rcv_nxt, seqno + tcplen)) {*/
tcp_in.c:1293:    if (TCP_SEQ_BETWEEN(pcb->rcv_nxt, seqno + 1, seqno + tcplen - 1)) {
tcp_in.c:1294:      /* Trimming the first edge is done by pushing the payload
tcp_in.c:1295:         pointer in the pbuf downwards. This is somewhat tricky since
tcp_in.c:1296:         we do not want to discard the full contents of the pbuf up to
tcp_in.c:1297:         the new starting point of the data since we have to keep the
tcp_in.c:1298:         TCP header which is present in the first pbuf in the chain.
tcp_in.c:1299:
tcp_in.c:1300:         What is done is really quite a nasty hack: the first pbuf in
tcp_in.c:1301:         the pbuf chain is pointed to by inseg.p. Since we need to be
tcp_in.c:1302:         able to deallocate the whole pbuf, we cannot change this
tcp_in.c:1303:         inseg.p pointer to point to any of the later pbufs in the
tcp_in.c:1304:         chain. Instead, we point the ->payload pointer in the first
tcp_in.c:1305:         pbuf to data in one of the later pbufs. We also set the
tcp_in.c:1306:         inseg.data pointer to point to the right place. This way, the
tcp_in.c:1307:         ->p pointer will still point to the first pbuf, but the
tcp_in.c:1308:         ->p->payload pointer will point to data in another pbuf.
tcp_in.c:1309:
tcp_in.c:1310:         After we are done with adjusting the pbuf pointers we must
tcp_in.c:1311:         adjust the ->data pointer in the seg and the segment
tcp_in.c:1312:         length.*/
tcp_in.c:1313:
tcp_in.c:1314:      struct pbuf *p = inseg.p;
tcp_in.c:1315:      off = pcb->rcv_nxt - seqno;
tcp_in.c:1316:      LWIP_ASSERT("inseg.p != NULL", inseg.p);
tcp_in.c:1317:      LWIP_ASSERT("insane offset!", (off < 0x7fff));
tcp_in.c:1318:      if (inseg.p->len < off) {
tcp_in.c:1319:        LWIP_ASSERT("pbuf too short!", (((s32_t)inseg.p->tot_len) >= off));
tcp_in.c:1320:        new_tot_len = (u16_t)(inseg.p->tot_len - off);
tcp_in.c:1321:        while (p->len < off) {
tcp_in.c:1322:          off -= p->len;
tcp_in.c:1323:          /* KJM following line changed (with addition of new_tot_len var)
tcp_in.c:1324:             to fix bug #9076
tcp_in.c:1325:             inseg.p->tot_len -= p->len; */
tcp_in.c:1326:          p->tot_len = new_tot_len;
tcp_in.c:1327:          p->len = 0;
tcp_in.c:1328:          p = p->next;
tcp_in.c:1329:        }
tcp_in.c:1330:        if (pbuf_header(p, (s16_t)-off)) {
tcp_in.c:1331:          /* Do we need to cope with this failing?  Assert for now */
tcp_in.c:1332:          LWIP_ASSERT("pbuf_header failed", 0);
tcp_in.c:1333:        }
tcp_in.c:1334:      } else {
tcp_in.c:1335:        if (pbuf_header(inseg.p, (s16_t)-off)) {
tcp_in.c:1336:          /* Do we need to cope with this failing?  Assert for now */
tcp_in.c:1337:          LWIP_ASSERT("pbuf_header failed", 0);
tcp_in.c:1338:        }
tcp_in.c:1339:      }
tcp_in.c:1340:      inseg.len -= (u16_t)(pcb->rcv_nxt - seqno);
tcp_in.c:1341:      inseg.tcphdr->seqno = seqno = pcb->rcv_nxt;
tcp_in.c:1342:    }
tcp_in.c:1343:    else {
tcp_in.c:1344:      if (TCP_SEQ_LT(seqno, pcb->rcv_nxt)) {
tcp_in.c:1345:        /* the whole segment is < rcv_nxt */
tcp_in.c:1346:        /* must be a duplicate of a packet that has already been correctly handled */
tcp_in.c:1347:
tcp_in.c:1348:        LWIP_DEBUGF(TCP_INPUT_DEBUG, ("tcp_receive: duplicate seqno %"U32_F"\n", seqno));
tcp_in.c:1349:        tcp_ack_now(pcb);
tcp_in.c:1350:      }
tcp_in.c:1351:    }
tcp_in.c:1352:
tcp_in.c:1353:    /* The sequence number must be within the window (above rcv_nxt
tcp_in.c:1354:       and below rcv_nxt + rcv_wnd) in order to be further
tcp_in.c:1355:       processed. */
tcp_in.c:1356:    if (TCP_SEQ_BETWEEN(seqno, pcb->rcv_nxt,
tcp_in.c:1357:                        pcb->rcv_nxt + pcb->rcv_wnd - 1)) {
tcp_in.c:1358:      if (pcb->rcv_nxt == seqno) {
tcp_in.c:1359:        /* The incoming segment is the next in sequence. We check if
tcp_in.c:1360:           we have to trim the end of the segment and update rcv_nxt
tcp_in.c:1361:           and pass the data to the application. */
tcp_in.c:1362:        tcplen = TCP_TCPLEN(&inseg);
tcp_in.c:1363:
tcp_in.c:1364:        if (tcplen > pcb->rcv_wnd) {
tcp_in.c:1365:          LWIP_DEBUGF(TCP_INPUT_DEBUG,
tcp_in.c:1366:                      ("tcp_receive: other end overran receive window"
tcp_in.c:1367:                       "seqno %"U32_F" len %"U16_F" right edge %"U32_F"\n",
tcp_in.c:1368:                       seqno, tcplen, pcb->rcv_nxt + pcb->rcv_wnd));
tcp_in.c:1369:          if (TCPH_FLAGS(inseg.tcphdr) & TCP_FIN) {
tcp_in.c:1370:            /* Must remove the FIN from the header as we're trimming
tcp_in.c:1371:             * that byte of sequence-space from the packet */
tcp_in.c:1372:            TCPH_FLAGS_SET(inseg.tcphdr, TCPH_FLAGS(inseg.tcphdr) & ~(unsigned int)TCP_FIN);
tcp_in.c:1373:          }
tcp_in.c:1374:          /* Adjust length of segment to fit in the window. */
tcp_in.c:1375:          TCPWND_CHECK16(pcb->rcv_wnd);
tcp_in.c:1376:          inseg.len = (u16_t)pcb->rcv_wnd;
tcp_in.c:1377:          if (TCPH_FLAGS(inseg.tcphdr) & TCP_SYN) {
tcp_in.c:1378:            inseg.len -= 1;
tcp_in.c:1379:          }
tcp_in.c:1380:          pbuf_realloc(inseg.p, inseg.len);
tcp_in.c:1381:          tcplen = TCP_TCPLEN(&inseg);
tcp_in.c:1382:          LWIP_ASSERT("tcp_receive: segment not trimmed correctly to rcv_wnd\n",
tcp_in.c:1383:                      (seqno + tcplen) == (pcb->rcv_nxt + pcb->rcv_wnd));
tcp_in.c:1384:        }
tcp_in.c:1385:#if TCP_QUEUE_OOSEQ
tcp_in.c:1386:        /* Received in-sequence data, adjust ooseq data if:
tcp_in.c:1387:           - FIN has been received or
tcp_in.c:1388:           - inseq overlaps with ooseq */
tcp_in.c:1389:        if (pcb->ooseq != NULL) {
tcp_in.c:1390:          if (TCPH_FLAGS(inseg.tcphdr) & TCP_FIN) {
tcp_in.c:1391:            LWIP_DEBUGF(TCP_INPUT_DEBUG,
tcp_in.c:1392:                        ("tcp_receive: received in-order FIN, binning ooseq queue\n"));
tcp_in.c:1393:            /* Received in-order FIN means anything that was received
tcp_in.c:1394:             * out of order must now have been received in-order, so
tcp_in.c:1395:             * bin the ooseq queue */
tcp_in.c:1396:            while (pcb->ooseq != NULL) {
tcp_in.c:1397:              struct tcp_seg *old_ooseq = pcb->ooseq;
tcp_in.c:1398:              pcb->ooseq = pcb->ooseq->next;
tcp_in.c:1399:              tcp_seg_free(old_ooseq);
tcp_in.c:1400:            }
tcp_in.c:1401:          } else {
tcp_in.c:1402:            next = pcb->ooseq;
tcp_in.c:1403:            /* Remove all segments on ooseq that are covered by inseg already.
tcp_in.c:1404:             * FIN is copied from ooseq to inseg if present. */
tcp_in.c:1405:            while (next &&
tcp_in.c:1406:                   TCP_SEQ_GEQ(seqno + tcplen,
tcp_in.c:1407:                               next->tcphdr->seqno + next->len)) {
tcp_in.c:1408:              /* inseg cannot have FIN here (already processed above) */
tcp_in.c:1409:              if (TCPH_FLAGS(next->tcphdr) & TCP_FIN &&
tcp_in.c:1410:                  (TCPH_FLAGS(inseg.tcphdr) & TCP_SYN) == 0) {
tcp_in.c:1411:                TCPH_SET_FLAG(inseg.tcphdr, TCP_FIN);
tcp_in.c:1412:                tcplen = TCP_TCPLEN(&inseg);
tcp_in.c:1413:              }
tcp_in.c:1414:              prev = next;
tcp_in.c:1415:              next = next->next;
tcp_in.c:1416:              tcp_seg_free(prev);
tcp_in.c:1417:            }
tcp_in.c:1418:            /* Now trim right side of inseg if it overlaps with the first
tcp_in.c:1419:             * segment on ooseq */
tcp_in.c:1420:            if (next &&
tcp_in.c:1421:                TCP_SEQ_GT(seqno + tcplen,
tcp_in.c:1422:                           next->tcphdr->seqno)) {
tcp_in.c:1423:              /* inseg cannot have FIN here (already processed above) */
tcp_in.c:1424:              inseg.len = (u16_t)(next->tcphdr->seqno - seqno);
tcp_in.c:1425:              if (TCPH_FLAGS(inseg.tcphdr) & TCP_SYN) {
tcp_in.c:1426:                inseg.len -= 1;
tcp_in.c:1427:              }
tcp_in.c:1428:              pbuf_realloc(inseg.p, inseg.len);
tcp_in.c:1429:              tcplen = TCP_TCPLEN(&inseg);
tcp_in.c:1430:              LWIP_ASSERT("tcp_receive: segment not trimmed correctly to ooseq queue\n",
tcp_in.c:1431:                          (seqno + tcplen) == next->tcphdr->seqno);
tcp_in.c:1432:            }
tcp_in.c:1433:            pcb->ooseq = next;
tcp_in.c:1434:          }
tcp_in.c:1435:        }
tcp_in.c:1436:#endif /* TCP_QUEUE_OOSEQ */
tcp_in.c:1437:
tcp_in.c:1438:        pcb->rcv_nxt = seqno + tcplen;
tcp_in.c:1439:
tcp_in.c:1440:        /* Update the receiver's (our) window. */
tcp_in.c:1441:        LWIP_ASSERT("tcp_receive: tcplen > rcv_wnd\n", pcb->rcv_wnd >= tcplen);
tcp_in.c:1442:        pcb->rcv_wnd -= tcplen;
tcp_in.c:1443:
tcp_in.c:1444:        tcp_update_rcv_ann_wnd(pcb);
tcp_in.c:1445:
tcp_in.c:1446:        /* If there is data in the segment, we make preparations to
tcp_in.c:1447:           pass this up to the application. The ->recv_data variable
tcp_in.c:1448:           is used for holding the pbuf that goes to the
tcp_in.c:1449:           application. The code for reassembling out-of-sequence data
tcp_in.c:1450:           chains its data on this pbuf as well.
tcp_in.c:1451:
tcp_in.c:1452:           If the segment was a FIN, we set the TF_GOT_FIN flag that will
tcp_in.c:1453:           be used to indicate to the application that the remote side has
tcp_in.c:1454:           closed its end of the connection. */
tcp_in.c:1455:        if (inseg.p->tot_len > 0) {
tcp_in.c:1456:          recv_data = inseg.p;
tcp_in.c:1457:          /* Since this pbuf now is the responsibility of the
tcp_in.c:1458:             application, we delete our reference to it so that we won't
tcp_in.c:1459:             (mistakingly) deallocate it. */
tcp_in.c:1460:          inseg.p = NULL;
tcp_in.c:1461:        }
tcp_in.c:1462:        if (TCPH_FLAGS(inseg.tcphdr) & TCP_FIN) {
tcp_in.c:1463:          LWIP_DEBUGF(TCP_INPUT_DEBUG, ("tcp_receive: received FIN.\n"));
tcp_in.c:1464:          recv_flags |= TF_GOT_FIN;
tcp_in.c:1465:        }
tcp_in.c:1466:
tcp_in.c:1467:#if TCP_QUEUE_OOSEQ
tcp_in.c:1468:        /* We now check if we have segments on the ->ooseq queue that
tcp_in.c:1469:           are now in sequence. */
tcp_in.c:1470:        while (pcb->ooseq != NULL &&
tcp_in.c:1471:               pcb->ooseq->tcphdr->seqno == pcb->rcv_nxt) {
tcp_in.c:1472:
tcp_in.c:1473:          cseg = pcb->ooseq;
tcp_in.c:1474:          seqno = pcb->ooseq->tcphdr->seqno;
tcp_in.c:1475:
tcp_in.c:1476:          pcb->rcv_nxt += TCP_TCPLEN(cseg);
tcp_in.c:1477:          LWIP_ASSERT("tcp_receive: ooseq tcplen > rcv_wnd\n",
tcp_in.c:1478:                      pcb->rcv_wnd >= TCP_TCPLEN(cseg));
tcp_in.c:1479:          pcb->rcv_wnd -= TCP_TCPLEN(cseg);
tcp_in.c:1480:
tcp_in.c:1481:          tcp_update_rcv_ann_wnd(pcb);
tcp_in.c:1482:
tcp_in.c:1483:          if (cseg->p->tot_len > 0) {
tcp_in.c:1484:            /* Chain this pbuf onto the pbuf that we will pass to
tcp_in.c:1485:               the application. */
tcp_in.c:1486:            /* With window scaling, this can overflow recv_data->tot_len, but
tcp_in.c:1487:               that's not a problem since we explicitly fix that before passing
tcp_in.c:1488:               recv_data to the application. */
tcp_in.c:1489:            if (recv_data) {
tcp_in.c:1490:              pbuf_cat(recv_data, cseg->p);
tcp_in.c:1491:            } else {
tcp_in.c:1492:              recv_data = cseg->p;
tcp_in.c:1493:            }
tcp_in.c:1494:            cseg->p = NULL;
tcp_in.c:1495:          }
tcp_in.c:1496:          if (TCPH_FLAGS(cseg->tcphdr) & TCP_FIN) {
tcp_in.c:1497:            LWIP_DEBUGF(TCP_INPUT_DEBUG, ("tcp_receive: dequeued FIN.\n"));
tcp_in.c:1498:            recv_flags |= TF_GOT_FIN;
tcp_in.c:1499:            if (pcb->state == ESTABLISHED) { /* force passive close or we can move to active close */
tcp_in.c:1500:              pcb->state = CLOSE_WAIT;
tcp_in.c:1501:            }
tcp_in.c:1502:          }
tcp_in.c:1503:
tcp_in.c:1504:          pcb->ooseq = cseg->next;
tcp_in.c:1505:          tcp_seg_free(cseg);
tcp_in.c:1506:        }
tcp_in.c:1507:#endif /* TCP_QUEUE_OOSEQ */
tcp_in.c:1508:
tcp_in.c:1509:
tcp_in.c:1510:        /* Acknowledge the segment(s). */
tcp_in.c:1511:        tcp_ack(pcb);
tcp_in.c:1512:
tcp_in.c:1513:#if LWIP_IPV6 && LWIP_ND6_TCP_REACHABILITY_HINTS
tcp_in.c:1514:        if (ip_current_is_v6()) {
tcp_in.c:1515:          /* Inform neighbor reachability of forward progress. */
tcp_in.c:1516:          nd6_reachability_hint(ip6_current_src_addr());
tcp_in.c:1517:        }
tcp_in.c:1518:#endif /* LWIP_IPV6 && LWIP_ND6_TCP_REACHABILITY_HINTS*/
tcp_in.c:1519:
tcp_in.c:1520:      } else {
tcp_in.c:1521:        /* We get here if the incoming segment is out-of-sequence. */
tcp_in.c:1522:        tcp_send_empty_ack(pcb);
tcp_in.c:1523:#if TCP_QUEUE_OOSEQ
tcp_in.c:1524:        /* We queue the segment on the ->ooseq queue. */
tcp_in.c:1525:        if (pcb->ooseq == NULL) {
tcp_in.c:1526:          pcb->ooseq = tcp_seg_copy(&inseg);
tcp_in.c:1527:        } else {
tcp_in.c:1528:          /* If the queue is not empty, we walk through the queue and
tcp_in.c:1529:             try to find a place where the sequence number of the
tcp_in.c:1530:             incoming segment is between the sequence numbers of the
tcp_in.c:1531:             previous and the next segment on the ->ooseq queue. That is
tcp_in.c:1532:             the place where we put the incoming segment. If needed, we
tcp_in.c:1533:             trim the second edges of the previous and the incoming
tcp_in.c:1534:             segment so that it will fit into the sequence.
tcp_in.c:1535:
tcp_in.c:1536:             If the incoming segment has the same sequence number as a
tcp_in.c:1537:             segment on the ->ooseq queue, we discard the segment that
tcp_in.c:1538:             contains less data. */
tcp_in.c:1539:
tcp_in.c:1540:          prev = NULL;
tcp_in.c:1541:          for (next = pcb->ooseq; next != NULL; next = next->next) {
tcp_in.c:1542:            if (seqno == next->tcphdr->seqno) {
tcp_in.c:1543:              /* The sequence number of the incoming segment is the
tcp_in.c:1544:                 same as the sequence number of the segment on
tcp_in.c:1545:                 ->ooseq. We check the lengths to see which one to
tcp_in.c:1546:                 discard. */
tcp_in.c:1547:              if (inseg.len > next->len) {
tcp_in.c:1548:                /* The incoming segment is larger than the old
tcp_in.c:1549:                   segment. We replace some segments with the new
tcp_in.c:1550:                   one. */
tcp_in.c:1551:                cseg = tcp_seg_copy(&inseg);
tcp_in.c:1552:                if (cseg != NULL) {
tcp_in.c:1553:                  if (prev != NULL) {
tcp_in.c:1554:                    prev->next = cseg;
tcp_in.c:1555:                  } else {
tcp_in.c:1556:                    pcb->ooseq = cseg;
tcp_in.c:1557:                  }
tcp_in.c:1558:                  tcp_oos_insert_segment(cseg, next);
tcp_in.c:1559:                }
tcp_in.c:1560:                break;
tcp_in.c:1561:              } else {
tcp_in.c:1562:                /* Either the lengths are the same or the incoming
tcp_in.c:1563:                   segment was smaller than the old one; in either
tcp_in.c:1564:                   case, we ditch the incoming segment. */
tcp_in.c:1565:                break;
tcp_in.c:1566:              }
tcp_in.c:1567:            } else {
tcp_in.c:1568:              if (prev == NULL) {
tcp_in.c:1569:                if (TCP_SEQ_LT(seqno, next->tcphdr->seqno)) {
tcp_in.c:1570:                  /* The sequence number of the incoming segment is lower
tcp_in.c:1571:                     than the sequence number of the first segment on the
tcp_in.c:1572:                     queue. We put the incoming segment first on the
tcp_in.c:1573:                     queue. */
tcp_in.c:1574:                  cseg = tcp_seg_copy(&inseg);
tcp_in.c:1575:                  if (cseg != NULL) {
tcp_in.c:1576:                    pcb->ooseq = cseg;
tcp_in.c:1577:                    tcp_oos_insert_segment(cseg, next);
tcp_in.c:1578:                  }
tcp_in.c:1579:                  break;
tcp_in.c:1580:                }
tcp_in.c:1581:              } else {
tcp_in.c:1582:                /*if (TCP_SEQ_LT(prev->tcphdr->seqno, seqno) &&
tcp_in.c:1583:                  TCP_SEQ_LT(seqno, next->tcphdr->seqno)) {*/
tcp_in.c:1584:                if (TCP_SEQ_BETWEEN(seqno, prev->tcphdr->seqno+1, next->tcphdr->seqno-1)) {
tcp_in.c:1585:                  /* The sequence number of the incoming segment is in
tcp_in.c:1586:                     between the sequence numbers of the previous and
tcp_in.c:1587:                     the next segment on ->ooseq. We trim trim the previous
tcp_in.c:1588:                     segment, delete next segments that included in received segment
tcp_in.c:1589:                     and trim received, if needed. */
tcp_in.c:1590:                  cseg = tcp_seg_copy(&inseg);
tcp_in.c:1591:                  if (cseg != NULL) {
tcp_in.c:1592:                    if (TCP_SEQ_GT(prev->tcphdr->seqno + prev->len, seqno)) {
tcp_in.c:1593:                      /* We need to trim the prev segment. */
tcp_in.c:1594:                      prev->len = (u16_t)(seqno - prev->tcphdr->seqno);
tcp_in.c:1595:                      pbuf_realloc(prev->p, prev->len);
tcp_in.c:1596:                    }
tcp_in.c:1597:                    prev->next = cseg;
tcp_in.c:1598:                    tcp_oos_insert_segment(cseg, next);
tcp_in.c:1599:                  }
tcp_in.c:1600:                  break;
tcp_in.c:1601:                }
tcp_in.c:1602:              }
tcp_in.c:1603:              /* If the "next" segment is the last segment on the
tcp_in.c:1604:                 ooseq queue, we add the incoming segment to the end
tcp_in.c:1605:                 of the list. */
tcp_in.c:1606:              if (next->next == NULL &&
tcp_in.c:1607:                  TCP_SEQ_GT(seqno, next->tcphdr->seqno)) {
tcp_in.c:1608:                if (TCPH_FLAGS(next->tcphdr) & TCP_FIN) {
tcp_in.c:1609:                  /* segment "next" already contains all data */
tcp_in.c:1610:                  break;
tcp_in.c:1611:                }
tcp_in.c:1612:                next->next = tcp_seg_copy(&inseg);
tcp_in.c:1613:                if (next->next != NULL) {
tcp_in.c:1614:                  if (TCP_SEQ_GT(next->tcphdr->seqno + next->len, seqno)) {
tcp_in.c:1615:                    /* We need to trim the last segment. */
tcp_in.c:1616:                    next->len = (u16_t)(seqno - next->tcphdr->seqno);
tcp_in.c:1617:                    pbuf_realloc(next->p, next->len);
tcp_in.c:1618:                  }
tcp_in.c:1619:                  /* check if the remote side overruns our receive window */
tcp_in.c:1620:                  if (TCP_SEQ_GT((u32_t)tcplen + seqno, pcb->rcv_nxt + (u32_t)pcb->rcv_wnd)) {
tcp_in.c:1621:                    LWIP_DEBUGF(TCP_INPUT_DEBUG,
tcp_in.c:1622:                                ("tcp_receive: other end overran receive window"
tcp_in.c:1623:                                 "seqno %"U32_F" len %"U16_F" right edge %"U32_F"\n",
tcp_in.c:1624:                                 seqno, tcplen, pcb->rcv_nxt + pcb->rcv_wnd));
tcp_in.c:1625:                    if (TCPH_FLAGS(next->next->tcphdr) & TCP_FIN) {
tcp_in.c:1626:                      /* Must remove the FIN from the header as we're trimming
tcp_in.c:1627:                       * that byte of sequence-space from the packet */
tcp_in.c:1628:                      TCPH_FLAGS_SET(next->next->tcphdr, TCPH_FLAGS(next->next->tcphdr) & ~TCP_FIN);
tcp_in.c:1629:                    }
tcp_in.c:1630:                    /* Adjust length of segment to fit in the window. */
tcp_in.c:1631:                    next->next->len = (u16_t)(pcb->rcv_nxt + pcb->rcv_wnd - seqno);
tcp_in.c:1632:                    pbuf_realloc(next->next->p, next->next->len);
tcp_in.c:1633:                    tcplen = TCP_TCPLEN(next->next);
tcp_in.c:1634:                    LWIP_ASSERT("tcp_receive: segment not trimmed correctly to rcv_wnd\n",
tcp_in.c:1635:                                (seqno + tcplen) == (pcb->rcv_nxt + pcb->rcv_wnd));
tcp_in.c:1636:                  }
tcp_in.c:1637:                }
tcp_in.c:1638:                break;
tcp_in.c:1639:              }
tcp_in.c:1640:            }
tcp_in.c:1641:            prev = next;
tcp_in.c:1642:          }
tcp_in.c:1643:        }
tcp_in.c:1644:#if TCP_OOSEQ_MAX_BYTES || TCP_OOSEQ_MAX_PBUFS
tcp_in.c:1645:        /* Check that the data on ooseq doesn't exceed one of the limits
tcp_in.c:1646:           and throw away everything above that limit. */
tcp_in.c:1647:        ooseq_blen = 0;
tcp_in.c:1648:        ooseq_qlen = 0;
tcp_in.c:1649:        prev = NULL;
tcp_in.c:1650:        for (next = pcb->ooseq; next != NULL; prev = next, next = next->next) {
tcp_in.c:1651:          struct pbuf *p = next->p;
tcp_in.c:1652:          ooseq_blen += p->tot_len;
tcp_in.c:1653:          ooseq_qlen += pbuf_clen(p);
tcp_in.c:1654:          if ((ooseq_blen > TCP_OOSEQ_MAX_BYTES) ||
tcp_in.c:1655:              (ooseq_qlen > TCP_OOSEQ_MAX_PBUFS)) {
tcp_in.c:1656:             /* too much ooseq data, dump this and everything after it */
tcp_in.c:1657:             tcp_segs_free(next);
tcp_in.c:1658:             if (prev == NULL) {
tcp_in.c:1659:               /* first ooseq segment is too much, dump the whole queue */
tcp_in.c:1660:               pcb->ooseq = NULL;
tcp_in.c:1661:             } else {
tcp_in.c:1662:               /* just dump 'next' and everything after it */
tcp_in.c:1663:               prev->next = NULL;
tcp_in.c:1664:             }
tcp_in.c:1665:             break;
tcp_in.c:1666:          }
tcp_in.c:1667:        }
tcp_in.c:1668:#endif /* TCP_OOSEQ_MAX_BYTES || TCP_OOSEQ_MAX_PBUFS */
tcp_in.c:1669:#endif /* TCP_QUEUE_OOSEQ */
tcp_in.c:1670:      }
tcp_in.c:1671:    } else {
tcp_in.c:1672:      /* The incoming segment is not within the window. */
tcp_in.c:1673:      tcp_send_empty_ack(pcb);
tcp_in.c:1674:    }
tcp_in.c:1675:  } else {
tcp_in.c:1676:    /* Segments with length 0 is taken care of here. Segments that
tcp_in.c:1677:       fall out of the window are ACKed. */
tcp_in.c:1678:    if (!TCP_SEQ_BETWEEN(seqno, pcb->rcv_nxt, pcb->rcv_nxt + pcb->rcv_wnd - 1)) {
tcp_in.c:1679:      tcp_ack_now(pcb);
tcp_in.c:1680:    }
tcp_in.c:1681:  }
tcp_in.c:1682:}
tcp_in.c:1683:
tcp_in.c:1684:static u8_t
tcp_in.c:1685:tcp_getoptbyte(void)
tcp_in.c:1686:{
tcp_in.c:1687:  if ((tcphdr_opt2 == NULL) || (tcp_optidx < tcphdr_opt1len)) {
tcp_in.c:1688:    u8_t* opts = (u8_t *)tcphdr + TCP_HLEN;
tcp_in.c:1689:    return opts[tcp_optidx++];
tcp_in.c:1690:  } else {
tcp_in.c:1691:    u8_t idx = (u8_t)(tcp_optidx++ - tcphdr_opt1len);
tcp_in.c:1692:    return tcphdr_opt2[idx];
tcp_in.c:1693:  }
tcp_in.c:1694:}
tcp_in.c:1695:
tcp_in.c:1696:/**
tcp_in.c:1697: * Parses the options contained in the incoming segment.
tcp_in.c:1698: *
tcp_in.c:1699: * Called from tcp_listen_input() and tcp_process().
tcp_in.c:1700: * Currently, only the MSS option is supported!
tcp_in.c:1701: *
tcp_in.c:1702: * @param pcb the tcp_pcb for which a segment arrived
tcp_in.c:1703: */
tcp_in.c:1704:static void
tcp_in.c:1705:tcp_parseopt(struct tcp_pcb *pcb)
tcp_in.c:1706:{
tcp_in.c:1707:  u8_t data;
tcp_in.c:1708:  u16_t mss;
tcp_in.c:1709:#if LWIP_TCP_TIMESTAMPS
tcp_in.c:1710:  u32_t tsval;
tcp_in.c:1711:#endif
tcp_in.c:1712:
tcp_in.c:1713:  /* Parse the TCP MSS option, if present. */
tcp_in.c:1714:  if (tcphdr_optlen != 0) {
tcp_in.c:1715:    for (tcp_optidx = 0; tcp_optidx < tcphdr_optlen; ) {
tcp_in.c:1716:      u8_t opt = tcp_getoptbyte();
tcp_in.c:1717:      switch (opt) {
tcp_in.c:1718:      case LWIP_TCP_OPT_EOL:
tcp_in.c:1719:        /* End of options. */
tcp_in.c:1720:        LWIP_DEBUGF(TCP_INPUT_DEBUG, ("tcp_parseopt: EOL\n"));
tcp_in.c:1721:        return;
tcp_in.c:1722:      case LWIP_TCP_OPT_NOP:
tcp_in.c:1723:        /* NOP option. */
tcp_in.c:1724:        LWIP_DEBUGF(TCP_INPUT_DEBUG, ("tcp_parseopt: NOP\n"));
tcp_in.c:1725:        break;
tcp_in.c:1726:      case LWIP_TCP_OPT_MSS:
tcp_in.c:1727:        LWIP_DEBUGF(TCP_INPUT_DEBUG, ("tcp_parseopt: MSS\n"));
tcp_in.c:1728:        if (tcp_getoptbyte() != LWIP_TCP_OPT_LEN_MSS || (tcp_optidx - 2 + LWIP_TCP_OPT_LEN_MSS) > tcphdr_optlen) {
tcp_in.c:1729:          /* Bad length */
tcp_in.c:1730:          LWIP_DEBUGF(TCP_INPUT_DEBUG, ("tcp_parseopt: bad length\n"));
tcp_in.c:1731:          return;
tcp_in.c:1732:        }
tcp_in.c:1733:        /* An MSS option with the right option length. */
tcp_in.c:1734:        mss = (tcp_getoptbyte() << 8);
tcp_in.c:1735:        mss |= tcp_getoptbyte();
tcp_in.c:1736:        /* Limit the mss to the configured TCP_MSS and prevent division by zero */
tcp_in.c:1737:        pcb->mss = ((mss > TCP_MSS) || (mss == 0)) ? TCP_MSS : mss;
tcp_in.c:1738:        break;
tcp_in.c:1739:#if LWIP_WND_SCALE
tcp_in.c:1740:      case LWIP_TCP_OPT_WS:
tcp_in.c:1741:        LWIP_DEBUGF(TCP_INPUT_DEBUG, ("tcp_parseopt: WND_SCALE\n"));
tcp_in.c:1742:        if (tcp_getoptbyte() != LWIP_TCP_OPT_LEN_WS || (tcp_optidx - 2 + LWIP_TCP_OPT_LEN_WS) > tcphdr_optlen) {
tcp_in.c:1743:          /* Bad length */
tcp_in.c:1744:          LWIP_DEBUGF(TCP_INPUT_DEBUG, ("tcp_parseopt: bad length\n"));
tcp_in.c:1745:          return;
tcp_in.c:1746:        }
tcp_in.c:1747:        /* If syn was received with wnd scale option,
tcp_in.c:1748:           activate wnd scale opt, but only if this is not a retransmission */
tcp_in.c:1749:        if ((flags & TCP_SYN) && !(pcb->flags & TF_WND_SCALE)) {
tcp_in.c:1750:          /* An WND_SCALE option with the right option length. */
tcp_in.c:1751:          data = tcp_getoptbyte();
tcp_in.c:1752:          pcb->snd_scale = data;
tcp_in.c:1753:          if (pcb->snd_scale > 14U) {
tcp_in.c:1754:            pcb->snd_scale = 14U;
tcp_in.c:1755:          }
tcp_in.c:1756:          pcb->rcv_scale = TCP_RCV_SCALE;
tcp_in.c:1757:          pcb->flags |= TF_WND_SCALE;
tcp_in.c:1758:          /* window scaling is enabled, we can use the full receive window */
tcp_in.c:1759:          LWIP_ASSERT("window not at default value", pcb->rcv_wnd == TCPWND_MIN16(TCP_WND));
tcp_in.c:1760:          LWIP_ASSERT("window not at default value", pcb->rcv_ann_wnd == TCPWND_MIN16(TCP_WND));
tcp_in.c:1761:          pcb->rcv_wnd = pcb->rcv_ann_wnd = TCP_WND;
tcp_in.c:1762:        }
tcp_in.c:1763:        break;
tcp_in.c:1764:#endif
tcp_in.c:1765:#if LWIP_TCP_TIMESTAMPS
tcp_in.c:1766:      case LWIP_TCP_OPT_TS:
tcp_in.c:1767:        LWIP_DEBUGF(TCP_INPUT_DEBUG, ("tcp_parseopt: TS\n"));
tcp_in.c:1768:        if (tcp_getoptbyte() != LWIP_TCP_OPT_LEN_TS || (tcp_optidx - 2 + LWIP_TCP_OPT_LEN_TS) > tcphdr_optlen) {
tcp_in.c:1769:          /* Bad length */
tcp_in.c:1770:          LWIP_DEBUGF(TCP_INPUT_DEBUG, ("tcp_parseopt: bad length\n"));
tcp_in.c:1771:          return;
tcp_in.c:1772:        }
tcp_in.c:1773:        /* TCP timestamp option with valid length */
tcp_in.c:1774:        tsval = tcp_getoptbyte();
tcp_in.c:1775:        tsval |= (tcp_getoptbyte() << 8);
tcp_in.c:1776:        tsval |= (tcp_getoptbyte() << 16);
tcp_in.c:1777:        tsval |= (tcp_getoptbyte() << 24);
tcp_in.c:1778:        if (flags & TCP_SYN) {
tcp_in.c:1779:          pcb->ts_recent = lwip_ntohl(tsval);
tcp_in.c:1780:          /* Enable sending timestamps in every segment now that we know
tcp_in.c:1781:             the remote host supports it. */
tcp_in.c:1782:          pcb->flags |= TF_TIMESTAMP;
tcp_in.c:1783:        } else if (TCP_SEQ_BETWEEN(pcb->ts_lastacksent, seqno, seqno+tcplen)) {
tcp_in.c:1784:          pcb->ts_recent = lwip_ntohl(tsval);
tcp_in.c:1785:        }
tcp_in.c:1786:        /* Advance to next option (6 bytes already read) */
tcp_in.c:1787:        tcp_optidx += LWIP_TCP_OPT_LEN_TS - 6;
tcp_in.c:1788:        break;
tcp_in.c:1789:#endif
tcp_in.c:1790:      default:
tcp_in.c:1791:        LWIP_DEBUGF(TCP_INPUT_DEBUG, ("tcp_parseopt: other\n"));
tcp_in.c:1792:        data = tcp_getoptbyte();
tcp_in.c:1793:        if (data < 2) {
tcp_in.c:1794:          LWIP_DEBUGF(TCP_INPUT_DEBUG, ("tcp_parseopt: bad length\n"));
tcp_in.c:1795:          /* If the length field is zero, the options are malformed
tcp_in.c:1796:             and we don't process them further. */
tcp_in.c:1797:          return;
tcp_in.c:1798:        }
tcp_in.c:1799:        /* All other options have a length field, so that we easily
tcp_in.c:1800:           can skip past them. */
tcp_in.c:1801:        tcp_optidx += data - 2;
tcp_in.c:1802:      }
tcp_in.c:1803:    }
tcp_in.c:1804:  }
tcp_in.c:1805:}
tcp_in.c:1806:
tcp_in.c:1807:void
tcp_in.c:1808:tcp_trigger_input_pcb_close(void)
tcp_in.c:1809:{
tcp_in.c:1810:  recv_flags |= TF_CLOSED;
tcp_in.c:1811:}
tcp_in.c:1812:
tcp_in.c:1813:#endif /* LWIP_TCP */
